{
 "cells": [
  {
   "cell_type": "raw",
   "id": "95d64a2a",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Introduction à ElasticSearch\"\n",
    "date: 2020-09-03T13:00:00Z\n",
    "draft: false\n",
    "weight: 20\n",
    "tags:\n",
    "  - elastic\n",
    "  - levenshtein\n",
    "  - openfood\n",
    "categories:\n",
    "  - Tutoriel\n",
    "slug: elastic\n",
    "type: book\n",
    "summary: |\n",
    "  ElasticSearch est un moteur de recherche extrêmement rapide et flexible. \n",
    "  Cette technologie s'est imposée dans le domaine du traitement des \n",
    "  données textuelles. L'API Python permet d'intégrer cette \n",
    "  technologie dans des processus Python afin de les accélérer. Ce chapitre\n",
    "  présente cette intégration d'Elastic avec l'exemple de la recherche\n",
    "  dans les données alimentaires de l'OpenFood Facts Database \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45abc02b",
   "metadata": {},
   "source": [
    "Pour essayer les exemples présents dans ce tutoriel : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eb944c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"https://github.com/linogaliana/python-datascientist/blob/master/course/NLP/06_elastic.ipynb\" class=\"github\"><i class=\"fab fa-github\"></i></a>\n",
      "[![Download](https://img.shields.io/badge/Download-Notebook-important?logo=Jupyter)](https://downgit.github.io/#/home?url=https://github.com/linogaliana/python-datascientist/blob/master/course/NLP/06_elastic.ipynb)\n",
      "[![nbviewer](https://img.shields.io/badge/Visualize-nbviewer-blue?logo=Jupyter)](https://nbviewer.jupyter.org/github/linogaliana/python-datascientist/blob/master/course/NLP/06_elastic.ipynb)\n",
      "[![Onyxia](https://img.shields.io/badge/SSPcloud-Tester%20via%20SSP--cloud-informational&color=yellow?logo=Python)](https://datalab.sspcloud.fr/launcher/inseefrlab-helm-charts-datascience/jupyter?autoLaunch=true&onyxia.friendlyName=%C2%ABpython-datascience%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%ABcourse/NLP%2006_elastic.ipynb%C2%BB&security.allowlist.enabled=false)<br>\n",
      "[![Binder](https://img.shields.io/badge/Launch-Binder-E66581.svg?logo=data:image/png;base64,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)](https://mybinder.org/v2/gh/linogaliana/python-datascientist/master?filepath=course/NLP/06_elastic.ipynb)\n",
      "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/github/linogaliana/python-datascientist/blob/master/course/NLP/06_elastic.ipynb)\n",
      "[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist/course/NLP/06_elastic.ipynb)\n"
     ]
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: 'asis'\n",
    "#| include: true\n",
    "#| eval: true\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../../../../') #insert the utils module\n",
    "from utils import print_badges\n",
    "\n",
    "#print_badges(__file__)\n",
    "print_badges(\"content/course/NLP/06_elastic.qmd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4e4388",
   "metadata": {},
   "source": [
    "Ce chapitre a été écrit avec [Milena Suarez-Castillo](https://milenasuarezcastillo.netlify.app/) \n",
    "et présente quelques éléments qui servent de base à un travail en cours\n",
    "sur les inégalités socioéconomiques dans les\n",
    "choix de consommation alimentaire.\n",
    "\n",
    ":warning: Il nécessite une version particulière du package `elasticsearch` pour tenir compte de l'héritage de la version 7 du moteur Elastic. Pour cela, faire\n",
    "\n",
    "~~~python\n",
    "pip install elasticsearch==8.2.0\n",
    "~~~\n",
    "\n",
    "# Introduction\n",
    "\n",
    "## Réplication de ce chapitre\n",
    "\n",
    "Ce chapitre est plus exigeant en termes d'infrastructures que les précédents.\n",
    "Il nécessite un serveur Elastic. Les utilisateurs du\n",
    "[SSP Cloud](datalab.sspcloud.fr/) pourront répliquer les exemples de ce cours\n",
    "car cette technologie est disponible (que ce soit pour indexer une base ou\n",
    "pour requêter une base existante).\n",
    "\n",
    "La première partie de ce tutoriel ne nécessite pas d'architecture particulière et\n",
    "peut ainsi être exécutée en utilisant les packages suivants: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1dfceda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4764821",
   "metadata": {},
   "source": [
    "Le script `functions.py`, disponible sur `Github`, regroupe un certain nombre de fonctions utiles. \n",
    "\n",
    "{{% box status=\"hint\" title=\"Hint\" icon=\"fa fa-lightbulb\" %}}\n",
    "\n",
    "Plusieurs méthodes peuvent être mises en oeuvre pour récupérer\n",
    "le script d'utilitaires. Voici une proposition\n",
    "\n",
    "```python\n",
    "import requests\n",
    "\n",
    "baseurl = \"https://raw.githubusercontent.com/linogaliana/python-datascientist\"\n",
    "branch = \"quarto\"\n",
    "path = \"content/course/NLP/06_elastic/functions.py\"\n",
    "\n",
    "url = f\"{baseurl}/{branch}/{path}\"\n",
    "r = requests.get(url, allow_redirects=True)\n",
    "\n",
    "open('functions.py', 'wb').write(r.content)\n",
    "```\n",
    "{{% /box %}}\n",
    "\n",
    "Après l'avoir récupéré (cf. encadré dédié), il convient d'importer les fonctions sous forme de module:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20650b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions as fc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af0803b",
   "metadata": {},
   "source": [
    "## Cas d'usage\n",
    "\n",
    "\n",
    "Ce notebook recense et propose d'appréhender quelques outils utilisés\n",
    "pour le papier présenté aux\n",
    "[Journées de Méthodologie Statistiques 2022: Galiana and Suarez-Castillo, _\"Fuzzy matching on big-data: an illustration with scanner data and crowd-sourced nutritional data\"_](http://jms-insee.fr/jms2022s28_2/)\n",
    "(travail en cours!)\n",
    "\n",
    "\n",
    "> Combien de calories dans ma recette de cuisine de ce soir? Combien de calories dans mes courses de la semaine?\n",
    "\n",
    "L'objectif est de reconstituer, à partir de libellés de produits, les caractéristiques nutritionnelles d'une recette.\n",
    "Le problème est que les libellés des tickets de caisse ne sont pas des champs textuels très propres, ils contiennent, \n",
    "par exemple, beaucoup d'abbréviations, toutes n'étant pas évidentes. \n",
    "\n",
    "Voici par exemple une série de noms de produits qu'on va utiliser par la suite: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc0611cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket = ['CROISSANTS X6 400G',\n",
    "          'MAQUEREAUX MOUTAR.',\n",
    "          'IGP OC SAUVIGNON B',\n",
    "          'LAIT 1/2 ECRM UHT',\n",
    "          '6 OEUFS FRAIS LOCA',\n",
    "          'ANANAS C2',\n",
    "          'L POMME FUDJI X6 CAL 75/80 1KG ENV',\n",
    "          'PLT MIEL',\n",
    "          'STELLA ARTOIS X6',\n",
    "          'COTES DU LUBERON AIGUEBRUN 75C']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e60005a",
   "metadata": {},
   "source": [
    "A ces produits, s'ajoutent les ingrédients suivants, issus de la\n",
    "[recette du velouté de potiron et carottes de Marmiton](https://www.marmiton.org/recettes/recette_veloute-de-potiron-et-carottes_19009.aspx)\n",
    "qui sera notre plat principal :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75ad0358",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients = ['500 g de carottes',\n",
    " '2 pommes de terre',\n",
    " \"1 gousse d'ail\",\n",
    " '1/2 l de lait',\n",
    " '1/2 l de bouillon de volaille',\n",
    " \"1 cuillère à soupe de huile d'olive\",\n",
    " '1 kg de potiron',\n",
    " '1 oignon',\n",
    " '10 cl de crème liquide (facultatif)']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7f7177",
   "metadata": {},
   "source": [
    "Essayer de récupérer par webscraping cette liste est un bon exercice pour réviser\n",
    "les concepts [vus précedemment](#webscraping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c2b3658",
   "metadata": {},
   "outputs": [],
   "source": [
    "libelles = ticket + ingredients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b23f77c",
   "metadata": {},
   "source": [
    "On part avec cette liste dans notre supermarché virtuel. L'objectif sera de trouver\n",
    "une méthode permettant passer à l'échelle:\n",
    "automatiser les traitements, effectuer des recherches efficaces, garder une certaine généralité et flexibilité. \n",
    "\n",
    "Ce chapitre montrera par l'exemple l'intérêt d'`Elastic` par rapport à une solution \n",
    "qui n'utiliserait que du Python\n",
    "\n",
    "# Données utilisées\n",
    "\n",
    "\n",
    "## Les bases offrant des informations nutritionnelles \n",
    "\n",
    "Pour un nombre restreint de produits, on pourrait bien-sûr chercher à\n",
    "la main les caractéristiques des produits en utilisant les \n",
    "fonctionalités d'un moteur de recherche:\n",
    "\n",
    "![](fraise.png)\n",
    "\n",
    "Cependant, cette approche serait très fastidieuse et \n",
    "nécessiterait de récuperer, à la main, chaque caractéristique\n",
    "pour chaque produit. Ce n'est donc pas envisageable.\n",
    "\n",
    "Les données disponibles sur Google viennent de l'[USDA](https://fdc.nal.usda.gov/),\n",
    "l'équivalent américain de notre Ministère de l'Agriculture. \n",
    "Cependant, pour des recettes comportant des noms de produits français, ainsi que \n",
    "des produits potentiellement transformés, ce n'est pas très pratique d'utiliser\n",
    "une base de données de produits agricoles en Français. Pour cette raison,\n",
    "nous proposons d'utiliser les deux bases suivantes, qui servent de base au travail de\n",
    "Galiana et al. (à venir)\n",
    "\n",
    "\n",
    "* L'[OpenFoodFacts database](https://fr.openfoodfacts.org/) qui est une base française, \n",
    "collaborative de produits alimentaires. Issue d'un projet [Data4Good](https://dataforgood.fr/), il s'agit d'une \n",
    "alternative opensource et opendata à la base de données de l'application [Yuka](https://yuka.io/). \n",
    "* La table de composition nutritionnelle [Ciqual](https://ciqual.anses.fr) produite par l'Anses. Celle-ci\n",
    "propose la composition nutritionnelle _moyenne_ des aliments les plus consommés en France. Il s'agit d'une base de données\n",
    "enrichie par rapport à celle de l'USDA puisqu'elle ne se cantonne pas aux produits agricoles non transformés. \n",
    "Avec cette base, il ne s'agit pas de trouver un produit exact mais essayer de trouver un produit type proche du produit\n",
    "dont on désire connaître les caractéristiques. \n",
    "\n",
    "![](openfood.png)\n",
    "\n",
    "## Import \n",
    "\n",
    "Quelques fonctions utiles sont regroupées dans le script `functions.py` et importées dans le notebook. La base OpenFood peut être récupérée en ligne (opération qui peut prendre un peu de temps, on passe ici par le stockage interne de la plateforme en spécifiant `from_latest=False`). La base ciqual, plus légère, est récupérée elle directement en ligne.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c740b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/__w/python-datascientist/python-datascientist/content/course/NLP/06_elastic/functions.py:30: DtypeWarning:\n",
      "\n",
      "Columns (76) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "openfood = fc.import_openfood()\n",
    "ciqual = fc.import_ciqual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a6f018c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>nutriscore_score</th>\n",
       "      <th>energy_100g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>moutarde au moût de raisin</td>\n",
       "      <td>18.0</td>\n",
       "      <td>936.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Salade de carottes râpées</td>\n",
       "      <td>1.0</td>\n",
       "      <td>134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Tarte noix de coco</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1594.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Compote de poire</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>657.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Salade de macedoine de légumes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>598.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      product_name  nutriscore_score energy_100g\n",
       "8      moutarde au moût de raisin               18.0       936.0\n",
       "18       Salade de carottes râpées               1.0       134.0\n",
       "27              Tarte noix de coco              14.0      1594.0\n",
       "38                Compote de poire              -2.0       657.0\n",
       "42  Salade de macedoine de légumes               1.0       598.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openfood.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f293777d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alim_nom_fr</th>\n",
       "      <th>Energie, Règlement UE N° 1169/2011 (kcal/100 g)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Taboulé ou Salade de couscous, préemballé</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Salade de pomme de terre à la piémontaise, pré...</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Crudité, sans assaisonnement (aliment moyen)</td>\n",
       "      <td>29,9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Salade végétale à base de boulgour et/ou quino...</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Salade de chou ou Coleslaw, avec sauce, préemb...</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          alim_nom_fr  \\\n",
       "5           Taboulé ou Salade de couscous, préemballé   \n",
       "6   Salade de pomme de terre à la piémontaise, pré...   \n",
       "9        Crudité, sans assaisonnement (aliment moyen)   \n",
       "13  Salade végétale à base de boulgour et/ou quino...   \n",
       "16  Salade de chou ou Coleslaw, avec sauce, préemb...   \n",
       "\n",
       "   Energie, Règlement UE N° 1169/2011 (kcal/100 g)  \n",
       "5                                              179  \n",
       "6                                              130  \n",
       "9                                             29,9  \n",
       "13                                             168  \n",
       "16                                             105  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ciqual.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9653afed",
   "metadata": {},
   "source": [
    "# ElasticSearch ? Mais ce n'est pas du Python ?!\n",
    "\n",
    "## Qu'est-ce qu'Elastic ? \n",
    "\n",
    "ElasticSearch c'est un logiciel qui fournit un moteur de recherche installé sur\n",
    "un serveur (ou une machine personnelle) qu'il est possible de requêter depuis un client\n",
    "(une session `Python` par exemple). C'est un moteur de recherche \n",
    "très performant, puissant et flexible, extrêmement utilisé dans le domaine de la datascience\n",
    "sur données textuelles. Un cas d'usage est par exemple de trouver,\n",
    "dans un corpus de grande dimension\n",
    "(plusieurs sites web, livres...), un certain texte en s'autorisant des termes voisins\n",
    "(verbes conjugués, fautes de frappes...).  \n",
    "\n",
    "Le principe est le même que celui d'un moteur de recherche du web comme Google. \n",
    "D'un côté, l'ensemble à parcourir est indexé (c'est-à-dire XXX) pour être en \n",
    "mesure de parcourir de manière efficace l'ensemble du corpus.\n",
    "De l'autre côté, la phase de recherche permet de retrouver l'élément du corpus le\n",
    "plus cohérent avec la requête de recherche. L'indexation consiste, par exemple,\n",
    "à pré-définir des traitements des termes du corpus pour gagner en efficacité\n",
    "lors de la phase de recherche. En effet, l'indexation est une opération peu fréquente\n",
    "par rapport à la recherche. Pour cette dernière, l'efficacité est cruciale (un site web \n",
    "qui prend plusieurs secondes à interpréter une requête simple ne sera pas utilisé). Mais, pour\n",
    "l'indexation, ceci est moins crucial. \n",
    "\n",
    "ElasticSearch propose une interface graphique nommée Kibana. Celle-ci est pratique\n",
    "pour tester des requêtes et pour superviser le serveur Elastic. Cependant,\n",
    "pour le passage à l'échelle, notamment pour mettre en lien une base indexée dans\n",
    "Elastic avec une autre source de données, les API proposées par ElasticSearch\n",
    "sont beaucoup plus pratiques. Ces API permettent de connecter une session `Python` (idem pour `R`)\n",
    "à un serveur Elastic afin de communiquer avec lui (échanger des flux via une API REST). \n",
    "\n",
    "## ElasticSearch et Python\n",
    "\n",
    "En `Python`, le package officiel est [`elasticsearch`](https://elasticsearch-py.readthedocs.io/en/v7.12.0/).\n",
    "Ce dernier permet de configurer les paramètres pour interagir avec un serveur, indexer \n",
    "une ou plusieurs bases, envoyer de manière automatisée un ensemble de requêtes\n",
    "au serveur, récupérer les résultats directement dans une session `Python`...\n",
    "\n",
    "# Limites de la distance de Levenshtein\n",
    "\n",
    "\n",
    "On appelle distance de Levenshtein entre deux chaînes de caractères le coût minimal (en nombre d'opérations)\n",
    "pour transformer la première en la seconde par\n",
    "\n",
    "* substitution\n",
    "* insertion\n",
    "* suppression\n",
    "\n",
    "La distance de Levenshtein est une mesure très utilisée pour comparer la similarité entre deux\n",
    "chaînes de caractères. Il existe plusieurs packages pour calculer cette dernière. \n",
    "`fuzzywuzzy` est le plus connu mais ce dernier est assez lent (implémentation en pur `Python`).\n",
    "Le package `rapidfuzz`, présenté ici, propose les mêmes fonctionalités mais est plus rapide car implémenté\n",
    "en `C++` qui est plus efficace. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cd2daad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import rapidfuzz # \"Rapid fuzzy string matching in Python and C++ using the Levenshtein Distance\" soit l'équivalent plus rapide de la librarie fuzzywuzzy\n",
    "[rapidfuzz.string_metric.levenshtein('salut','slut', weights =(1,1,1)), # Suppression \n",
    " rapidfuzz.string_metric.levenshtein('salut','saalut', weights =(1,1,1)), # Addition \n",
    " rapidfuzz.string_metric.levenshtein('salut','selut', weights =(1,1,1))] # Substitution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1921de11",
   "metadata": {},
   "source": [
    "## Produits Ciqual les plus similaires aux produits de la recette\n",
    "\n",
    "On pourrait écrire une fonction qui prend en argument une liste de libellés d'intérêt et une liste de candidat au *match* et\n",
    "renvoie le libellé le plus proche. Cependant, le risque est que cet algorithme soit relativement lent s'il n'est pas codé\n",
    "parfaitement. Il est, à mon avis, plus simple, quand\n",
    "on est habitué à la logique `pandas`, de faire un produit cartésien pour obtenir un vecteur mettant en miroir\n",
    "chaque produit de notre recette avec l'ensembles des produits Ciqual et ensuite comparer les deux vecteurs pour prendre,\n",
    "pour chaque produit, le meilleur *match*. Les bases étant de taille limitée, le produit cartésien n'est pas problématique.\n",
    "Avec des bases plus conséquentes une stratégie plus parcimonieuse en mémoire devrait être envisagée. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "916c0405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'exécution total : 0.06 secondes ---\n"
     ]
    }
   ],
   "source": [
    "dist_leven = fc.match_product(libelles, ciqual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8238eccf",
   "metadata": {},
   "source": [
    "Cette première étape naïve est décevante à plusieurs égards: \n",
    "\n",
    "* Certes, on a des matches cohérent (par exemple \"Oignon rouge, cru\" et \"1 oignon\")\n",
    "mais on a plus de couples incohérents ;\n",
    "* Le temps de calcul peut apparaître faible mais le passage à l'échelle risque d'être compliqué ;\n",
    "* Les besoins mémoires sont potentiellement importants lors de l'appel à \n",
    "`rapidfuzz.process.extract` ce qui peut bloquer le passage à l'échelle\n",
    "* La distance textuelle n'est pas nécessairement la plus pertinente. \n",
    "\n",
    "On a négligé une étape importante: la normalisation (ou nettoyage des textes) présentée dans la \n",
    "partie [NLP](#nlp), notamment: \n",
    "\n",
    "* harmonisation de la casse, suppression des accents...\n",
    "* suppressions des mots outils (e.g. ici on va d'abord négliger les quantités pour trouver la nature de l'aliment, en particulier pour Ciqual)\n",
    "    \n",
    "\n",
    "## Preprocessing pour améliorer la pertinence des matches\n",
    "\n",
    "On nettoie les libellés en mobilisant des expressions régulières et un dictionnaire de mots outils.\n",
    "On peut adapter le nettoyage à la base, par exemple dans ciqual, la cuisson est souvent renseignée et bruite les appariemments.\n",
    "La fonction `clean_libelle` du script [`utils.py`](#utils.py) propose quelques fonctions\n",
    "appliquant les méthodes disponibles dans la partie [NLP](#NLP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f5e507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import clean_libelle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03a52d9",
   "metadata": {},
   "source": [
    "On peut déjà : \n",
    "\n",
    "* Harmoniser la casse et retirer les accents (voir `functions.py`)\n",
    "* Retirer tout les caractères qui ne sont pas des lettres (chiffres, ponctuations)\n",
    "* Retirer les caractères isolés\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69664c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords = ['KG','CL','G','L','CRUE?S?', 'PREEMBALLEE?S?']\n",
    "replace_regex = {r'[^A-Z]': ' ', r'\\b[A-Z0-9]{1,2}?\\b':' '} # "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b86708",
   "metadata": {},
   "source": [
    "Cela permet d'obtenir les bases nettoyées suivantes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e3f4866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alim_nom_fr</th>\n",
       "      <th>Energie, Règlement UE N° 1169/2011 (kcal/100 g)</th>\n",
       "      <th>libel_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>Agneau, viande, cuite (aliment moyen)</td>\n",
       "      <td>208</td>\n",
       "      <td>AGNEAU VIANDE CUITE ALIMENT MOYEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>Pain grillé suédois au blé complet</td>\n",
       "      <td>398</td>\n",
       "      <td>PAIN GRILLE SUEDOIS BLE COMPLET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Bouillon de viande et légumes type pot-au-feu,...</td>\n",
       "      <td>4,8</td>\n",
       "      <td>BOUILLON VIANDE LEGUMES TYPE POT FEU PRET CONS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3085</th>\n",
       "      <td>Ail, sauté/poêlé, sans matière grasse</td>\n",
       "      <td>130</td>\n",
       "      <td>AIL SAUTE POELE SANS MATIERE GRASSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>Poulet fermier, viande et peau, cru</td>\n",
       "      <td>135</td>\n",
       "      <td>POULET FERMIER VIANDE PEAU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2902</th>\n",
       "      <td>Huile combinée (mélange d'huiles)</td>\n",
       "      <td>896</td>\n",
       "      <td>HUILE COMBINEE MELANGE HUILES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2910</th>\n",
       "      <td>Matière grasse végétale (type margarine), tene...</td>\n",
       "      <td>532</td>\n",
       "      <td>MATIERE GRASSE VEGETALE TYPE MARGARINE TENEUR ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>Feuilleté salé (aliment moyen)</td>\n",
       "      <td>301</td>\n",
       "      <td>FEUILLETE SALE ALIMENT MOYEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719</th>\n",
       "      <td>Rouget-barbet de roche, cru</td>\n",
       "      <td>158</td>\n",
       "      <td>ROUGET BARBET ROCHE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>Pomme de terre primeur, sans peau, bouillie/cu...</td>\n",
       "      <td>71,6</td>\n",
       "      <td>POMME TERRE PRIMEUR SANS PEAU BOUILLIE CUITE EAU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            alim_nom_fr  \\\n",
       "1222              Agneau, viande, cuite (aliment moyen)   \n",
       "1071                 Pain grillé suédois au blé complet   \n",
       "29    Bouillon de viande et légumes type pot-au-feu,...   \n",
       "3085              Ail, sauté/poêlé, sans matière grasse   \n",
       "1339                Poulet fermier, viande et peau, cru   \n",
       "2902                  Huile combinée (mélange d'huiles)   \n",
       "2910  Matière grasse végétale (type margarine), tene...   \n",
       "332                      Feuilleté salé (aliment moyen)   \n",
       "1719                        Rouget-barbet de roche, cru   \n",
       "663   Pomme de terre primeur, sans peau, bouillie/cu...   \n",
       "\n",
       "     Energie, Règlement UE N° 1169/2011 (kcal/100 g)  \\\n",
       "1222                                             208   \n",
       "1071                                             398   \n",
       "29                                               4,8   \n",
       "3085                                             130   \n",
       "1339                                             135   \n",
       "2902                                             896   \n",
       "2910                                             532   \n",
       "332                                              301   \n",
       "1719                                             158   \n",
       "663                                             71,6   \n",
       "\n",
       "                                            libel_clean  \n",
       "1222                 AGNEAU VIANDE CUITE ALIMENT MOYEN   \n",
       "1071                    PAIN GRILLE SUEDOIS BLE COMPLET  \n",
       "29    BOUILLON VIANDE LEGUMES TYPE POT FEU PRET CONS...  \n",
       "3085                AIL SAUTE POELE SANS MATIERE GRASSE  \n",
       "1339                        POULET FERMIER VIANDE PEAU   \n",
       "2902                     HUILE COMBINEE MELANGE HUILES   \n",
       "2910  MATIERE GRASSE VEGETALE TYPE MARGARINE TENEUR ...  \n",
       "332                       FEUILLETE SALE ALIMENT MOYEN   \n",
       "1719                               ROUGET BARBET ROCHE   \n",
       "663    POMME TERRE PRIMEUR SANS PEAU BOUILLIE CUITE EAU  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ciqual = clean_libelle(ciqual, yvar = 'alim_nom_fr', replace_regex = replace_regex, stopWords = stopWords)\n",
    "ciqual.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a27aa2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>nutriscore_score</th>\n",
       "      <th>energy_100g</th>\n",
       "      <th>libel_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1984367</th>\n",
       "      <td>Sugo alla Norma</td>\n",
       "      <td>2.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>SUGO ALLA NORMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2218171</th>\n",
       "      <td>Kekse</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1887.0</td>\n",
       "      <td>KEKSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174019</th>\n",
       "      <td>Cacao &amp;quot;comme avant&amp;quot;</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1548.0</td>\n",
       "      <td>CACAO QUOT COMME AVANT QUOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2271167</th>\n",
       "      <td>ซอสเหยาะจิ้ม healthy fit less sodium40%</td>\n",
       "      <td>10.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>SEHYAAACCHIM HEALTHY FIT LESS SODIUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036157</th>\n",
       "      <td>Aiguillettes de poulet au curry et petits légumes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>AIGUILLETTES POULET CURRY PETITS LEGUMES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341875</th>\n",
       "      <td>Sauce bbq originale</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1116.0</td>\n",
       "      <td>SAUCE BBQ ORIGINALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514322</th>\n",
       "      <td>Tait farm foods, ginger venaifrette, ginger</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1795.0</td>\n",
       "      <td>TAIT FARM FOODS GINGER VENAIFRETTE GINGER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615116</th>\n",
       "      <td>Sea salt caramel popcorn, sea salt caramel</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1941.0</td>\n",
       "      <td>SEA SALT CARAMEL POPCORN SEA SALT CARAMEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260916</th>\n",
       "      <td>Matzo-style squares</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1812.0</td>\n",
       "      <td>MATZO STYLE SQUARES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2269296</th>\n",
       "      <td>Lemon yerba mate tea</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LEMON YERBA MATE TEA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              product_name  nutriscore_score  \\\n",
       "1984367                                    Sugo alla Norma               2.0   \n",
       "2218171                                              Kekse              18.0   \n",
       "1174019                      Cacao &quot;comme avant&quot;              24.0   \n",
       "2271167            ซอสเหยาะจิ้ม healthy fit less sodium40%              10.0   \n",
       "1036157  Aiguillettes de poulet au curry et petits légumes               1.0   \n",
       "341875                                 Sauce bbq originale              21.0   \n",
       "514322         Tait farm foods, ginger venaifrette, ginger              18.0   \n",
       "615116          Sea salt caramel popcorn, sea salt caramel              28.0   \n",
       "260916                                 Matzo-style squares              10.0   \n",
       "2269296                               Lemon yerba mate tea               0.0   \n",
       "\n",
       "        energy_100g                                libel_clean  \n",
       "1984367       330.0                            SUGO ALLA NORMA  \n",
       "2218171      1887.0                                      KEKSE  \n",
       "1174019      1548.0               CACAO QUOT COMME AVANT QUOT   \n",
       "2271167       247.0      SEHYAAACCHIM HEALTHY FIT LESS SODIUM   \n",
       "1036157       460.0   AIGUILLETTES POULET CURRY PETITS LEGUMES  \n",
       "341875       1116.0                        SAUCE BBQ ORIGINALE  \n",
       "514322       1795.0  TAIT FARM FOODS GINGER VENAIFRETTE GINGER  \n",
       "615116       1941.0  SEA SALT CARAMEL POPCORN SEA SALT CARAMEL  \n",
       "260916       1812.0                        MATZO STYLE SQUARES  \n",
       "2269296         0.0                       LEMON YERBA MATE TEA  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openfood = clean_libelle(openfood, yvar = 'product_name', replace_regex = replace_regex, stopWords = stopWords)\n",
    "openfood.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6089873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>libel</th>\n",
       "      <th>libel_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>500 g de carottes</td>\n",
       "      <td>CAROTTES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>STELLA ARTOIS X6</td>\n",
       "      <td>STELLA ARTOIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1 kg de potiron</td>\n",
       "      <td>POTIRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ANANAS C2</td>\n",
       "      <td>ANANAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PLT MIEL</td>\n",
       "      <td>PLT MIEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LAIT 1/2 ECRM UHT</td>\n",
       "      <td>LAIT ECRM UHT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CROISSANTS X6 400G</td>\n",
       "      <td>CROISSANTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6 OEUFS FRAIS LOCA</td>\n",
       "      <td>OEUFS FRAIS LOCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAQUEREAUX MOUTAR.</td>\n",
       "      <td>MAQUEREAUX MOUTAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IGP OC SAUVIGNON B</td>\n",
       "      <td>IGP SAUVIGNON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 libel         libel_clean\n",
       "10   500 g de carottes            CAROTTES\n",
       "8     STELLA ARTOIS X6      STELLA ARTOIS \n",
       "16     1 kg de potiron             POTIRON\n",
       "5            ANANAS C2             ANANAS \n",
       "7             PLT MIEL            PLT MIEL\n",
       "3    LAIT 1/2 ECRM UHT       LAIT ECRM UHT\n",
       "0   CROISSANTS X6 400G         CROISSANTS \n",
       "4   6 OEUFS FRAIS LOCA    OEUFS FRAIS LOCA\n",
       "1   MAQUEREAUX MOUTAR.  MAQUEREAUX MOUTAR \n",
       "2   IGP OC SAUVIGNON B      IGP SAUVIGNON "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "courses = pd.DataFrame(libelles, columns = ['libel'])\n",
    "courses = clean_libelle(courses, yvar = 'libel', replace_regex = replace_regex, stopWords = stopWords)\n",
    "courses.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19283506",
   "metadata": {},
   "source": [
    "Les noms de produits sont déjà plus harmonisés. Voyons voir si _a permet de trouver un\n",
    "*match* dans l'Openfood database: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ef4f8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'exécution total : 14.07 secondes ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_match</th>\n",
       "      <th>distance</th>\n",
       "      <th>index_ciqual</th>\n",
       "      <th>produit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAQUEREAU MOUTARDE</td>\n",
       "      <td>91.428571</td>\n",
       "      <td>520380</td>\n",
       "      <td>MAQUEREAUX MOUTAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OEUFS FRAIS</td>\n",
       "      <td>81.481481</td>\n",
       "      <td>280919</td>\n",
       "      <td>OEUFS FRAIS LOCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>POMMES TERRE</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>288016</td>\n",
       "      <td>POMMES TERRE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FRUIT CIE POMME</td>\n",
       "      <td>70.588235</td>\n",
       "      <td>461132</td>\n",
       "      <td>POMME FUDJI CAL ENV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SOUPE PISTOU CUISINEE HUILE OLIVE</td>\n",
       "      <td>77.966102</td>\n",
       "      <td>419703</td>\n",
       "      <td>CUILLERE SOUPE HUILE OLIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>OIGNON</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>386166</td>\n",
       "      <td>OIGNON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>COTES AGNEAU GRILLER</td>\n",
       "      <td>65.116279</td>\n",
       "      <td>402326</td>\n",
       "      <td>COTES LUBERON AIGUEBRUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ANANAS</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>30469</td>\n",
       "      <td>ANANAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LAIT UHT ECREME</td>\n",
       "      <td>92.857143</td>\n",
       "      <td>351932</td>\n",
       "      <td>LAIT ECRM UHT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GOUSSE AIL</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>649035</td>\n",
       "      <td>GOUSSE AIL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           best_match    distance  index_ciqual  \\\n",
       "1                  MAQUEREAU MOUTARDE   91.428571        520380   \n",
       "4                         OEUFS FRAIS   81.481481        280919   \n",
       "11                       POMMES TERRE  100.000000        288016   \n",
       "6                     FRUIT CIE POMME   70.588235        461132   \n",
       "15  SOUPE PISTOU CUISINEE HUILE OLIVE   77.966102        419703   \n",
       "17                             OIGNON  100.000000        386166   \n",
       "9                COTES AGNEAU GRILLER   65.116279        402326   \n",
       "5                              ANANAS  100.000000         30469   \n",
       "3                    LAIT UHT ECREME    92.857143        351932   \n",
       "12                         GOUSSE AIL  100.000000        649035   \n",
       "\n",
       "                        produit  \n",
       "1            MAQUEREAUX MOUTAR   \n",
       "4              OEUFS FRAIS LOCA  \n",
       "11                 POMMES TERRE  \n",
       "6           POMME FUDJI CAL ENV  \n",
       "15   CUILLERE SOUPE HUILE OLIVE  \n",
       "17                       OIGNON  \n",
       "9      COTES LUBERON AIGUEBRUN   \n",
       "5                       ANANAS   \n",
       "3                 LAIT ECRM UHT  \n",
       "12                   GOUSSE AIL  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_leven_openfood = fc.match_product(courses[\"libel_clean\"], openfood, \"libel_clean\")\n",
    "dist_leven_openfood.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1871848b",
   "metadata": {},
   "source": [
    "Pas encore parfait, mais on progresse sur les produits appariés! \n",
    "Concernant le temps de calcul, les quelques secondes nécessaires à\n",
    "ce calcul peuvent apparaître un faible prix à payer. Cependant,\n",
    "il convient de rappeler que le nombre de produits dans l'ensemble\n",
    "de recherche est faible. Cette solution n'est donc pas généralisable.\n",
    "\n",
    "\n",
    "\n",
    "## Réduire les temps de recherche\n",
    "\n",
    "Finalement, l'idéal serait de disposer d'un **moteur de recherche** adapté à notre besoin, contenant les produits candidats, que l'on pourrait interroger, rapide en lecture, capable de classer les echos renvoyés par pertinence, que l'on pourrait requêter de manière flexible\n",
    "(par exemple, on pourrait vouloir signaler qu'un echo nous intéresse seulement si la donnée calorique n'est pas manquante).\n",
    "On pourrait même vouloir qu'il effectue pour nous des prétraitements sur les données. \n",
    "\n",
    "C'est exactement ce que fait Elastic\n",
    "\n",
    "# Indexer une base \n",
    "\n",
    "A partir de maintenant, commence, à proprement parler, la démonstration Elastic. Cette \n",
    "partie développe les éléments les plus techniques, à savoir l'indexation d'une base. \n",
    "Tous les utilisateurs d'Elastic n'ont pas nécessairement à passer par là, ils peuvent \n",
    "trouver une base déjà indexée, idéalement par un *data engineer* qui aura optimisé\n",
    "les traitements. \n",
    "\n",
    "Les utilisateurs du [SSP Cloud](https://datalab.sspcloud.fr/accueil), architecture qui\n",
    "repose sur la technologie [Kubernetes](https://kubernetes.io/) peuvent \n",
    "répliquer les éléments de la suite du document. \n",
    "\n",
    "\n",
    "## Créer un cluster Elastic sur le DataLab\n",
    "\n",
    "Pour lancer un service Elastic, il faut cliquer sur [ce lien](https://datalab.sspcloud.fr/launcher/inseefrlab-helm-charts-datascience/elastic). \n",
    "\n",
    "Une fois créé, vous pouvez explorer l'interface graphique Kibana. Cependant, grâce à l'API Elastic\n",
    "de Python, on se passera de celle-ci. Donc, en pratique,\n",
    "une fois lancé, pas besoin d'ouvrir ce service Elastic pour continuer à suivre[^1].\n",
    "\n",
    "[^1]: Le lancement du service a créé dans votre `NAMESPACE Kubernetes` (l'ensemble de tout vos services) un cluster Elastic.\n",
    "Vous n'avez droit qu'à un cluster par namespace (ou compte d'utilisateur).\n",
    "Votre service Jupyter, VSCode, RStudio, etc. est associé au même namespace.\n",
    "De même qu'il n'est pas nécessaire de comprendre comment fonctionne le moteur d'une voiture pour conduire, \n",
    "il n'est pas nécessaire de comprendre la manière dont tout ce beau monde dialogue pour pouvoir utiliser le `SSP Cloud`. \n",
    "\n",
    "Dans un terminal, vous pouvez aussi vérifier que vous êtes en mesure de dialoguer avec votre cluster Elastic, qui est prêt à vous écouter:\n",
    "\n",
    "```shell\n",
    "kubectl get statefulset\n",
    "```\n",
    "\n",
    "Passer par la ligne de commande serait peu commode. \n",
    "Nous allons utiliser la librairie `python` `elasticsearch` pour dialoguer avec notre moteur de recherche Elastic.\n",
    "Les instructions ci-dessous indiquent comment établir la connection.\n",
    "\n",
    "```python\n",
    "from elasticsearch import Elasticsearch\n",
    "HOST = 'elasticsearch-master'\n",
    "\n",
    "def elastic():\n",
    "    \"\"\"Connection avec Elastic sur le data lab\"\"\"\n",
    "    es = Elasticsearch([{'host': HOST, 'port': 9200}], http_compress=True,  timeout=200)\n",
    "    return es\n",
    "\n",
    "es = elastic()\n",
    "```\n",
    "\n",
    "```\n",
    "<Elasticsearch([{'host': 'elasticsearch-master', 'port': 9200}])>\n",
    "```\n",
    "\n",
    "\n",
    "Maintenant que la connection est établie, deux étapes nous attendent:\n",
    "\n",
    "1. **Indexation** Envoyer les documents parmi lesquels on veut chercher des echos pertinents dans notre elastic. Un index est une collection de document. Nous pourrions en créer deux: un pour les produits ciqual, un pour les produits openfood\n",
    "2. **Requête** Chercher les documents les plus pertinents suivant une recherche textuelle flexible. Nous allons rechercher les libellés de notre recette et de notre liste de course.\n",
    "\n",
    "## Première indexation\n",
    "\n",
    "On crée donc nos deux index:\n",
    "\n",
    "~~~python\n",
    "if not es.indices.exists('openfood'):\n",
    "    es.indices.create('openfood')\n",
    "if not es.indices.exists('ciqual'):\n",
    "    es.indices.create('ciqual')\n",
    "~~~\n",
    "\n",
    "Pour l'instant, nos index sont vides! Ils contiennent 0 documents.\n",
    "\n",
    "~~~python\n",
    "es.count(index = 'openfood')\n",
    "~~~\n",
    "\n",
    "```\n",
    "{'count': 0, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}}\n",
    "```\n",
    "\n",
    "Nous allons en rajouter quelques uns ! \n",
    "\n",
    "~~~python\n",
    "es.create(index = 'openfood',  id = 1, body = {'product_name': 'Tarte noix de coco', 'product_name_clean': 'TARTE NOIX COCO'})\n",
    "es.create(index = 'openfood',  id = 2, body = {'product_name': 'Noix de coco', 'product_name_clean': 'NOIX COCO'})\n",
    "es.create(index = 'openfood',  id = 3, body = {'product_name': 'Beurre doux', 'product_name_clean': 'BEURRE DOUX'})\n",
    "~~~\n",
    "\n",
    "~~~python\n",
    "es.count(index = 'openfood')\n",
    "~~~\n",
    "\n",
    "```\n",
    "{'count': 3, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}}\n",
    "```\n",
    "\n",
    "## Première recherche\n",
    "\n",
    "Faisons notre première recherche: cherchons des noix de pécan! \n",
    "\n",
    "~~~python\n",
    "es.search(index = 'openfood', q = 'noix de pécan')\n",
    "~~~\n",
    "\n",
    "```\n",
    "{'took': 3102, 'timed_out': False, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 2, 'relation': 'eq'}, 'max_score': 0.9400072, 'hits': [{'_index': 'openfood', '_type': '_doc', '_id': '2', '_score': 0.9400072, '_source': {'product_name': 'Noix de coco', 'product_name_clean': 'NOIX COCO'}}, {'_index': 'openfood', '_type': '_doc', '_id': '1', '_score': 0.8272065, '_source': {'product_name': 'Tarte noix de coco', 'product_name_clean': 'TARTE NOIX COCO'}}]}}\n",
    "```\n",
    "\n",
    "\n",
    "Intéressons nous aux `hits` (résultats pertinents, ou echos) : nous en avons 2. \n",
    "Le score maximal parmi les hits est mentionné dans `max_score` et correspond à celui du deuxième document indexé.\n",
    "\n",
    "Elastic nous fournit ici un **score de pertinence** dans notre recherche d'information, et classe ainsi les documents renvoyés.\n",
    "\n",
    "Ici nous utilisons la configuration par défaut. Mais comment est calculé ce score? Demandons à Elastic de nous expliquer le score du document `2` dans la requête `\"noix de pécan\"`.\n",
    "\n",
    "~~~python\n",
    "es.explain(index = 'openfood', id = 2, q = 'noix de pécan')\n",
    "~~~\n",
    "\n",
    "```\n",
    "{'_index': 'openfood', '_type': '_doc', '_id': '2', 'matched': True, 'explanation': {'value': 0.9400072, 'description': 'max of:', 'details': [{'value': 0.49917626, 'description': 'sum of:', 'details': [{'value': 0.49917626, 'description': 'weight(product_name_clean:noix in 1) [PerFieldSimilarity], result of:', 'details': [{'value': 0.49917626, 'description': 'score(freq=1.0), computed as boost * idf * tf from:', 'details': [{'value': 2.2, 'description': 'boost', 'details': []}, {'value': 0.47000363, 'description': 'idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:', 'details': [{'value': 2, 'description': 'n, number of documents containing term', 'details': []}, {'value': 3, 'description': 'N, total number of documents with field', 'details': []}]}, {'value': 0.48275858, 'description': 'tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:', 'details': [{'value': 1.0, 'description': 'freq, occurrences of term within document', 'details': []}, {'value': 1.2, 'description': 'k1, term saturation parameter', 'details': []}, {'value': 0.75, 'description': 'b, length normalization parameter', 'details': []}, {'value': 2.0, 'description': 'dl, length of field', 'details': []}, {'value': 2.3333333, 'description': 'avgdl, average length of field', 'details': []}]}]}]}]}, {'value': 0.9400072, 'description': 'sum of:', 'details': [{'value': 0.4700036, 'description': 'weight(product_name:noix in 1) [PerFieldSimilarity], result of:', 'details': [{'value': 0.4700036, 'description': 'score(freq=1.0), computed as boost * idf * tf from:', 'details': [{'value': 2.2, 'description': 'boost', 'details': []}, {'value': 0.47000363, 'description': 'idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:', 'details': [{'value': 2, 'description': 'n, number of documents containing term', 'details': []}, {'value': 3, 'description': 'N, total number of documents with field', 'details': []}]}, {'value': 0.45454544, 'description': 'tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:', 'details': [{'value': 1.0, 'description': 'freq, occurrences of term within document', 'details': []}, {'value': 1.2, 'description': 'k1, term saturation parameter', 'details': []}, {'value': 0.75, 'description': 'b, length normalization parameter', 'details': []}, {'value': 3.0, 'description': 'dl, length of field', 'details': []}, {'value': 3.0, 'description': 'avgdl, average length of field', 'details': []}]}]}]}, {'value': 0.4700036, 'description': 'weight(product_name:de in 1) [PerFieldSimilarity], result of:', 'details': [{'value': 0.4700036, 'description': 'score(freq=1.0), computed as boost * idf * tf from:', 'details': [{'value': 2.2, 'description': 'boost', 'details': []}, {'value': 0.47000363, 'description': 'idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:', 'details': [{'value': 2, 'description': 'n, number of documents containing term', 'details': []}, {'value': 3, 'description': 'N, total number of documents with field', 'details': []}]}, {'value': 0.45454544, 'description': 'tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:', 'details': [{'value': 1.0, 'description': 'freq, occurrences of term within document', 'details': []}, {'value': 1.2, 'description': 'k1, term saturation parameter', 'details': []}, {'value': 0.75, 'description': 'b, length normalization parameter', 'details': []}, {'value': 3.0, 'description': 'dl, length of field', 'details': []}, {'value': 3.0, 'description': 'avgdl, average length of field', 'details': []}]}]}]}]}]}}\n",
    "```\n",
    "\n",
    "\n",
    "Elastic nous explique donc que le score `0.9400072` est le maximum entre deux sous-scores, `0.4991` et `0.9400072`.\n",
    "\n",
    "Pour chacun de ces sous-scores, le détail de son calcul est donné.\n",
    "Le premier sous-score n'a accordé un score que par rapport au premier mot (noix), tandis que le second a accordé un score sur la base des deux mots déjà connu dans les documents (\"noix\" et \"de\"). Il a ignoré pécan! Jusqu'à présent, ce terme n'est pas connu dans l'index. \n",
    "\n",
    "La pertinence d'un mot pour notre recherche est construite sur une variante de la TF-IDF,\n",
    "considérant qu'un terme est pertinent s'il est souvent présent dans le document (Term Frequency)\n",
    "alors qu'il est peu fréquent dans les autres document (inverse document frequency).\n",
    "Ici les notations des documents 1 et 2 sont très proches, la différence est dûe à des IDF plus faibles dans le document 1,\n",
    "qui est pénalisé pour être légérement plus long. \n",
    "\n",
    "Bref, tout ça est un peu lourd, mais assez efficace, en tout cas moins rudimentaire que les distances caractères à caractères pour ramener des echos pertinents.\n",
    "\n",
    "\n",
    "## Limite de cette première indexation\n",
    "\n",
    "Pour l'instant, Elastic n'a pas l'air de gérer les fautes de frappes!\n",
    "Pas le droit à l'erreur dans la requête:\n",
    "\n",
    "~~~python\n",
    "es.search(index = 'openfood',q = 'TART NOI')\n",
    "~~~\n",
    "\n",
    "```\n",
    "{'took': 35, 'timed_out': False, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 0, 'relation': 'eq'}, 'max_score': None, 'hits': []}}\n",
    "```\n",
    "\n",
    "\n",
    "Cela s'explique par la représentation des champs (*'product_name'* par exemple) qu'Elastic a inféré, puisque nous n'avons rien spécifié.\n",
    "La représentation d'une variable conditionne la façon dont les champs sont analysés pour calculer la pertinence.\n",
    "Par exemple, regardons la représentation du champ `product_name`\n",
    "\n",
    "~~~python\n",
    "es.indices.get_field_mapping(index = 'openfood', fields = 'product_name')\n",
    "~~~\n",
    "\n",
    "```\n",
    "{'openfood': {'mappings': {'product_name': {'full_name': 'product_name', 'mapping': {'product_name': {'type': 'text'}}}}}}\n",
    "```\n",
    "\n",
    "Elastic a compris qu'il s'agissait d'un champ textuel. En revanche, le type est `keyword` n'autorise pas des analyses approximatives donc \n",
    "ne permet pas de tenir compte de fautes de frappes.\n",
    "Pour qu'un echo remonte, un des termes doit matcher exactement. Dommage !\n",
    "Mais c'est parce qu'on a utilisé le *mapping* par défaut.\n",
    "En réalité, il est assez simple de préciser un *mapping* plus riche, autorisant une analyse *\"fuzzy\"* ou *\"flou\"*.\n",
    "\n",
    "# Améliorer l'indexation\n",
    "\n",
    "\n",
    "On peut spécifier la façon dont l'on souhaite analyser le texte.\n",
    "Par exemple, on peut préciser que l'on souhaite enlever des *stopwords*, raciniser, analyser les termes via des *n-grammes*\n",
    "pour rendre la recherche plus robuste aux fautes de frappes...\n",
    "\n",
    "Ces concepts sont présentés dans la partie [NLP](#nlp).\n",
    "Pour une présentation plus complète, voir\n",
    "[la documentation officielle d'Elastic](https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping.html)\n",
    "\n",
    "On propose les analyseurs stockés dans un fichier [schema.json](#schema.json)\n",
    "\n",
    "\n",
    "Les *n-grammes* sont des séquences de *n* caractères ou plus généralement *n* éléments qui s'enchaînent séquentiellement.\n",
    "Par exemple, NOI et OIX sont des tri-grammes de caractères dans NOIX. \n",
    "\n",
    "Comparer les n-grammes composant des libellés peut permettre d'avoir dans des comparaisons à fautes de frappe/abbréviations près.\n",
    "Cela fait aussi plus de comparaisons à opérer ! D'où également, l'intérêt d'Elastic, qui intégre facilement et efficacement ces comparaisons. \n",
    "\n",
    "\n",
    "On va préciser un peu le schéma de données qu'on souhaite _indexer_, et aussi préciser comment les différents champs seront _analysés_.\n",
    "\n",
    "\n",
    "### Une indexation plus adaptée\n",
    "\n",
    "~~~python\n",
    "import json\n",
    "\n",
    "if es.indices.exists('openfood'):\n",
    "    es.indices.delete('openfood')\n",
    "\n",
    "with open('schema.json') as f:\n",
    "    mapping = json.load(f)\n",
    "    \n",
    "es.indices.create(index = \"openfood\", body = mapping)    \n",
    "~~~\n",
    "\n",
    "Maintenant, les champs textuels *\"product_name\"* et *\"product_name_clean\"*\n",
    "vont pouvoir être analysé aussi via leur n-grammes et après racinisation (et l'un n'exclut pas l'autre!)\n",
    "\n",
    "~~~python\n",
    "es.indices.get_field_mapping(index = 'openfood', fields = 'product_name')\n",
    "~~~\n",
    "\n",
    "```\n",
    "{'openfood': {'mappings': {'product_name': {'full_name': 'product_name', 'mapping': {'product_name': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}, 'ngr': {'type': 'text', 'analyzer': 'ngram_analyzer'}, 'stem': {'type': 'text', 'analyzer': 'stem_analyzer'}}}}}}}}\n",
    "```\n",
    "\n",
    "C'est parti, on envoie toute notre base OpenFood pour pouvoir la requêter ! La fonction suivante (`index_elastic`) va vous faire gagner du temps pour indexer\n",
    "car indexer chaque produit à la main n'est pas très efficace.\n",
    "\n",
    "Du coup ça prend quelques minutes ... mais c'est pour nous en faire gagner ensuite. Cette opération est faite une fois, pour préparer des requêtes potentiellement nombreuses!\n",
    "\n",
    "~~~python\n",
    "fc.index_elastic(es =es, index_name = \"openfood\",\n",
    "        setting_file = 'schema.json',\n",
    "        df = openfood[['product_name',\"libel_clean\",\"energy_100g\",\"nutriscore_score\"]].drop_duplicates())\n",
    "~~~\n",
    "\n",
    "```\n",
    "Temps d'exécution total : 263.11 secondes ---\n",
    "```\n",
    "\n",
    "~~~python\n",
    "es.count(index = 'openfood')\n",
    "~~~\n",
    "\n",
    "```\n",
    "{'count': 630727, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}}\n",
    "```\n",
    "\n",
    "\n",
    "## Nos premières requêtes\n",
    "\n",
    "Vérifions qu'on recupère quelques tartes aux noix même si l'on fait plein de fautes:\n",
    "\n",
    "~~~python\n",
    "es.search(index = 'openfood', q = 'TART NOI', size = 3)\n",
    "~~~\n",
    "\n",
    "```\n",
    "{'took': 4201, 'timed_out': False, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 10000, 'relation': 'gte'}, 'max_score': 22.765423, 'hits': [{'_index': 'openfood', '_type': '_doc', '_id': '307496', '_score': 22.765423, '_source': {'product_name': 'Tarte noix', 'libel_clean': 'TARTE NOIX', 'energy_100g': 1833.0, 'nutriscore_score': 23.0}}, {'_index': 'openfood', '_type': '_doc', '_id': '825159', '_score': 22.277456, '_source': {'product_name': 'Tarte aux noix', 'libel_clean': 'TARTE AUX NOIX', 'energy_100g': 4.0, 'nutriscore_score': 4.0}}, {'_index': 'openfood', '_type': '_doc', '_id': '867887', '_score': 22.277456, '_source': {'product_name': 'Tarte aux noix', 'libel_clean': 'TARTE AUX NOIX', 'energy_100g': 1929.0, 'nutriscore_score': 21.0}}]}}\n",
    "```\n",
    "\n",
    "Pour automatiser cette approche, on peut définir  la fonctioin suivante\n",
    "\n",
    "```python\n",
    "def matchElastic(libelles):\n",
    "    matches = dict()\n",
    "    start_time = time.time()\n",
    "    for l in libelles:\n",
    "        response = es.search(index = 'openfood', q = l, size = 1)\n",
    "        if len(response['hits']['hits'])>0:\n",
    "            matches[l] = response['hits']['hits'][0]['_source']['libel_clean']\n",
    "    print(80*'-')\n",
    "    print(f\"Temps d'exécution total : {(time.time() - start_time):.2f} secondes ---\")\n",
    "    \n",
    "    return matches\n",
    "```\n",
    "\n",
    "```python\n",
    "matches = matchElastic(courses['libel_clean'])\n",
    "pd.DataFrame.from_dict(matches, orient='index')\n",
    "```\n",
    "\n",
    "Et voilà, on a un outil très rapide de requête ! \n",
    "Maintenant, on peut préciser des requêtes plus sophistiquées![^2]\n",
    "\n",
    "[^2]: Vous pouvez aussi explorer les possibilités de requêtes via la [doc Elastic](https://www.elastic.co/guide/en/elasticsearch/reference/6.8/query-dsl.html) et vous entrainer à un écrire avec votre index tout neuf.\n",
    "\n",
    "\n",
    "```python\n",
    "body = '''\n",
    "{\n",
    "  \"size\": \"1\",\n",
    "  \"query\": {\n",
    "    \"bool\": {\n",
    "      \"should\": [\n",
    "        { \"match\": { \"libel_clean\":  { \"query\":  \"HUILE OLIVE\" , \"boost\" : 10}}},\n",
    "        { \"match\": { \"libel_clean.ngr\":   \"HUILE OLIVE\" }}],\n",
    "      \"minimum_should_match\": 1,\n",
    "      \"filter\": [\n",
    "      { \n",
    "            \"range\" : {\n",
    "                \"nutriscore_score\" : {\n",
    "                    \"gte\" : 10,\n",
    "                    \"lte\" : 20\n",
    "                    }\n",
    "                    }\n",
    "                    }\n",
    "      ]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "'''\n",
    "```\n",
    "\n",
    "~~~python\n",
    "es.search(index = 'openfood', body = body)\n",
    "~~~\n",
    "\n",
    "```\n",
    "{'took': 10322, 'timed_out': False, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 10000, 'relation': 'gte'}, 'max_score': 174.37657, 'hits': [{'_index': 'openfood', '_type': '_doc', '_id': '693544', '_score': 174.37657, '_source': {'product_name': 'Huile d olive', 'libel_clean': 'HUILE OLIVE', 'energy_100g': 3761.0, 'nutriscore_score': 11.0}}]}}\n",
    "```\n",
    "\n",
    "\n",
    "Qu'a-t-on demandé ici? De renvoyer 1 et 1 seul echo (`\"size\":\"1\"`) et seulement si celui ci a:\n",
    "* `\"should\"`: Au moins un (`\"minimum_should_match\":\"1\"`) des termes des deux champs `libel_clean` et `libel_clean.ngr` qui matche sur un terme de _HUILE OLIVE_, l'analyse (la définition du \"terme\") étant réalisé soit en tant que `text` (\"libel_clean\") soit en tant que n-gramme `ngr` (\"libel_clean.ngr\", une analyse que nous avons spécifié dans le mapping) \n",
    "* `\"filter\"`: Le champ `float` nutriscore_score doit être compris entre 10 et 20 (\"filter\").  \n",
    "\n",
    "A noter :\n",
    "\n",
    "1. Les clauses (`\"should\"`+`\"minimum_should_match\":\"1\"`) peuvent être remplacé par un `\"must\"`, auquel cas, l'echo doit obligatoirement matcher sur chaque clause.\n",
    "2. Préciser dans `\"filter\"` (plutôt que dans \"`should`\") une condition signifie que celle-ci ne participe pas au score de pertinence. \n",
    "\n",
    "\n",
    "On n'a pas encore un appariemment très satisfaisant, en particulier sur les boissons. Comment faire ? La réponse sera dans Galiana et al. (à venir)\n",
    "\n",
    "A vous, de calculer le nombre de calories de notre recette de course ! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
