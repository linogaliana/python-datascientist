{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Intégration continue et MLops avec Python\n",
        "\n",
        "L’un des apports principaux des innovations\n",
        "récentes de la *data-science* est la\n",
        "manière dont des projets, malgré\n",
        "leur complexité, peuvent facilement\n",
        "être converti en projets pérennes\n",
        "à partir\n",
        "d’un prototype bien construit.\n",
        "En s’inspirant de l’approche `devops` ,\n",
        "méthode de travail qui consiste à adopter un certain\n",
        "nombre de gestes pour\n",
        "automatiser la production de livrables ou de tests\n",
        "dès la\n",
        "conception du produit, les *data-scientists*\n",
        "ont adopté une méthode de travail très efficace\n",
        "pour favoriser la réutilisation de leur travail\n",
        "par d’autres équipes que celles à l’origine de\n",
        "la conception du protype initial.\n",
        "\n",
        "Cette approche `devops` a été reprise et étendue\n",
        "pour donner un autre buzz-word, le `MLops`.\n",
        "Il s’agit d’une approche qui vise à créer\n",
        "et mettre à disposition des modèles de machine\n",
        "learning de manière fiable et automatisée\n",
        "à chaque nouvelle étape du projet, en parallèle\n",
        "de la mise à jour du code ayant produit ces\n",
        "output.\n",
        "\n",
        "Ces nouvelles méthodes de travail permettent\n",
        "des gains substantiels de productivité\n",
        "pour les équipes développant des modèles\n",
        "et réduit fortement le coût de reprise d’un\n",
        "code par une équipe en charge de sa\n",
        "pérenisation. Ce coût est en effet le principal\n",
        "frein à la mise en production de nouveaux\n",
        "projets ce qui peut représenter un gâchis\n",
        "non négligeable de temps et de ressources.\n",
        "Comme nous l’expliquons avec Romain Avouac\n",
        "dans un cours de dernière année de l’ENSAE\n",
        "(https://ensae-reproductibilite.netlify.app/),\n",
        "l’adoption de certaines bonnes pratiques\n",
        "de développement de code et d’une démarche\n",
        "exploitant les dernières innovations de\n",
        "la *data-science* peut substantiellement\n",
        "augmenter les chances d’un succès\n",
        "d’un projet. Le nouveau paradigme, qui\n",
        "consiste à intégrer en amont du projet\n",
        "certaines contraintes de la production\n",
        "et tester continuellement la manière dont les\n",
        "livrables évoluent, évite que la mise\n",
        "en production d’un projet, qui est coûteuse\n",
        "en temps et en ressources, n’aboutisse qu’au\n",
        "moment où le projet est déjà caduc\n",
        "(car les données ou les besoins ont évolués…).\n",
        "\n",
        "# L’intégration continue: une opportunité pour les *data-scientists*\n",
        "\n",
        "On retrouve régulièrement l’acronyme CI/CD\n",
        "pour illustrer cette\n",
        "nouvelle méthode de travail dans le\n",
        "monde du développement logiciel :\n",
        "\n",
        "-   l’intégration continue (CI pour\n",
        "    *continuous integration*)\n",
        "    est une pratique consistant, de manière automatique,\n",
        "    à fréquemment tester les effets d’une modification faite à un code ou à un\n",
        "    document faisant parti d’un projet informatique.\n",
        "\n",
        "-   le déploiement en continu (CD pour *continuous\n",
        "    delivery*) consiste à intégrer de manière automatisée\n",
        "    la production d’un ou plusieurs livrables (environnement\n",
        "    portable, application, site web, etc.) à chaque\n",
        "    modification du code associé à un projet informatique.\n",
        "\n",
        "Cette pratique permet ainsi de détecter de manière précoce des possibilités\n",
        "de *bug* ou l’introduction d’un changement non anticipé. Tout comme `Git`,\n",
        "cette pratique devient un standard dans les domaines collaboratifs.\n",
        "\n",
        "L’intégration continue permet de sécuriser le travail, puisqu’elle offre un\n",
        "filet de sécurité (par exemple un test sur une machine à la configuration\n",
        "arbitraire), mais permet aussi de déployer en temps réel certaines\n",
        "évolutions. On parle parfois de déploiement en continu, complémentaire de\n",
        "l’intégration continue. Cette approche réduit ainsi\n",
        "la muraille de Chine entre un\n",
        "analyste de données et une équipe de développeurs d’application. Elle offre donc\n",
        "plus de contrôle, pour le producteur d’une analyse statistique, sur la\n",
        "valorisation de celle-ci.\n",
        "\n",
        "Cette approche consiste une excellente opportunité\n",
        "pour les *data-scientists* d’être en mesure\n",
        "de valoriser leurs projets auprès de publics aux\n",
        "exigences différentes. Pour des développeurs, le\n",
        "*data-scientist* pourra fournir une image `Docker`\n",
        "(environnement portable où l’ensemble des dépendances\n",
        "et des configurations systèmes pour faire tourner un code\n",
        "sont contrôlés) permettant à d’autres d’exécuter\n",
        "facilement le code d’un projet. Pour faciliter\n",
        "la réutilisation d’un modèle par d’autres *data-scientists*,\n",
        "il devient de plus en plus fréquent d’exposer\n",
        "un modèle sous forme d’API: les personnes désirant\n",
        "réutiliser le modèle peuvent directement l’appliquer\n",
        "en accédant à une prédiction par le biais d’une API\n",
        "ce qui évite d’avoir à fournir le jeu d’entraînement\n",
        "si ce dernier est sensible. Pour toucher\n",
        "des publics moins\n",
        "familiers du code, la mise à disposition de sites web\n",
        "interactifs valorisant certains résultats d’un projet\n",
        "peut être intéressante. Cette approche très exigeante\n",
        "d’utiliser un même projet pour toucher des cibles\n",
        "très différentes est grandement facilitée par le\n",
        "déploiement en continu et la mise à disposition\n",
        "de librairies ou d’infrastructures\n",
        "dédiées dans le monde de l’*open-source*.\n",
        "\n",
        "Tout en restant éco-responsable (voir partie XXX), cela\n",
        "permet de mieux valoriser des projets pour réduire\n",
        "les coûts à le maintenir et le faire évoluer.\n",
        "Le cours de dernière année de l’ENSAE que je développe\n",
        "avec Romain Avouac (https://ensae-reproductibilite.netlify.app/)\n",
        "présente beaucoup plus de détails sur cette question.\n",
        "\n",
        "# L’intégration continue en pratique\n",
        "\n",
        "L’intégration continue fonctionne très bien sur `Gitlab` et sur `Github`.\n",
        "A chaque interaction avec le dépôt distant (`push`), une série d’instruction\n",
        "définie par l’utilisateur est exécutée. `Python` et `R` s’intègrent très bien dans ce paradigme grâce\n",
        "à un certain nombre d’images de base (concept sur lequel nous allons revenir)\n",
        "qui peuvent être customisées pour répondre à une certaine configuration\n",
        "nécessaire pour exécuter des codes\n",
        "([voir ici pour quelques éléments sur R](https://linogaliana.gitlab.io/collaboratif/package.html#utiliser-lint%C3%A9gration-continue-de-gitlab).\n",
        "C’est une méthode idéale pour améliorer la reproductibilité d’un projet: les\n",
        "instructions exécutées le sont dans un environnement isolé et contrôlé, ce qui\n",
        "diffère d’une machine personnelle.\n",
        "\n",
        "# Comment fonctionne l’intégration continue ?\n",
        "\n",
        "L’intégration continue repose sur le système de la *dockerisation* ou *conteneurisation*.\n",
        "La technologie sous jacente s’appelle `Docker`.\n",
        "Il s’agit d’une technologie qui permet la construction\n",
        "de machines autosuffisantes\n",
        "(que l’on nomme **containeurs**) répliquant un environnement\n",
        "contrôlé (que l’on nomme **image**).\n",
        "\n",
        "On parle de *pipelines* pour désigner une suite de tâches pour partir de 0\n",
        "(généralement une machine `Linux` à la configuration minimale) et aboutir\n",
        "à l’issue d’une série d’instructions définies par l’utilisateur.\n",
        "\n",
        "L’objectif est de trouver une image la plus\n",
        "parcimonieuse possible, c’est-à-dire à la configuration minimale, qui permet\n",
        "de faire tourner le code voulu.\n",
        "Les [Actions Github](https://docs.github.com/en/actions/automating-builds-and-tests/building-and-testing-python)\n",
        "consistuent un modèle sur lequel il est facile\n",
        "de s’appuyer lorsqu’on a des connaissances limitées\n",
        "concernant \\`Docker.\n",
        "Il est également très simple de construire son image\n",
        "de rien, ce qui est la démarche choisie dans\n",
        "l’autre cours de l’ENSAE que nous donnons avec Romain\n",
        "Avouac (https://ensae-reproductibilite.netlify.app/).\n",
        "\n",
        "Quand on utilise un dépôt `Github` <i class=\"fa-brands fa-github\"></i>\n",
        "ou `Gitlab` <i class=\"fa-brands fa-gitlab\"></i>,\n",
        "des services automatiques\n",
        "d’intégration continue peuvent être utilisés:\n",
        "\n",
        "-   `Gitlab CI`: solution pleinement intégrée à un dépôt `Gitlab`. Très généraliste\n",
        "    et permettant des *pipelines* très complexes\n",
        "    ([voir l’intégration continue du projet utilitR, une documentation pour R](https://gitlab.com/linogaliana/documentationR/-/blob/master/.gitlab-ci.yml)).\n",
        "    Il est également possible de\n",
        "    l’utiliser avec un dépôt stocké sur `Github`. L’inconvénient de cette approche\n",
        "    est qu’elle est assez lente.\n",
        "-   `Github Actions`: c’est l’alternative (relativement récente) au service d’intégration continue de\n",
        "    Gitlab uniquement basée sur les technologies `Github`. La très forte\n",
        "    dynamique de développement a rendu ce service incontournable.\n",
        "    Un grand nombre de scripts pré-définis et paramétrables\n",
        "    facilitent l’entrée dans le monde de l’intégration\n",
        "    continue.\n",
        "\n",
        "Historiquement, il existait d’autres services d’intégration continue, notamment\n",
        "`Travis CI` ou `AppVeyor`[1]\n",
        "\n",
        "## Fonctionnement des actions Github\n",
        "\n",
        "Les actions `Github` fonctionnent par couches successives au sein desquelles\n",
        "on effectue un certain nombre d’instructions.\n",
        "La meilleure manière d’apprendre les actions `Github` est, certes, de [lire la\n",
        "documentation officielle](https://docs.github.com/en/actions) mais surtout,\n",
        "à mon avis, de regarder quelques *pipelines* pour comprendre la démarche.\n",
        "\n",
        "L’un des intérêts des `Github Actions` est la possibilité d’avoir un *pipeline*\n",
        "proposant une intrication de langages différents pour avoir une chaine de\n",
        "production qui propose les outils les plus efficaces pour répondre à un\n",
        "objectif en limitant les verrous techniques.\n",
        "\n",
        "Par exemple, le *pipeline* de ce cours, disponible\n",
        "sur `Github`\n",
        "\n",
        "{{\\< githubrepo \\>}}\n",
        "\n",
        "propose une intrication des langages\n",
        "`Python` et `R` avec des technologies `Anaconda` (pour contrôler\n",
        "l’environnement `Python` comme expliqué dans les chapitres précédents)\n",
        "et `Javascript` (pour le déploiement d’un site web avec le service tiers\n",
        "`Netlify`)[2]. Cette chaîne de production multi-langage permet que\n",
        "les mêmes fichiers sources génèrent un site web et des notebooks disponibles\n",
        "sur plusieurs environnements.\n",
        "\n",
        "b’name: Docker Build and Website Deploy:push:branches:- main- master:blogdown:name: Render-Blogruns-on: ubuntu-latestcontainer: linogaliana/python-datascientist-vstudio:quartosteps:- uses: actions/checkout@v2with:submodules: truefetch-depth: 0ref: \\${{ github.event.pull_request.head.ref }}repository: \\${{github.event.pull_request.head.repo.full_name}}- name: Configure safe.directory \\# Workaround for actions/checkout#760run: git config –global –add safe.directory /\\_\\_w/python-datascientist/python-datascientist- shell: bashrun: \\|conda infoconda list- name: Build to mdrun: \\|quarto render –to hugomv content/course/manipulation/index.md content/course/manipulation/\\_index.mdmv content/course/visualisation/index.md content/course/visualisation/\\_index.mdmv content/course/modelisation/index.md content/course/modelisation/\\_index.mdmv content/course/index.md content/course/\\_index.mdpython build/wc_website.pypython build/tweak_markdown.pyhugo mod graphhugo -D –themesDir themes -t github.com- name: Install npmuses: actions/setup-node@v2 with:node-version: '12' - name: Deploy to Netlify\\# NETLIFY_AUTH_TOKEN and NETLIFY_SITE_ID added in the repo's secretsenv:NETLIFY_AUTH_TOKEN: \\${{ secrets.NETLIFY_AUTH_TOKEN }}NETLIFY_SITE_ID: \\${{ secrets.NETLIFY_SITE_ID }}BRANCHE_REF: \\${{ github.event.pull_request.head.ref }}run: \\|npm init -ynpm install –unsafe-perm=true netlify-cli -gnetlify initnetlify deploy –prod –dir=“public” –message “Deploy master”- uses: actions/upload-artifact@v1with:name: publicpath: public/’\n",
        "\n",
        "Les couches qui constituent les étapes du *pipeline*\n",
        "portent ainsi le nom de `steps`. Un *step* peut comporter un certain\n",
        "nombre d’instructions ou exécuter des instructions pré-définies.\n",
        "L’une de ces instructions prédéfinies est, par exemple,\n",
        "l’[installation de Python](https://github.com/actions/setup-python)\n",
        "ou l’[initialisation d’un environnement conda](https://github.com/marketplace/actions/setup-miniconda).\n",
        "La documentation officielle de `Github` propose un\n",
        "[fichier qui peut servir de modèle](https://docs.github.com/en/actions/automating-builds-and-tests/building-and-testing-nodejs-or-python?langId=py)\n",
        "pour tester un script `Python` voire l’uploader de manière automatique\n",
        "sur `Pypi`.\n",
        "\n",
        "## Intégration continue avec `Python`: tester un notebook\n",
        "\n",
        "Cette section n’est absolument pas exhaustive. Au contraire, elle ne fournit\n",
        "qu’un exemple minimal pour expliquer la logique de l’intégration continue. Il\n",
        "ne s’agit ainsi pas d’une garantie absolue de reproductibilité d’un *notebook*.\n",
        "\n",
        "`Github` propose une action officielle pour utiliser `Python` dans un\n",
        "*pipeline* d’intégration continue. Elle est disponible sur le\n",
        "[MarketPlace Github](https://github.com/marketplace/actions/setup-python).\n",
        "Il s’agit d’un bon point de départ, à enrichir.\n",
        "\n",
        "Le fichier qui contrôle les instructions exécutées dans l’environnement `Actions`\n",
        "doit se trouver dans le dossier `.github/workflows/`\n",
        "(:warning: ne pas oublier le point au début du\n",
        "nom du dossier). Il doit être au format `YAML` avec une extension `.yml`.\n",
        "Il peut avoir n’importe quel nom mais mieux vaut lui donner un nom signifiant,\n",
        "par exemple `prod.yml` pour un fichier contrôlant une chaîne de production.\n",
        "\n",
        "### Lister les dépendances\n",
        "\n",
        "Avant d’écrire les instructions à exécuter par `Github`, il faut définir un\n",
        "environnement d’exécution car `Github` ne connaît pas la configuration `Python`\n",
        "dont vous avez besoin.\n",
        "\n",
        "Il convient ainsi de lister les dépendances nécessaires dans un fichier\n",
        "`requirements.txt`, comme expliqué dans la partie\n",
        "[Bonnes pratiques](#bonnespratiques), ou un fichier `environment.yml`.\n",
        "Ce fichier fait la liste des dépendances à installer.\n",
        "Si on fait le choix de l’option `environment.yml`,\n",
        "le fichier prendra ainsi la forme\n",
        "suivante:\n",
        "\n",
        "``` yaml\n",
        "channels:\n",
        "  - conda-forge\n",
        "\n",
        "dependencies:\n",
        "  - python\n",
        "  - jupyter\n",
        "  - jupytext\n",
        "  - matplotlib\n",
        "  - nbconvert\n",
        "  - numpy\n",
        "  - pandas\n",
        "  - scipy\n",
        "  - seaborn\n",
        "```\n",
        "\n",
        "Le choix du *channel* `conda-forge` vise à contrôler le dépôt utilisé par\n",
        "`Anaconda`.\n",
        "\n",
        "Ne pas oublier de mettre ce fichier sous contrôle de version et de l’envoyer\n",
        "sur le dépôt par un `push`.\n",
        "\n",
        "### Tester un notebook `myfile.ipynb`\n",
        "\n",
        "Dans cette partie, on va supposer que le *notebook* à tester s’appelle `myfile.ipynb`\n",
        "et se trouve à la racine du dépôt.\n",
        "\n",
        "Le modèle suivant, expliqué en dessous, fournit un modèle de recette pour\n",
        "tester un notebook:\n",
        "\n",
        "TO BE COMPLETED\n",
        "\n",
        "## Annexe: la même approche avec `Travis`\n",
        "\n",
        "``` shell\n",
        "# Modèle de fichier .travis.yml\n",
        "language: python\n",
        "python:\n",
        "  - \"3.7\"\n",
        "\n",
        "install:\n",
        "  - sudo apt-get update\n",
        "  # We do this conditionally because it saves us some downloading if the\n",
        "  # version is the same.\n",
        "  - if [[ \"$TRAVIS_PYTHON_VERSION\" == \"2.7\" ]]; then\n",
        "      wget https://repo.continuum.io/miniconda/Miniconda2-latest-Linux-x86_64.sh -O miniconda.sh;\n",
        "    else\n",
        "      wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh;\n",
        "    fi\n",
        "  - bash miniconda.sh -b -p $HOME/miniconda\n",
        "  - export PATH=\"$HOME/miniconda/bin:$PATH\"\n",
        "  - hash -r\n",
        "  - conda config --set always_yes yes --set changeps1 no\n",
        "  - conda update -q conda\n",
        "  # Useful for debugging any issues with conda\n",
        "  - conda info -a\n",
        "  - conda env create -n test-environment python=$TRAVIS_PYTHON_VERSION -f environment.yml\n",
        "  - source activate test-environment\n",
        "\n",
        "script:\n",
        "  - jupytext --to py --execute myfile.ipynb\n",
        "```\n",
        "\n",
        "### Explications\n",
        "\n",
        "Les lignes:\n",
        "\n",
        "``` shell\n",
        "language: python\n",
        "python:\n",
        "  - \"3.7\"\n",
        "```\n",
        "\n",
        "définissent la version de Python qui sera utilisée. Cependant, il convient\n",
        "d’installer `Anaconda` (en fait une version minimaliste d’`Anaconda` nommée\n",
        "`Miniconda`) ainsi que configurer la machine pour utiliser Anaconda plutôt\n",
        "que la version de base de `Python`. Ce sont les lignes suivantes\n",
        "qui contrôlent ces opérations:\n",
        "\n",
        "``` yaml\n",
        "install:\n",
        "  - sudo apt-get update\n",
        "  # We do this conditionally because it saves us some downloading if the\n",
        "  # version is the same.\n",
        "  - if [[ \"$TRAVIS_PYTHON_VERSION\" == \"2.7\" ]]; then\n",
        "      wget https://repo.continuum.io/miniconda/Miniconda2-latest-Linux-x86_64.sh -O miniconda.sh;\n",
        "    else\n",
        "      wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh;\n",
        "    fi\n",
        "  - bash miniconda.sh -b -p $HOME/miniconda\n",
        "  - export PATH=\"$HOME/miniconda/bin:$PATH\"\n",
        "  - hash -r\n",
        "  - conda config --set always_yes yes --set changeps1 no\n",
        "  - conda update -q conda\n",
        "  # Useful for debugging any issues with conda\n",
        "  - conda info -a\n",
        "```\n",
        "\n",
        "Enfin, le reste de la tâche `install` est consacrée à la construction d’un\n",
        "environnement Anaconda cohérent avec les packages définis dans `environment.yml`:\n",
        "\n",
        "``` yaml\n",
        "- conda env create -n test-environment python=$TRAVIS_PYTHON_VERSION -f environment.yml\n",
        "- source activate test-environment\n",
        "```\n",
        "\n",
        "Tout cela permet de construire un conteneur qui a vocation à être suffisant\n",
        "pour exécuter `myfile.ipynb`. C’est l’objet de la tâche `script`:\n",
        "\n",
        "``` yaml\n",
        "script:\n",
        "  - jupytext --to py --execute myfile.ipynb\n",
        "```\n",
        "\n",
        "`jupytext` est une extension de `jupyter` qui fournit des éléments pour passer d’un\n",
        "notebook à un autre format. En l’occurrence, il s’agit de convertir\n",
        "un *notebook* en\n",
        "script `.py` et l’exécuter. Ce test pourrait également être fait en n’utilisant\n",
        "que `Jupyter`:\n",
        "\n",
        "``` yaml\n",
        "script:\n",
        "  - jupyter nbconvert --to notebook --execute --inplace myfile.ipynb\n",
        "```\n",
        "\n",
        "# Références\n",
        "\n",
        "-   https://ensae-reproductibilite.netlify.app/\n",
        "-   https://towardsdatascience.com/from-jupyter-to-kubernetes-refactoring-and-deploying-notebooks-using-open-source-tools-19f99585e923\n",
        "\n",
        "[1] Ces services d’intégration continue étaient utilisés lorsque `Github`\n",
        "ne proposait pas encore de service intégré, comme le faisait `Gitlab`.\n",
        "Ils sont de moins en moins fréquemment utilisés.\n",
        "\n",
        "[2] Pour réduire le temps nécessaire pour construire le site *web*, ce\n",
        "*pipeline* s’appuie sur un environnement `Docker` construit sur un autre dépôt\n",
        "disponible également sur `Github`\n",
        "<a href=\"https://github.com/linogaliana/python-datascientist-docker/blob/master/.github/workflows/prod.yml\" class=\"github\"><i class=\"fab fa-github\"></i></a>.\n",
        "Celui-ci part d’une configuration système `Linux` et construit un environnement\n",
        "`Anaconda` à partir d’un fichier `environment.yml` qui liste toutes les dépendances\n",
        "nécessaires pour exécuter les morceaux de code du site *web*.\n",
        "Cet environnement `Anaconda` est construit grâce à l’outil `mamba` qui permet\n",
        "d’aller beaucoup plus vite dans la constitution d’environnements que ne le\n",
        "permet `conda`."
      ],
      "id": "fc09efe6-709f-4f5d-8f8b-517502a708a7"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  }
}