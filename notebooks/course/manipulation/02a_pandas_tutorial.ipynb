{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "508056c0",
   "metadata": {},
   "source": [
    "#  Introduction à pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28efa105",
   "metadata": {},
   "source": [
    "Pour visualiser le [TP associé à ce tutoriel](pandasTP) : \n",
    "<!---- reminder_badges(\"content/manipulation/02_pandas_tp.ipynb\") --->\n",
    "<a href=\"https://github.com/linogaliana/python-datascientist/blob/master/content/manipulation/notebooks/02_pandas_tp.ipynb\" class=\"github\"><i class=\"fab fa-github\"></i></a>\n",
    "[![nbviewer](https://img.shields.io/badge/visualize-nbviewer-blue)](https://nbviewer.jupyter.org/github/linogaliana/python-datascientist/blob/master/content/manipulation/notebooks/02_pandas_tp.ipynb)\n",
    "[![Onyxia](https://img.shields.io/badge/SSPcloud-Tester%20via%20SSP--cloud-informational&color=yellow?logo=Python)](https://datalab.sspcloud.fr/launcher/inseefrlab-helm-charts-datascience/jupyter?onyxia.friendlyName=%C2%ABpython-datascientist%C2%BB&resources.requests.memory=%C2%AB4Gi%C2%BB)\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/linogaliana/python-datascientist/master?filepath=content/manipulation/notebooks/02_pandas_tp.ipynb)\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/github/linogaliana/python-datascientist/blob/master/content/manipulation/notebooks/02_pandas_tp.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e3a53c",
   "metadata": {},
   "source": [
    "Dans ce tutoriel `pandas`, nous allons utiliser:\n",
    "\n",
    "* Les émissions de gaz à effet de serre estimées au niveau communal par l'ADEME. Le jeu de données est \n",
    "disponible sur [data.gouv](https://www.data.gouv.fr/fr/datasets/inventaire-de-gaz-a-effet-de-serre-territorialise/#_)\n",
    "et requêtable directement dans python avec\n",
    "[cet url](https://koumoul.com/s/data-fair/api/v1/datasets/igt-pouvoir-de-rechauffement-global/convert)\n",
    "* Quelques données de contexte au niveau communal. Idéalement, on utiliserait les données\n",
    "[disponibles sur le site de l'Insee](https://www.insee.fr/fr/statistiques/3560121). Pour faciliter l'import de celles-ci, les données ont été mises à disposition dans le dépôt github, [sur cet url](https://github.com/linogaliana/python-datascientist/blob/pandas_intro/data/filosofi_2016.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4fd9a8",
   "metadata": {},
   "source": [
    ":warning: `pandas` offre la possibilité d'importer des données\n",
    "directement depuis un url. C'est l'option prise dans ce tutoriel.\n",
    "Si vous préfèrez, pour des\n",
    "raisons d'accès au réseau ou de performance, importer depuis un poste local,\n",
    "vous pouvez télécharger les données et changer\n",
    "les commandes d'import avec le chemin adéquat plutôt que l'url. \n",
    "\n",
    "Nous suivrons les conventions habituelles dans l'import des packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac377a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7347785",
   "metadata": {},
   "source": [
    "Pour obtenir des résultats reproductibles, on peut fixer la racine du générateur\n",
    "pseudo-aléatoire. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127c093e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312e2728",
   "metadata": {},
   "source": [
    "Au cours de cette démonstration des principales fonctionalités de `pandas`, et\n",
    "lors du TP\n",
    "[![Onyxia](https://img.shields.io/badge/SSPcloud-Tester%20via%20SSP--cloud-informational&color=yellow?logo=Python)](https://datalab.sspcloud.fr/launcher/inseefrlab-helm-charts-datascience/jupyter?onyxia.friendlyName=%C2%ABpython-datascientist%C2%BB&resources.requests.memory=%C2%AB4Gi%C2%BB)\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/linogaliana/python-datascientist/master?filepath=content/manipulation/notebooks/02_pandas_tp.ipynb)\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/github/linogaliana/python-datascientist/blob/master/content/manipulation/notebooks/02_pandas_tp.ipynb)\n",
    "\n",
    ",\n",
    "je recommande de se référer régulièrement aux ressources suivantes:\n",
    "\n",
    "* L'[aide officielle de pandas](https://pandas.pydata.org/docs/user_guide/index.html).\n",
    "Notamment, la\n",
    "[page de comparaison des langages](https://pandas.pydata.org/pandas-docs/stable/getting_started/comparison/index.html)\n",
    "est très utile\n",
    "* La cheatsheet suivante, [issue de ce post](https://becominghuman.ai/cheat-sheets-for-ai-neural-networks-machine-learning-deep-learning-big-data-678c51b4b463)\n",
    "\n",
    "![Cheasheet pandas](https://cdn-images-1.medium.com/max/2000/1*YhTbz8b8Svi22wNVvqzneg.jpeg)\n",
    "\n",
    "# Logique de pandas\n",
    "\n",
    "L'objet central dans la logique `pandas` est le `DataFrame`.\n",
    "Il s'agit d'une structure particulière de données\n",
    "à deux dimensions, structurées en alignant des lignes et colonnes. Les colonnes\n",
    "peuvent être de type différent.\n",
    "\n",
    "Un DataFrame est composé des éléments suivants:\n",
    "\n",
    "* l'indice de la ligne ;\n",
    "* le nom de la colonne ;\n",
    "* la valeur de la donnée ;\n",
    "\n",
    "Structuration d'un DataFrame pandas, emprunté à <https://medium.com/epfl-extension-school/selecting-data-from-a-pandas-dataframe-53917dc39953>:\n",
    "\n",
    "![](https://miro.medium.com/max/700/1*6p6nF4_5XpHgcrYRrLYVAw.png)\n",
    "\n",
    "Le concept de *tidy* data, popularisé par Hadley Wickham via ses packages `R`,\n",
    "est parfaitement pertinent pour décrire la structure d'un DataFrame pandas.\n",
    "Les trois règles sont les suivantes:\n",
    "\n",
    "* Chaque variable possède sa propre colonne\n",
    "* Chaque observation possède sa propre ligne\n",
    "* Une valeur, matérialisant la valeur d'une observation d'une variable,\n",
    "se trouve sur une unique cellule."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b0d678",
   "metadata": {},
   "source": [
    "![Concept de tidy data (emprunté à H. Wickham)](https://d33wubrfki0l68.cloudfront.net/6f1ddb544fc5c69a2478e444ab8112fb0eea23f8/91adc/images/tidy-1.png)\n",
    "\n",
    ":warning: Les DataFrames sont assez rapides en Python[^1] et permettent de traiter en local de manière efficace des tables de\n",
    "données comportant plusieurs millions d'observations (en fonction de la configuration de l'ordinateur)\n",
    "et dont la volumétrie peut être conséquente (plusieurs centaines\n",
    "de Mo). Néanmoins,  passé un certain seuil, qui dépend de la puissance de la machine mais aussi de la complexité\n",
    "de l'opération effectuée, le DataFrame `pandas` peut montrer certaines limites. Dans ce cas, il existe différentes\n",
    "solutions: `dask` (dataframe aux opérations parallélisés), `SQL` (notamment postgres), `spark` (solution big data)\n",
    "\n",
    "[^1]:  En `R`, les deux formes de dataframes qui se sont imposées récemment sont les `tibbles` (package `dplyr`)\n",
    "et les `data.tables` (package `data.table`). `dplyr` reprend la syntaxe SQL de manière relativement\n",
    "transparente ce qui rend la syntaxe très proche de celle de `pandas`. Cependant,\n",
    "alors que `dplyr` supporte très mal les données dont la volumétrie dépasse 1Go, `pandas` s'en\n",
    "accomode bien. Les performances de `pandas` sont plus proches de celles de `data.table`, qui est\n",
    "connu pour être une approche efficace avec des données de taille importante.\n",
    "\n",
    "Concernant la syntaxe, une partie des commandes python est inspirée par la logique SQL. On retrouvera ainsi\n",
    "des instructions relativement transparentes.\n",
    "\n",
    "Il est vivement recommandé, avant de se lancer dans l'écriture d'une\n",
    "fonction, de se poser la question de son implémentation native dans `numpy`, `pandas`, etc.\n",
    "En particulier, la plupart du temps, s'il existe une solution implémentée dans une librairie, il convient\n",
    "de l'utiliser.\n",
    "\n",
    "# Les Series\n",
    "\n",
    "En fait, un DataFrame est une collection d'objets appelés `pandas.Series`.\n",
    "Ces `Series` sont des objets d'une dimension qui sont des extensions des\n",
    "array-unidimensionnels `numpy`. En particulier, pour faciliter le traitement\n",
    "de données catégorielles ou temporelles, des types de variables\n",
    "supplémentaires sont disponibles dans `pandas` par rapport à\n",
    "`numpy` (`categorical`, `datetime64` et `timedelta64`). Ces\n",
    "types sont associés à des méthodes optimisées pour faciliter le traitement\n",
    "de ces données.\n",
    "\n",
    "Il ne faut pas négliger l'attribut `dtype` d'un objet\n",
    "`pandas.Series` car cela a une influence déterminante sur les méthodes\n",
    "et fonctions pouvant être utilisés (on ne fait pas les mêmes opérations\n",
    "sur une donnée temporelle et une donnée catégorielle) et le volume en\n",
    "mémoire d'une variable (le type de la variable détermine le volume\n",
    "d'information stocké pour chaque élément ; être trop précis est parfois\n",
    "néfaste).\n",
    "\n",
    "Il existe plusieurs types possibles pour un `pandas.Series`.\n",
    "Le type `object` correspond aux types Python `str` ou `mixed`.\n",
    "Il existe un type particulier pour les variables dont le nombre de valeurs\n",
    "est une liste finie et relativement courte, le type `category`.\n",
    "Il faut bien examiner les types de son DataFrame, et convertir éventuellement\n",
    "les types lors de l'étape de `data cleaning`.\n",
    "\n",
    "### Indexation\n",
    "\n",
    "La différence essentielle entre une `Series` et un objet `numpy` est l'indexation.\n",
    "Dans `numpy`,\n",
    "l'indexation est implicite ; elle permet d'accéder à une donnée (celle à\n",
    "l'index situé à la position *i*).\n",
    "Avec une `Series`, on peut bien-sûr utiliser un indice de position mais on peut\n",
    "surtout faire appel à des indices plus explicites.\n",
    "Par exemple,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ace0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "taille = pd.Series(\n",
    "    [1.,1.5,1],\n",
    "    index = ['chat', 'chien', 'koala']\n",
    ")\n",
    "\n",
    "taille.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00e82c6",
   "metadata": {},
   "source": [
    "```\n",
    "## chat     1.0\n",
    "## chien    1.5\n",
    "## koala    1.0\n",
    "## dtype: float64\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85fe7fc",
   "metadata": {},
   "source": [
    "Cette indexation permet d'accéder à des valeurs de la `Series`\n",
    "via une valeur de l'indice. Par\n",
    "exemple, `taille['koala']`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93b4cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "taille['koala']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974dd1df",
   "metadata": {},
   "source": [
    "```\n",
    "## 1.0\n",
    "```\n",
    "\n",
    "L'existence d'indice rend le *subsetting* particulièrement aisé, ce que vous\n",
    "pouvez expérimenter dans les TP\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/linogaliana/python-datascientist/master)\n",
    "[![Onyxia](https://img.shields.io/badge/SSPcloud-Tester%20via%20SSP--cloud-informational&color=yellow?logo=Python)](https://datalab.sspcloud.fr/launcher/inseefrlab-helm-charts-datascience/jupyter?onyxia.friendlyName=%C2%ABpython-datascientist%C2%BB&resources.requests.memory=%C2%AB4Gi%C2%BB)\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/github/linogaliana/python-datascientist/blob/pandas_intro/static/notebooks/numpy.ipynb)\n",
    " ([ou depuis github](https://github.com/linogaliana/python-datascientist/blob/master/content/01_data/02_pandas_tp.ipynb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5296bc34",
   "metadata": {},
   "source": [
    "Pour transformer un objet `pandas.Series` en array `numpy`,\n",
    "on utilise la méthode `values`. Par exemple, `taille.values`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e49ceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "taille.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce2361c",
   "metadata": {},
   "source": [
    "```\n",
    "## array([1. , 1.5, 1. ])\n",
    "```\n",
    "\n",
    "Un avantage des `Series` par rapport à un *array* `numpy` est que\n",
    "les opérations sur les `Series` alignent\n",
    "automatiquement les données à partir des labels.\n",
    "Avec des `Series` labélisées, il n'est ainsi pas nécessaire\n",
    "de se poser la question de l'ordre des lignes.\n",
    "L'exemple dans la partie suivante permettra de s'en assurer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3e64ac",
   "metadata": {},
   "source": [
    "### Valeurs manquantes\n",
    "\n",
    "Par défaut, les valeurs manquantes sont affichées `NaN` et sont de type `np.nan` (pour\n",
    "les valeurs temporelles, i.e. de type `datatime64`, les valeurs manquantes sont\n",
    "`NaT`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf5a778",
   "metadata": {},
   "source": [
    "<!-----\n",
    ":warning: Il faut **vraiment faire attention** aux valeurs manquantes, notamment lorsqu'on utilise les\n",
    "méthodes de statistiques descriptives présentées ultérieurement. Les règles sont les suivantes:\n",
    "\n",
    "* Dans les opérations de somme ou de moyenne d'une valeur, les valeurs manquantes\n",
    " sont traitées comme des `0`. C'est un comportement par défaut différent\n",
    " de celui de `R` où les opérations `sum`, `mean`, etc. renvoient un `NA`.\n",
    " __C'est très dangereux pour la moyenne__: la valeur n'est pas ignorée, elle est traitée comme un\n",
    " `0` (ce qui biaise la moyenne). Le paramètre crucial à changer pour\n",
    " ignorer la valeur (et non la remplacer par 0!) est `skipna` (cet argument\n",
    " permettant un comportement équivalent à `na.rm = TRUE` en `R`).\n",
    " Pour plus de détails, `help(pandas.Series.sum)`.\n",
    "* Les méthodes `cumsum` et `cumprod` ignorent les `NA` par défaut mais les préservent dans le vecteur de sortie.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff2c783",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [np.nan, np.arange(3)]\n",
    "np.mean(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601c5d93",
   "metadata": {},
   "source": [
    "```\n",
    "## array([nan, nan, nan])\n",
    "## \n",
    "## /opt/conda/envs/python-ENSAE/lib/python3.9/site-packages/numpy/core/_methods.py:163: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
    "##   arr = asanyarray(a)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49755172",
   "metadata": {},
   "source": [
    "```r\n",
    "x <- c(NA, 1:3)\n",
    "mean(x, na.rm = TRUE)\n",
    "```\n",
    "\n",
    "```\n",
    "## [1] 2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e48089",
   "metadata": {},
   "source": [
    "En revanche, ----->\n",
    "On a un comportement cohérent d'agrégation lorsqu'on combine deux `DataFrames` (ou deux colonnes).\n",
    "Par exemple,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac17c6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(\n",
    "    {'prix': np.random.uniform(size = 5),\n",
    "     'quantite': [i+1 for i in range(5)]\n",
    "    },\n",
    "    index = ['yaourt','pates','riz','tomates','gateaux']\n",
    ")\n",
    "\n",
    "y = pd.DataFrame(\n",
    "    {'prix': [np.nan, 0, 1, 2, 3],\n",
    "     'quantite': [i+1 for i in range(5)]\n",
    "    },\n",
    "    index = ['tomates','yaourt','gateaux','pates','riz']\n",
    ")\n",
    "\n",
    "x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe2ff24",
   "metadata": {},
   "source": [
    "```\n",
    "##              prix  quantite\n",
    "## gateaux  1.719469         8\n",
    "## pates    2.286139         6\n",
    "## riz      3.226851         8\n",
    "## tomates       NaN         5\n",
    "## yaourt   0.696469         3\n",
    "```\n",
    "\n",
    "donne bien une valeur manquante pour la ligne `tomates`. Au passage, on peut remarquer que l'agrégation\n",
    "a tenu compte des index.\n",
    "\n",
    "Il est possible de supprimer les valeurs manquantes grâce à `dropna()`.\n",
    "Cette méthode va supprimer toutes les lignes où il y a au moins une valeur manquante.\n",
    "Il est aussi possible de supprimer seulement les colonnes où il y a des valeurs manquantes\n",
    "dans un DataFrame avec `dropna()` avec le paramètre `axis=1` (par défaut égal à 0).\n",
    "\n",
    "Il est également possible de remplir les valeurs manquantes grâce à la méthode `fillna()`.\n",
    "\n",
    "# Le DataFrame pandas\n",
    "\n",
    "Le `DataFrame` est l'objet central de la librairie `pandas`.\n",
    "Il s'agit d'une collection de `pandas.Series` (colonnes) alignées par les index.\n",
    "Les types des variables peuvent différer.\n",
    "\n",
    "Un DataFrame non-indexé a la structure suivante:\n",
    "\n",
    "<!-----\n",
    "Exo 1\n",
    "Aller dans la doc pandas et trouver comment créer le dataFrame pandas suivant\n",
    "------>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808c6108",
   "metadata": {},
   "source": [
    "```\n",
    "##    index  taille  poids\n",
    "## 0   chat     1.0    3.0\n",
    "## 1  chien     1.5    5.0\n",
    "## 2  koala     1.0    2.5\n",
    "```\n",
    "\n",
    "Alors que le même dataframe indexé aura la structure suivante:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96841606",
   "metadata": {},
   "source": [
    "```\n",
    "##        taille  poids\n",
    "## chat      1.0    3.0\n",
    "## chien     1.5    5.0\n",
    "## koala     1.0    2.5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2324b9",
   "metadata": {},
   "source": [
    "## Les attributs et méthodes utiles\n",
    "\n",
    "Pour présenter les méthodes les plus pratiques pour l'analyse de données,\n",
    "on peut partir de l'exemple des consommations de CO2 communales issues\n",
    "des données de l'Ademe. Cette base de données est exploitée plus intensément\n",
    "dans le TP\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/linogaliana/python-datascientist/master)\n",
    "[![Onyxia](https://img.shields.io/badge/SSPcloud-Tester%20via%20SSP--cloud-informational&color=yellow?logo=Python)](https://datalab.sspcloud.fr/launcher/inseefrlab-helm-charts-datascience/jupyter?onyxia.friendlyName=%C2%ABpython-datascientist%C2%BB&resources.requests.memory=%C2%AB4Gi%C2%BB)\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/github/linogaliana/python-datascientist/blob/pandas_intro/static/notebooks/numpy.ipynb)\n",
    " ([ou depuis github](https://github.com/linogaliana/python-datascientist/blob/master/content/01_data/02_pandas_tp.ipynb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32eac7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://koumoul.com/s/data-fair/api/v1/datasets/igt-pouvoir-de-rechauffement-global/convert\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caba7d31",
   "metadata": {},
   "source": [
    "```\n",
    "##       INSEE commune                  Commune  ...       Routier     Tertiaire\n",
    "## 0             01001  L'ABERGEMENT-CLEMENCIAT  ...    793.156501    367.036172\n",
    "## 1             01002    L'ABERGEMENT-DE-VAREY  ...    348.997893    112.934207\n",
    "## 2             01004        AMBERIEU-EN-BUGEY  ...  15642.420310  10732.376930\n",
    "## 3             01005      AMBERIEUX-EN-DOMBES  ...   1756.341319    782.404357\n",
    "## 4             01006                  AMBLEON  ...    398.786800     51.681756\n",
    "## ...             ...                      ...  ...           ...           ...\n",
    "## 35793         95676       VILLERS-EN-ARTHIES  ...    309.627908    235.439109\n",
    "## 35794         95678            VILLIERS-ADAM  ...  18759.370070    403.404815\n",
    "## 35795         95680          VILLIERS-LE-BEL  ...  12217.122400  13849.512000\n",
    "## 35796         95682          VILLIERS-LE-SEC  ...   4663.232127     85.657725\n",
    "## 35797         95690      WY-DIT-JOLI-VILLAGE  ...    504.400972    147.867245\n",
    "## \n",
    "## [35798 rows x 12 columns]\n",
    "```\n",
    "\n",
    "Dans un processus de production, où normalement on connait les types des variables du DataFrame qu'on va importer,\n",
    "il convient de préciser les types avec lesquels on souhaite importer les données\n",
    "(argument `dtype`, sous la forme d'un dictionnaire). Cela est particulièrement important lorsqu'on désire utiliser une colonne comme une variable textuelle mais qu'elle comporte des attributs proches d'un nombre qui vont inciter `pandas` à l'importer sous forme de variable numérique.\n",
    "\n",
    "Par exemple, une colonne `[00001,00002,...] ` risque d'être importée comme une variable numérique, ignorant l'information des premiers 0 (qui peuvent pourtant la distinguer de la séquence 1, 2, etc.). Pour s'assurer que `pandas` importe sous forme textuelle la variable, on peut utiliser `dtype = {\"code\": \"str\"}`\n",
    "Sinon, on peut importer le csv, et modifier les types avec `astype()`.\n",
    "Avec `astype`, on peut gérer les erreurs de conversion avec le paramètre `errors`.\n",
    "\n",
    "L'affichage des DataFrames est très ergonomique. On obtiendrait le même *output*\n",
    "avec `display(df)`[^2]. Les premières et dernières lignes s'affichent\n",
    "automatiquement. Autrement, on peut aussi faire:\n",
    "\n",
    "* `head` qui permet, comme son\n",
    "nom l'indique, de n'afficher que les premières lignes ;\n",
    "* `tail` qui permet, comme son\n",
    "nom l'indique, de n'afficher que les dernières lignes\n",
    "* `sample` qui permet d'afficher un échantillon aléatoire de *n* lignes.\n",
    "Cette méthode propose de nombreuses options\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/linogaliana/python-datascientist/master)\n",
    "[![Onyxia](https://img.shields.io/badge/SSPcloud-Tester%20via%20SSP--cloud-informational&color=yellow?logo=Python)](https://datalab.sspcloud.fr/launcher/inseefrlab-helm-charts-datascience/jupyter?onyxia.friendlyName=%C2%ABpython-datascientist%C2%BB&resources.requests.memory=%C2%AB4Gi%C2%BB)\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/github/linogaliana/python-datascientist/blob/pandas_intro/static/notebooks/numpy.ipynb)\n",
    " ([ou depuis github](https://github.com/linogaliana/python-datascientist/blob/master/content/01_data/02_pandas_tp.ipynb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a2672b",
   "metadata": {},
   "source": [
    "[^2]: Il est préférable d'utiliser la fonction `display` (ou tout simplement\n",
    "taper le nom du DataFrame qu'utiliser la fonction `print`). Le\n",
    "`display` des objets `pandas` est assez esthétique, contrairement à `print`\n",
    "qui renvoie du texte brut."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae59d220",
   "metadata": {},
   "source": [
    "Il faut faire attention au `display` et aux\n",
    "commandes qui révèlent des données (`head`, `tail`, etc.)\n",
    "dans un notebook ou un markdown qui exploite\n",
    "des données confidentielles lorsqu'on utilise `git`. En effet, on peut se\n",
    "retrouver à partager des données, involontairement, dans l'historique\n",
    "`git`. Avec un `R markdown`, il suffit d'ajouter les sorties au fichier\n",
    "`gitignore` (par exemple avec une balise de type `*.html`). Avec un\n",
    "notebook `jupyter`, la démarche est plus compliquée car les fichiers\n",
    "`.ipynb` intègrent dans le même document, texte, sorties et mise en forme.\n",
    "Techniquement, il est possible d'appliquer des filtres avec `git`\n",
    "(voir\n",
    "[ici](http://timstaley.co.uk/posts/making-git-and-jupyter-notebooks-play-nice/))\n",
    "mais c'est une démarche très complexe\n",
    "\n",
    "On pourra alors préférer convertir systématiquement les `.ipynb` en `.py` grâce\n",
    "à `jupytext` (`jupytext --to py nom_du_notebook.ipynb`) et mettre l'extension `*.ipynb`\n",
    "dans le `.gitignore` de son projet git.\n",
    "\n",
    "### Dimensions et structure du DataFrame\n",
    "\n",
    "Les premières méthodes utiles permettent d'afficher quelques\n",
    "attributs d'un DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c059813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.axes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2104219f",
   "metadata": {},
   "source": [
    "```\n",
    "## [RangeIndex(start=0, stop=35798, step=1), Index(['INSEE commune', 'Commune', 'Agriculture', 'Autres transports',\n",
    "##        'Autres transports international', 'CO2 biomasse hors-total', 'Déchets',\n",
    "##        'Energie', 'Industrie hors-énergie', 'Résidentiel', 'Routier',\n",
    "##        'Tertiaire'],\n",
    "##       dtype='object')]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24a4cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61f6d41",
   "metadata": {},
   "source": [
    "```\n",
    "## Index(['INSEE commune', 'Commune', 'Agriculture', 'Autres transports',\n",
    "##        'Autres transports international', 'CO2 biomasse hors-total', 'Déchets',\n",
    "##        'Energie', 'Industrie hors-énergie', 'Résidentiel', 'Routier',\n",
    "##        'Tertiaire'],\n",
    "##       dtype='object')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e55c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5890c0b6",
   "metadata": {},
   "source": [
    "```\n",
    "## RangeIndex(start=0, stop=35798, step=1)\n",
    "```\n",
    "\n",
    "Pour connaître les dimensions d'un DataFrame, on peut utiliser quelques méthodes\n",
    "pratiques:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893eebf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fe7a21",
   "metadata": {},
   "source": [
    "```\n",
    "## 2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c6e153",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b934e4",
   "metadata": {},
   "source": [
    "```\n",
    "## (35798, 12)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2f2414",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f56256a",
   "metadata": {},
   "source": [
    "```\n",
    "## 429576\n",
    "```\n",
    "\n",
    "Pour déterminer le nombre de valeurs uniques d'une variable, plutôt que chercher à écrire soi-même une fonction,\n",
    "on utilise la\n",
    "méthode `nunique`. Par exemple,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eb3afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Commune'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6badfa20",
   "metadata": {},
   "source": [
    "```\n",
    "## 33338\n",
    "```\n",
    "\n",
    "Voici un premier résumé des méthodes `pandas` utiles, et un comparatif avec `R`\n",
    "\n",
    "| Opération                     | pandas       | dplyr (`R`)    | data.table (`R`)           |\n",
    "|-------------------------------|--------------|----------------|----------------------------|\n",
    "| Récupérer le nom des colonnes | `df.columns` | `colnames(df)` | `colnames(df)`             |\n",
    "| Récupérer les indices[^3]     | `df.index`   |                |`unique(df[,get(key(df))])` |\n",
    "| Récupérer les dimensions      | `df.shape` | `c(nrow(df), ncol(df))` | `c(nrow(df), ncol(df))` |\n",
    "| Récupérer le nombre de valeurs uniques d'une variable | `df['myvar'].nunique()` | `df %>%  summarise(distinct(myvar))` | `df[,uniqueN(myvar)]` |\n",
    "\n",
    "^[3]: Le principe d'indice n'existe pas dans `dplyr`. Ce qui s'approche le plus des indices, au sens de\n",
    "`pandas`, sont les *clés* en `data.table`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6b6f10",
   "metadata": {},
   "source": [
    "### Statistiques agrégées\n",
    "\n",
    "`pandas` propose une série de méthodes pour faire des statistiques\n",
    "agrégées de manière efficace.\n",
    "\n",
    "On peut, par exemple, appliquer des méthodes pour compter le nombre de lignes,\n",
    "faire une moyenne ou une somme de l'ensemble des lignes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b702c19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea6d6dc",
   "metadata": {},
   "source": [
    "```\n",
    "## INSEE commune                      35798\n",
    "## Commune                            35798\n",
    "## Agriculture                        35736\n",
    "## Autres transports                   9979\n",
    "## Autres transports international     2891\n",
    "## CO2 biomasse hors-total            35798\n",
    "## Déchets                            35792\n",
    "## Energie                            34490\n",
    "## Industrie hors-énergie             34490\n",
    "## Résidentiel                        35792\n",
    "## Routier                            35778\n",
    "## Tertiaire                          35798\n",
    "## dtype: int64\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30713ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded6d874",
   "metadata": {},
   "source": [
    "```\n",
    "## Agriculture                        2459.975760\n",
    "## Autres transports                   654.919940\n",
    "## Autres transports international    7692.344960\n",
    "## CO2 biomasse hors-total            1774.381550\n",
    "## Déchets                             410.806329\n",
    "## Energie                             662.569846\n",
    "## Industrie hors-énergie             2423.127789\n",
    "## Résidentiel                        1783.677872\n",
    "## Routier                            3535.501245\n",
    "## Tertiaire                          1105.165915\n",
    "## dtype: float64\n",
    "## \n",
    "## <string>:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cdfd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6431699",
   "metadata": {},
   "source": [
    "```\n",
    "## INSEE commune                      0100101002010040100501006010070100801009010100...\n",
    "## Commune                            L'ABERGEMENT-CLEMENCIATL'ABERGEMENT-DE-VAREYAM...\n",
    "## Agriculture                                                          87909693.748185\n",
    "## Autres transports                                                     6535446.082616\n",
    "## Autres transports international                                      22238569.279024\n",
    "## CO2 biomasse hors-total                                              63519310.715902\n",
    "## Déchets                                                              14703580.140421\n",
    "## Energie                                                              22852033.998225\n",
    "## Industrie hors-énergie                                               83573677.443527\n",
    "## Résidentiel                                                          63841398.384566\n",
    "## Routier                                                             126493163.530568\n",
    "## Tertiaire                                                            39562729.439236\n",
    "## dtype: object\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00c3bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be339c9",
   "metadata": {},
   "source": [
    "```\n",
    "## INSEE commune                      35798\n",
    "## Commune                            33338\n",
    "## Agriculture                        35576\n",
    "## Autres transports                   9963\n",
    "## Autres transports international     2883\n",
    "## CO2 biomasse hors-total            35798\n",
    "## Déchets                            11016\n",
    "## Energie                             1453\n",
    "## Industrie hors-énergie              1889\n",
    "## Résidentiel                        35791\n",
    "## Routier                            35749\n",
    "## Tertiaire                           8663\n",
    "## dtype: int64\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346d6ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.quantile(q = [0.1,0.25,0.5,0.75,0.9])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf352f3",
   "metadata": {},
   "source": [
    "```\n",
    "##       Agriculture  Autres transports  ...      Routier    Tertiaire\n",
    "## 0.10   382.620882          25.034578  ...   199.765410    49.289082\n",
    "## 0.25   797.682631          52.560412  ...   419.700460    94.749885\n",
    "## 0.50  1559.381286         106.795928  ...  1070.895593   216.297718\n",
    "## 0.75  3007.883903         237.341501  ...  3098.612157   576.155869\n",
    "## 0.90  5442.727470         528.349529  ...  8151.047248  1897.732565\n",
    "## \n",
    "## [5 rows x 10 columns]\n",
    "```\n",
    "\n",
    "Il faut toujours regarder les options de ces fonctions en termes de valeurs manquantes, car\n",
    "ces options sont déterminantes dans le résultat obtenu.\n",
    "\n",
    "Les exercices de TD ([![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/linogaliana/python-datascientist/master)\n",
    "[![Onyxia](https://img.shields.io/badge/SSPcloud-Tester%20via%20SSP--cloud-informational&color=yellow?logo=Python)](https://datalab.sspcloud.fr/launcher/inseefrlab-helm-charts-datascience/jupyter?onyxia.friendlyName=%C2%ABpython-datascientist%C2%BB&resources.requests.memory=%C2%AB4Gi%C2%BB)\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/github/linogaliana/python-datascientist/blob/pandas_intro/static/notebooks/numpy.ipynb) [ou depuis github](https://github.com/linogaliana/python-datascientist/blob/master/content/01_data/02_pandas_tp.ipynb))\n",
    "visent à démontrer l'intérêt de ces méthodes dans quelques cas précis.\n",
    "\n",
    "<!---\n",
    "Comme indiqué précédemment, il faut faire attention aux valeurs manquantes qui,\n",
    "par défaut, sont traitées comme des 0.\n",
    "Il est ainsi recommandé de systématiquement\n",
    "ajouter l'argument skipna, par exemple,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66ba4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean(skipna=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6492438",
   "metadata": {},
   "source": [
    "```\n",
    "## Agriculture                        2459.975760\n",
    "## Autres transports                   654.919940\n",
    "## Autres transports international    7692.344960\n",
    "## CO2 biomasse hors-total            1774.381550\n",
    "## Déchets                             410.806329\n",
    "## Energie                             662.569846\n",
    "## Industrie hors-énergie             2423.127789\n",
    "## Résidentiel                        1783.677872\n",
    "## Routier                            3535.501245\n",
    "## Tertiaire                          1105.165915\n",
    "## dtype: float64\n",
    "## \n",
    "## <string>:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
    "```\n",
    "\n",
    "----->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1cd288",
   "metadata": {},
   "source": [
    "Le tableau suivant récapitule le code équivalent pour avoir des\n",
    "statistiques sur toutes les colonnes d'un dataframe en `R`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb250de",
   "metadata": {},
   "source": [
    "| Opération                     | pandas       | dplyr (`R`)    | data.table (`R`)           |\n",
    "|-------------------------------|----------------|--------------|----------------|----------------------------|\n",
    "| Nombre de valeurs non manquantes | `df.count()`   | `df %>% summarise_each(funs(sum(!is.na(.))))` | `df[, lapply(.SD, function(x) sum(!is.na(x)))]`\n",
    "| Moyenne de toutes les variables | `df.mean()` | `df %>% summarise_each(funs(mean((., na.rm = TRUE))))` | `df[,lapply(.SD, function(x) mean(x, na.rm = TRUE))]`\n",
    "| TO BE CONTINUED |\n",
    "\n",
    "La méthode `describe` permet de sortir un tableau de statistiques\n",
    "agrégées:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690c00a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79805ec6",
   "metadata": {},
   "source": [
    "```\n",
    "##         Agriculture  Autres transports  ...        Routier      Tertiaire\n",
    "## count  35736.000000        9979.000000  ...   35778.000000   35798.000000\n",
    "## mean    2459.975760         654.919940  ...    3535.501245    1105.165915\n",
    "## std     2926.957701        9232.816833  ...    9663.156628    5164.182507\n",
    "## min        0.003432           0.000204  ...       0.555092       0.000000\n",
    "## 25%      797.682631          52.560412  ...     419.700460      94.749885\n",
    "## 50%     1559.381286         106.795928  ...    1070.895593     216.297718\n",
    "## 75%     3007.883903         237.341501  ...    3098.612157     576.155869\n",
    "## max    98949.317760      513140.971700  ...  586054.672800  288175.400100\n",
    "## \n",
    "## [8 rows x 10 columns]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fb1f67",
   "metadata": {},
   "source": [
    "### Méthodes relatives aux valeurs manquantes\n",
    "\n",
    "Les méthodes relatives aux valeurs manquantes peuvent être mobilisées\n",
    "en conjonction des méthodes de statistiques agrégées. C'est utiles lorsqu'on\n",
    "désire obtenir une idée de la part de valeurs manquantes dans un jeu de\n",
    "données\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/linogaliana/python-datascientist/master)\n",
    "[![Onyxia](https://img.shields.io/badge/SSPcloud-Tester%20via%20SSP--cloud-informational&color=yellow?logo=Python)](https://datalab.sspcloud.fr/launcher/inseefrlab-helm-charts-datascience/jupyter?onyxia.friendlyName=%C2%ABpython-datascientist%C2%BB&resources.requests.memory=%C2%AB4Gi%C2%BB)\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/github/linogaliana/python-datascientist/blob/pandas_intro/static/notebooks/numpy.ipynb)\n",
    " ([ou depuis github](https://github.com/linogaliana/python-datascientist/blob/master/content/01_data/02_pandas_tp.ipynb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb88c11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edfb534",
   "metadata": {},
   "source": [
    "On trouvera aussi la référence à `isna()` qui est la même méthode que `isnull()`.\n",
    "\n",
    "# Graphiques rapides\n",
    "\n",
    "Les méthodes par défaut de graphique\n",
    "(approfondies dans la partie visualisation **LIEN A AJOUTER**)\n",
    "sont pratiques pour\n",
    "produire rapidement un graphique, notament après des opérations\n",
    "complexes de maniement de données.\n",
    "\n",
    "En effet, on peut appliquer la méthode `plot()` directement à une `pandas.Series`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10abd5a3",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "df['Déchets'].plot()\n",
    "df['Déchets'].hist()\n",
    "df['Déchets'].plot(kind = 'hist', logy = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92862341",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1678e4a6",
   "metadata": {},
   "source": [
    "```r\n",
    "knitr::include_graphics(\"plot_base.png\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f865c1",
   "metadata": {},
   "source": [
    "```r\n",
    "knitr::include_graphics(\"plot_hist.png\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325a8376",
   "metadata": {},
   "source": [
    "```r\n",
    "knitr::include_graphics(\"plot_hist_log.png\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd089b37",
   "metadata": {},
   "source": [
    "La sortie est un objet `matplotlib`. La *customisation* de ces\n",
    "figures est ainsi\n",
    "possible (et même désirable car les graphiques `matplotlib`\n",
    "sont, par défaut, assez rudimentaires), nous en verrons quelques exemples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09588fe5",
   "metadata": {},
   "source": [
    "# Accéder à des éléments d'un DataFrame\n",
    "\n",
    "## Sélectionner des colonnes\n",
    "\n",
    "En SQL, effectuer des opérations sur les colonnes se fait avec la commande\n",
    "`SELECT`. Avec `pandas`,\n",
    "pour accéder à une colonne dans son ensemble on peut\n",
    "utiliser plusieurs approches:\n",
    "\n",
    "* `dataframe.variable`, par exemple `df.Energie`.\n",
    "Cette méthode requiert néanmoins d'avoir des\n",
    "noms de colonnes sans espace.\n",
    "* `dataframe[['variable']]` pour renvoyer la variable sous\n",
    "forme de `DataFrame` ou dataframe['variable'] pour\n",
    "la renvoyer sous forme de `Series`. Par exemple, `df[['Autres transports']]`\n",
    "ou `df['Autres transports']`. C'est une manière préférable de procéder.\n",
    "\n",
    "## Accéder à des lignes\n",
    "\n",
    "Pour accéder à une ou plusieurs valeurs d'un `DataFrame`,\n",
    "il existe deux manières conseillées de procéder, selon la\n",
    "forme des indices de lignes ou colonnes utilisés:\n",
    "\n",
    "* `df.loc`: use labels\n",
    "* `df.iloc`: use indices\n",
    "\n",
    "Les bouts de code utilisant la structure `df.ix`\n",
    "sont à bannir car la fonction est *deprecated* et peut\n",
    "ainsi disparaître à tout moment.\n",
    "\n",
    "`iloc` va se référer à l'indexation de 0 à *N* où *N* est égal à `df.shape[0]` d'un\n",
    "`pandas.DataFrame`. `loc` va se référer aux valeurs de l'index\n",
    "de `df`.\n",
    "\n",
    "Par exemple, si j'ai un `pandas.DataFrame` `df`:\n",
    "```\n",
    "       year  sale\n",
    "month\n",
    "1      2012    55\n",
    "4      2014    40\n",
    "7      2013    84\n",
    "10     2014    31\n",
    "```\n",
    "Alors `df.loc[1, :]` donnera la première ligne de `df` (ligne où l'indice `month` est égal à 1) tandis que\n",
    "`df.iloc[1, :]` donnera la deuxième ligne (puisque l'indexation en `Python` commence à 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ce846d",
   "metadata": {},
   "source": [
    "<!----\n",
    "data.loc[1:3]\n",
    "data.loc[(data.age >= 20), ['section', 'city']]\n",
    "\n",
    "data.iloc[[0,2]]\n",
    "data.iloc[[0,2],[1,3]]\n",
    "data.iloc[1:3,2:4]\n",
    "\n",
    "data.loc[(data.age >= 12), ['section']]\n",
    "------>\n",
    "\n",
    "# Principales manipulation de données\n",
    "\n",
    "L'objectif du [TP pandas](#pandasTP) est de se familiariser plus avec ces\n",
    "commandes à travers l'exemple des données des émissions de C02.\n",
    "\n",
    "Les opérations les plus fréquentes en SQL sont résumées par le tableau suivant.\n",
    "Il est utile de les connaître (beaucoup de syntaxes de maniement de données\n",
    "reprennent ces termes) car, d'une\n",
    "manière ou d'une autre, elles couvrent la plupart\n",
    "des usages de manipulation des données\n",
    "\n",
    "| Opération | SQL | pandas | dplyr (`R`) | data.table (`R`) |\n",
    "|-----|-----------|--------|-------------|------------------|\n",
    "| Sélectionner des variables par leur nom | `SELECT` | `df[['Autres transports','Energie']]` | `df %>% select(Autres transports, Energie)` | `df[, c('Autres transports','Energie')]` |\n",
    "| Sélectionner des observations selon une ou plusieurs conditions; | `FILTER` | `df[df['Agriculture']>2000]` | `df %>% filter(Agriculture>2000)` | `df[Agriculture>2000]` |\n",
    "| Trier la table selon une ou plusieurs variables | `SORT BY` | `df.sort_values(['Commune','Agriculture'])` | `df %>% arrange(Commune, Agriculture)` | `df[order(Commune, Agriculture)]` |\n",
    "| Ajouter des variables qui sont fonction d’autres variables; | `SELECT *, LOG(Agriculture) AS x FROM df` | `df['x'] = np.log(df['Agriculture'])`  |  `df %>% mutate(x = log(Agriculture))` | `df[,x := log(Agriculture)]` |\n",
    "| Effectuer une opération par groupe | `GROUP BY` | `df.groupby('Commune').mean()` | `df %>% group_by(Commune) %>% summarise(m = mean)` | `df[,mean(Commune), by = Commune]` |\n",
    "| Joindre deux bases de données (*inner join*) | `SELECT * FROM table1 INNER JOIN table2 ON table1.id = table2.x` | `table1.merge(table2, left_on = 'id', right_on = 'x')` | `table1 %>% inner_join(table2, by = c('id'='x'))` | `merge(table1, table2, by.x = 'id', by.y = 'x')` |\n",
    "\n",
    "## Opérations sur les colonnes: select, mutate, drop\n",
    "\n",
    "Les DataFrames pandas sont des objets *mutables* en langage `python`,\n",
    "c'est-à-dire qu'il est possible de faire évoluer le DataFrame au grès\n",
    "des opérations. L'opération la plus classique consiste à ajouter ou retirer\n",
    "des variables à la table de données."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3665336f",
   "metadata": {},
   "source": [
    "Attention au comportement de `pandas` lorsqu'on crée une duplication\n",
    "d'un DataFrame. Par défaut, `pandas` effectue une copie par référence. Dans ce\n",
    "cas, les deux objets (la copie et l'objet copié) restent reliés. Les colonnes\n",
    "crées sur l'un vont être répercutées sur l'autre. Ce comportement permet de\n",
    "limiter l'inflation en mémoire de `python`. En faisant ça, le deuxième\n",
    "objet prend le même espace mémoire que le premier. Le package `data.table`\n",
    "en  `R` adopte le même comportement, contrairement à `dplyr`.\n",
    "\n",
    "Cela peut amener à quelques surprises si ce comportement d'optimisation\n",
    "n'est pas anticipé. Si vous voulez, par sécurité, conserver intact le\n",
    "premier DataFrame, faites appel à une copie profonde (*deep copy*) en\n",
    "utilisant la méthode `copy`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c5f582",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd64447",
   "metadata": {},
   "source": [
    "Attention toutefois, cela a un coût mémoire. Avec des données volumineuses, c'est une pratique à utiliser avec précaution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7161b30f",
   "metadata": {},
   "source": [
    "La manière la plus simple d'opérer pour ajouter des colonnes est\n",
    "d'utiliser la réassignation. Par exemple, pour créer une variable\n",
    "`x` qui est le `log` de la\n",
    "variable `Agriculture`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fa110c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['x'] = np.log(df_new['Agriculture'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3349d6e0",
   "metadata": {},
   "source": [
    "Il est possible d'appliquer cette approche sur plusieurs colonnes. Un des\n",
    "intérêts de cette approche est qu'elle permet de recycler le nom de colonnes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c269570c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = ['Agriculture', 'Déchets', 'Energie']\n",
    "\n",
    "df_new[[v + \"_log\" for v in vars]] = np.log(df_new[vars])\n",
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901b43c6",
   "metadata": {},
   "source": [
    "```\n",
    "##       INSEE commune                  Commune  ...  Déchets_log  Energie_log\n",
    "## 0             01001  L'ABERGEMENT-CLEMENCIAT  ...     4.619374     0.856353\n",
    "## 1             01002    L'ABERGEMENT-DE-VAREY  ...     4.946455     0.856353\n",
    "## 2             01004        AMBERIEU-EN-BUGEY  ...     8.578159     6.906086\n",
    "## 3             01005      AMBERIEUX-EN-DOMBES  ...     5.376285     4.545232\n",
    "## 4             01006                  AMBLEON  ...     3.879532          NaN\n",
    "## ...             ...                      ...  ...          ...          ...\n",
    "## 35793         95676       VILLERS-EN-ARTHIES  ...     4.175366     2.465791\n",
    "## 35794         95678            VILLIERS-ADAM  ...     4.713854     0.856353\n",
    "## 35795         95680          VILLIERS-LE-BEL  ...     5.418865     6.281303\n",
    "## 35796         95682          VILLIERS-LE-SEC  ...     4.691070     0.856353\n",
    "## 35797         95690      WY-DIT-JOLI-VILLAGE  ...     4.582194     1.549500\n",
    "## \n",
    "## [35798 rows x 16 columns]\n",
    "```\n",
    "\n",
    "Il est également possible d'utiliser la méthode `assign`. Pour des opérations\n",
    "vectorisées, comme le sont les opérateurs de `numpy`, cela n'a pas d'intérêt.\n",
    "\n",
    "Cela permet notamment d'enchainer les opérations sur un même `DataFrame` (notamment grâce au `pipe` que\n",
    "nous verrons plus loin).\n",
    "Cette approche utilise généralement\n",
    "des *lambda functions*. Par exemple le code précédent (celui concernant une\n",
    " seule variable) prendrait la forme:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25f2570",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.assign(Energie_log = lambda x: np.log(x['Energie']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae5904e",
   "metadata": {},
   "source": [
    "```\n",
    "##       INSEE commune                  Commune  ...  Déchets_log  Energie_log\n",
    "## 0             01001  L'ABERGEMENT-CLEMENCIAT  ...     4.619374     0.856353\n",
    "## 1             01002    L'ABERGEMENT-DE-VAREY  ...     4.946455     0.856353\n",
    "## 2             01004        AMBERIEU-EN-BUGEY  ...     8.578159     6.906086\n",
    "## 3             01005      AMBERIEUX-EN-DOMBES  ...     5.376285     4.545232\n",
    "## 4             01006                  AMBLEON  ...     3.879532          NaN\n",
    "## ...             ...                      ...  ...          ...          ...\n",
    "## 35793         95676       VILLERS-EN-ARTHIES  ...     4.175366     2.465791\n",
    "## 35794         95678            VILLIERS-ADAM  ...     4.713854     0.856353\n",
    "## 35795         95680          VILLIERS-LE-BEL  ...     5.418865     6.281303\n",
    "## 35796         95682          VILLIERS-LE-SEC  ...     4.691070     0.856353\n",
    "## 35797         95690      WY-DIT-JOLI-VILLAGE  ...     4.582194     1.549500\n",
    "## \n",
    "## [35798 rows x 16 columns]\n",
    "```\n",
    "\n",
    "Dans les méthodes suivantes, il est possible de modifier le `pandas.DataFrame`\n",
    "*en place*, c'est à dire en ne le réassignant pas, avec le paramètre `inplace = True`.\n",
    "Par défaut, `inplace` est égal à False et pour modifier le `pandas.DataFrame`,\n",
    "il convient de le réassigner.\n",
    "\n",
    "On peut facilement renommer des variables avec la méthode `rename` qui\n",
    "fonctionne bien avec des dictionnaires (pour renommer des colonnes il faut\n",
    "préciser le paramètre `axis = 1`):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bc3d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new.rename({\"Energie\": \"eneg\", \"Agriculture\": \"agr\"}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ed9b7f",
   "metadata": {},
   "source": [
    "Enfin, pour effacer des colonnes, on utilise la méthode `drop` avec l'argument\n",
    "`columns`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3700216",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new.drop(columns = [\"eneg\", \"agr\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7268ba1",
   "metadata": {},
   "source": [
    "## Réordonner\n",
    "\n",
    "La méthode `sort_values` permet de réordonner un `DataFrame`. Par exemple,\n",
    "si on désire classer par ordre décroissant de consommation de CO2 du secteur\n",
    "résidentiel, on fera\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3523fbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(\"Résidentiel\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19cd7f9",
   "metadata": {},
   "source": [
    "Ainsi, en une ligne de code, on identifie les villes où le secteur\n",
    "résidentiel consomme le plus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ced5246",
   "metadata": {},
   "source": [
    "## Filtrer\n",
    "\n",
    "L'opération de sélection de lignes s'appelle `FILTER` en SQL et s'utilise\n",
    "en fonction d'une condition logique (clause `WHERE`). On sélectionne les\n",
    "données sur une condition logique. Il existe plusieurs méthodes en `pandas`.\n",
    "\n",
    "La plus simple est d'utiliser les *boolean mask*, déjà vus dans le chapitre\n",
    "[`numpy`](#numpy)\n",
    "\n",
    "Par exemple, pour sélectionner les communes dans les Hauts-de-Seine, on\n",
    "peut utiliser le résultat de la méthode `str.startswith` (qui renvoie\n",
    "`True` ou `False`) directement dans les crochets:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3d4359",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['INSEE commune'].str.startswith(\"92\")].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a1f769",
   "metadata": {},
   "source": [
    "```\n",
    "##       INSEE commune               Commune  ...      Routier    Tertiaire\n",
    "## 35494         92012  BOULOGNE-BILLANCOURT  ...  64985.28090  60349.10948\n",
    "## 35501         92025              COLOMBES  ...  52070.92794  41526.60087\n",
    "## \n",
    "## [2 rows x 12 columns]\n",
    "```\n",
    "\n",
    "Pour remplacer des valeurs spécifiques, on utilise la méthode `where` ou une\n",
    "réassignation couplée à la méthode précédente.\n",
    "\n",
    "Par exemple, pour assigner des valeurs manquantes aux départements du 92,\n",
    "on peut faire cela\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaece40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()\n",
    "df_copy = df_copy.where(~df['INSEE commune'].str.startswith(\"92\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38977743",
   "metadata": {},
   "source": [
    "et vérifier les résultats:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b5de78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy[df['INSEE commune'].str.startswith(\"92\")].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5564b91c",
   "metadata": {},
   "source": [
    "```\n",
    "##       INSEE commune Commune  Agriculture  ...  Résidentiel  Routier  Tertiaire\n",
    "## 35494           NaN     NaN          NaN  ...          NaN      NaN        NaN\n",
    "## 35501           NaN     NaN          NaN  ...          NaN      NaN        NaN\n",
    "## \n",
    "## [2 rows x 12 columns]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3df17ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy[~df['INSEE commune'].str.startswith(\"92\")].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2115f982",
   "metadata": {},
   "source": [
    "```\n",
    "##       INSEE commune   Commune  ...      Routier    Tertiaire\n",
    "## 12167         31555  TOULOUSE  ...  586054.6728  288175.4001\n",
    "## 16774         44109    NANTES  ...  221068.6327  173447.5828\n",
    "## \n",
    "## [2 rows x 12 columns]\n",
    "```\n",
    "\n",
    "ou alors utiliser une réassignation plus classique:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b224b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()\n",
    "df_copy[df_copy['INSEE commune'].str.startswith(\"92\")] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5a1d31",
   "metadata": {},
   "source": [
    "Il est conseillé de filtrer avec `loc` en utilisant un masque.\n",
    "En effet, contrairement à `df[mask]`, `df.loc[mask, :]` permet d'indiquer clairement\n",
    "à Python que l'on souhaite appliquer le masque aux labels de l'index.\n",
    "Ce n'est pas le cas avec `df[mask]`. D'ailleurs, lorsqu'on utilise la syntaxe `df[mask]`, `pandas` renvoie généralement un *warning*\n",
    "\n",
    "## Opérations par groupe\n",
    "\n",
    "En SQL, il est très simple de découper des données pour\n",
    "effectuer des opérations sur des blocs cohérents et recollecter des résultats\n",
    "dans la dimension appropriée.\n",
    "La logique sous-jacente est celle du *split-apply-combine* qui est repris\n",
    "par les langages de manipulation de données, auxquels `pandas`\n",
    "[ne fait pas exception](https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html).\n",
    "\n",
    "L'image suivante, issue de\n",
    "[ce site](https://unlhcc.github.io/r-novice-gapminder/16-plyr/)\n",
    "représente bien la manière dont fonctionne l'approche\n",
    "`split`-`apply`-`combine`\n",
    "\n",
    "![Split-apply-combine](https://unlhcc.github.io/r-novice-gapminder/fig/12-plyr-fig1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6dc5b6",
   "metadata": {},
   "source": [
    "Ce [tutoriel](https://realpython.com/pandas-groupby/) sur le sujet\n",
    "est particulièrement utile.\n",
    "\n",
    "Pour donner quelques exemples, on peut créer une variable départementale qui\n",
    "servira de critère de groupe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd6f280",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dep'] = df['INSEE commune'].str[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dde708a",
   "metadata": {},
   "source": [
    "En `pandas`, on utilise `groupby` pour découper les données selon un ou\n",
    "plusieurs axes. Techniquement, cette opération consiste à créer une association\n",
    "entre des labels (valeurs des variables de groupe) et des\n",
    "observations.\n",
    "\n",
    "Par exemple, pour compter le nombre de communes par département en SQL, on\n",
    "utiliserait la requête suivante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0071309c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT dep, count(INSEE commune)\n",
    "FROM df\n",
    "GROUP BY dep;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca78c241",
   "metadata": {},
   "source": [
    "Ce qui, en `pandas`, donne:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25897f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('dep')[\"INSEE commune\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca72f31",
   "metadata": {},
   "source": [
    "```\n",
    "## dep\n",
    "## 01    410\n",
    "## 02    805\n",
    "## 03    318\n",
    "## 04    199\n",
    "## 05    168\n",
    "##      ... \n",
    "## 91    196\n",
    "## 92     36\n",
    "## 93     40\n",
    "## 94     47\n",
    "## 95    185\n",
    "## Name: INSEE commune, Length: 96, dtype: int64\n",
    "```\n",
    "\n",
    "La syntaxe est quasiment transparente. On peut bien-sûr effectuer des opérations\n",
    "par groupe sur plusieurs colonnes. Par exemple,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeaae1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('dep').mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9960569",
   "metadata": {},
   "source": [
    "```\n",
    "## <bound method GroupBy.mean of <pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f4328af9e20>>\n",
    "```\n",
    "\n",
    "A noter que la variable de groupe, ici `dep`, devient, par défaut, l'index\n",
    "du DataFrame de sortie. Si on avait utilisé plusieurs variables de groupe,\n",
    "on obtiendrait un objet multi-indexé. Sur la gestion des `multiindex`, on\n",
    "pourra se référer à la référence de `Modern pandas` donnée en fin de cours.\n",
    "\n",
    "Tant qu'on appelle pas une action sur un DataFrame par groupe, du type\n",
    "`head` ou `display`, `pandas` n'effectue aucune opération. On parle de\n",
    "*lazy evaluation*. Par exemple, le résultat de `df.groupby('dep')` est\n",
    "une transformation qui n'est pas encore évaluée:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53203512",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('dep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bbdc84",
   "metadata": {},
   "source": [
    "```\n",
    "## <pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f43285032b0>\n",
    "```\n",
    "\n",
    "Il est possible d'appliquer plus d'une opération à la fois grâce à la méthode\n",
    "`agg`. Par exemple, pour obtenir à la fois le minimum, la médiane et le maximum\n",
    "de chaque département, on peut faire:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00115593",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('dep').agg(['min',\"median\",\"max\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7627714c",
   "metadata": {},
   "source": [
    "```\n",
    "##     Agriculture               ...     Tertiaire             \n",
    "##             min       median  ...        median          max\n",
    "## dep                           ...                           \n",
    "## 01     0.003432  1304.519570  ...    401.490676  30847.36686\n",
    "## 02     0.391926  1205.725078  ...    130.639994  34159.34575\n",
    "## 03     5.041238  5382.194339  ...    191.892445  31099.77288\n",
    "## 04    30.985972  1404.752852  ...    122.504902  16478.02481\n",
    "## 05    38.651727  1520.896526  ...    151.695524  23666.23590\n",
    "## ..          ...          ...  ...           ...          ...\n",
    "## 91     0.400740   516.908303  ...   1428.426303  38296.20473\n",
    "## 92     0.073468     6.505185  ...  18086.633085  65043.36450\n",
    "## 93     3.308495     3.308495  ...  20864.923340  71918.16398\n",
    "## 94     1.781885     1.781885  ...  14054.223450  58528.62348\n",
    "## 95     8.779506   445.279844  ...    725.467969  61497.82148\n",
    "## \n",
    "## [96 rows x 30 columns]\n",
    "```\n",
    "\n",
    "## Appliquer des fonctions\n",
    "\n",
    "`pandas` est, comme on a pu le voir, un package très flexible, qui\n",
    "propose une grande variété de méthodes optimisées. Cependant, il est fréquent\n",
    "d'avoir besoin de méthodes non implémentées.\n",
    "\n",
    "Dans ce cas, on recourt souvent aux `lambda` functions. Par exemple, si\n",
    "on désire connaître les communes dont le nom fait plus de 10 caractères,\n",
    "on peut appliquer la fonction `len` de manière itérative:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227e151b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Commune'].apply(lambda s: len(s)>10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8862112c",
   "metadata": {},
   "source": [
    "```\n",
    "##       INSEE commune                   Commune  ...     Tertiaire  dep\n",
    "## 13379         34172               MONTPELLIER  ...  169196.24140   34\n",
    "## 16300         42218             SAINT-ETIENNE  ...  107359.76360   42\n",
    "## 25248         63113          CLERMONT-FERRAND  ...   90140.04915   63\n",
    "## 30105         75116  PARIS-16E-ARRONDISSEMENT  ...   98551.72423   75\n",
    "## 30106         75117  PARIS-17E-ARRONDISSEMENT  ...  100660.54130   75\n",
    "## ...             ...                       ...  ...           ...  ...\n",
    "## 20731         55039     BEAUMONT-EN-VERDUNOIS  ...       0.00000   55\n",
    "## 20817         55139    CUMIERES-LE-MORT-HOMME  ...       0.00000   55\n",
    "## 20861         55189   FLEURY-DEVANT-DOUAUMONT  ...       0.00000   55\n",
    "## 20898         55239    HAUMONT-PRES-SAMOGNEUX  ...       0.00000   55\n",
    "## 20957         55307  LOUVEMONT-COTE-DU-POIVRE  ...       0.00000   55\n",
    "## \n",
    "## [16289 rows x 13 columns]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94bf9c7",
   "metadata": {},
   "source": [
    "Cependant, toutes les `lambda` functions ne se justifient pas.\n",
    "Par exemple, prenons\n",
    "le résultat d'agrégation précédent. Imaginons qu'on désire avoir les résultats\n",
    "en milliers de tonnes. Dans ce cas, le premier réflexe est d'utiliser\n",
    "la `lambda` function suivante:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352a6198",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('dep').agg(['min',\"median\",\"max\"]).apply(lambda s: s/1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8d8f41",
   "metadata": {},
   "source": [
    "```\n",
    "##     Agriculture                       ... Tertiaire                      \n",
    "##             min    median        max  ...       min     median        max\n",
    "## dep                                   ...                                \n",
    "## 01     0.000003  1.304520  14.402057  ...  0.010049   0.401491  30.847367\n",
    "## 02     0.000392  1.205725  13.257717  ...  0.006221   0.130640  34.159346\n",
    "## 03     0.005041  5.382194  24.912249  ...  0.017706   0.191892  31.099773\n",
    "## 04     0.030986  1.404753  11.423536  ...  0.000957   0.122505  16.478025\n",
    "## 05     0.038652  1.520897  13.143466  ...  0.004785   0.151696  23.666236\n",
    "## ..          ...       ...        ...  ...       ...        ...        ...\n",
    "## 91     0.000401  0.516908   5.965349  ...  0.036369   1.428426  38.296205\n",
    "## 92     0.000073  0.006505   0.032986  ...  0.800589  18.086633  65.043365\n",
    "## 93     0.003308  0.003308   1.362352  ...  2.257371  20.864923  71.918164\n",
    "## 94     0.001782  0.001782   0.556939  ...  1.190116  14.054223  58.528623\n",
    "## 95     0.008780  0.445280   2.987287  ...  0.011485   0.725468  61.497821\n",
    "## \n",
    "## [96 rows x 30 columns]\n",
    "```\n",
    "\n",
    "En effet, cela effectue le résultat désiré. Cependant, il y a mieux: utiliser\n",
    "la méthode `div`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114a1cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "%timeit df.groupby('dep').agg(['min',\"median\",\"max\"]).div(1000)\n",
    "%timeit df.groupby('dep').agg(['min',\"median\",\"max\"]).apply(lambda s: s/1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5626f351",
   "metadata": {},
   "source": [
    "La méthode `div` est en moyenne plus rapide et a un temps d'exécution\n",
    "moins variable. Dans ce cas, on pourrait même utiliser le principe\n",
    "du *broadcasting* de numpy (cf. [chapitre numpy](numpy)) qui offre\n",
    "des performances équivalentes:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0ea6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit df.groupby('dep').agg(['min',\"median\",\"max\"])/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c835283d",
   "metadata": {},
   "source": [
    "`apply` est plus rapide qu'une boucle (en interne, `apply` utilise `Cython`\n",
    "pour itérer) mais reste moins rapide qu'une solution vectorisée quand\n",
    "elle existe. Ce [site](https://realpython.com/fast-flexible-pandas/#pandas-apply)\n",
    "propose des solutions, par exemple les méthodes `isin` ou `digitize`, pour\n",
    "éviter de manuellement créer des boucles lentes.\n",
    "\n",
    "En particulier, il faut noter que `apply` avec le paramètre `axis=1` est en générale lente.\n",
    "\n",
    "## Joindre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d4304c",
   "metadata": {},
   "source": [
    "Il est commun de devoir combiner des données issues de sources différentes.\n",
    "Nous allons ici nous focaliser sur le cas le plus favorable qui est la situation\n",
    "où une information permet d'apparier de manière exacte deux bases de données (autrement nous\n",
    "serions dans une situation, beaucoup plus complexe, d'appariement flou).\n",
    "\n",
    "La situation typique est l'appariement entre deux sources de données selon un identifiant\n",
    "individuel. Ici, il s'agit d'un identifiant de code commune.\n",
    "\n",
    "Il est recommandé de lire [ce guide assez complet sur la question des jointures avec R](https://linogaliana.gitlab.io/documentationR/joindre-des-tables-de-donn%C3%A9es.html) qui donne des recommandations également utiles en `python`.\n",
    "\n",
    "On utilise de manière indifférente les termes *merge* ou *join*.\n",
    "Le deuxième terme provient de la syntaxe SQL.\n",
    "En `pandas`, dans la plupart des cas, on peut utiliser indifféremment `df.join` et `df.merge`\n",
    "\n",
    "![](pandas_join.png)\n",
    "\n",
    "Il est aussi possible de réaliser un merge en utilisant la fonction `pandas.concat()` avec `axis=1`.\n",
    "Se référer à la documentation de `concat` pour voir les options possibles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfd2316",
   "metadata": {},
   "source": [
    "## Reshape\n",
    "\n",
    "On présente généralement deux types de données:\n",
    "\n",
    "    * format __wide__: les données comportent des observations répétées, pour un même individu (ou groupe), dans des colonnes différentes\n",
    "    * format __long__: les données comportent des observations répétées, pour un même individu, dans des lignes différentes avec une colonne permettant de distinguer les niveaux d'observations\n",
    "\n",
    "Un exemple de la distinction entre les deux peut être pris à l'ouvrage de référence d'Hadley Wickham, *R for Data Science*:\n",
    "\n",
    "![](https://d33wubrfki0l68.cloudfront.net/3aea19108d39606bbe49981acda07696c0c7fcd8/2de65/images/tidy-9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4020e3",
   "metadata": {},
   "source": [
    "L'aide mémoire suivante aidera à se rappeler les fonctions à appliquer si besoin:\n",
    "\n",
    "![](reshape.png)\n",
    "<!-- #endregion -->\n",
    "\n",
    "Le fait de passer d'un format *wide* au format *long* (ou vice-versa) peut être extrêmement pratique car\n",
    "certaines fonctions sont plus adéquates sur une forme de données ou sur l'autre.\n",
    "En règle générale, avec `python` comme avec `R`, les formats *long* sont souvent préférables.\n",
    "\n",
    "Le TP pandas\n",
    "<!---- reminder_badges(\"content/manipulation/02_pandas_tp.ipynb\") --->\n",
    "<a href=\"https://github.com/linogaliana/python-datascientist/blob/master/content/manipulation/02_pandas_tp.ipynb\" class=\"github\"><i class=\"fab fa-github\"></i></a>\n",
    "[![nbviewer](https://img.shields.io/badge/visualize-nbviewer-blue)](https://nbviewer.jupyter.org/github/linogaliana/python-datascientist/blob/master/content/manipulation/02_pandas_tp.ipynb)\n",
    "[![Onyxia](https://img.shields.io/badge/SSPcloud-Tester%20via%20SSP--cloud-informational&color=yellow?logo=Python)](https://datalab.sspcloud.fr/launcher/inseefrlab-helm-charts-datascience/jupyter?onyxia.friendlyName=%C2%ABpython-datascientist%C2%BB&resources.requests.memory=%C2%AB4Gi%C2%BB)\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/linogaliana/python-datascientist/master?filepath=content/manipulation/02_pandas_tp.ipynb)\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/github/linogaliana/python-datascientist/blob/master/content/manipulation/02_pandas_tp.ipynb)\n",
    "propose une série d'exemples sur la manière de restructurer les données en\n",
    "`pandas`.\n",
    "\n",
    "## Les pipe\n",
    "\n",
    "En général, dans un projet, le nettoyage de données va consister en un ensemble de\n",
    "méthodes appliquées à un `pandas.DataFrame`.\n",
    "On a vu que `assign` permettait de créer une variable dans un DataFrame.\n",
    "Il est également possible d'appliquer une fonction, appelée par exemple `my_udf` au\n",
    "DataFrame grâce à `pipe`:\n",
    "```\n",
    "df = (pd.read_csv(path2data)\n",
    "            .pipe(my_udf))\n",
    "```\n",
    "\n",
    "# Quelques enjeux de performance\n",
    "\n",
    "La librairie `dask` intègre la structure de `numpy`, `pandas` et `sklearn`.\n",
    "Elle a vocation à traiter de données en grande dimension, ainsi elle ne sera pas\n",
    "optimale pour des données qui tiennent très bien en RAM.\n",
    "Il s'agit d'une librairie construite sur la parallélisation.\n",
    "Pour aller plus loin, se référer à la [documentation de `dask`](https://docs.dask.org/en/latest/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fc28c6",
   "metadata": {},
   "source": [
    "# Références\n",
    "\n",
    "* Le site\n",
    "[pandas.pydata](https://pandas.pydata.org/pandas-docs/stable/user_guide/basics.html)\n",
    "fait office de référence\n",
    "\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
