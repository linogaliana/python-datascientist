{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e38234d7",
   "metadata": {},
   "source": [
    "#  Introduction à ElasticSearch\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61cd896",
   "metadata": {},
   "source": [
    "Pour essayer les exemples présents dans ce tutoriel : \n",
    "\n",
    "<a href=\"https://github.com/linogaliana/python-datascientist/blob/master/notebooks/course/manipulation/07_elastic.ipynb\" class=\"github\"><i class=\"fab fa-github\"></i></a>\n",
    "[![nbviewer](https://img.shields.io/badge/visualize-nbviewer-blue)](https://nbviewer.jupyter.org/github/linogaliana/python-datascientist/blob/master/notebooks/course/manipulation/07_elastic.ipynb)\n",
    "[![Onyxia](https://img.shields.io/badge/SSPcloud-Tester%20via%20SSP--cloud-informational&color=yellow?logo=Python)](https://datalab.sspcloud.fr/launcher/inseefrlab-helm-charts-datascience/jupyter?onyxia.friendlyName=%C2%ABpython-datascientist%C2%BB&resources.requests.memory=%C2%AB4Gi%C2%BB)\n",
    "\n",
    "# Introduction\n",
    "\n",
    "## Réplication de ce chapitre\n",
    "\n",
    "Ce chapitre est plus exigeant en termes d'infrastructures que les précédents.\n",
    "Il nécessite un serveur Elastic. Les utilisateurs du\n",
    "[SSP Cloud](datalab.sspcloud.fr/) pourront répliquer les exemples de ce cours\n",
    "car cette technologie est disponible (que ce soit pour indexer une base ou\n",
    "pour requêter une base existante)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc29716",
   "metadata": {},
   "source": [
    "## Cas d'usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745cc213",
   "metadata": {},
   "source": [
    "Ce notebook recense et propose d'appréhender quelques outils utilisés\n",
    "pour l'étude \"Disparités territoriales de consommation d’aliments gras, salés et sucrés\", Lino Galiana, Milena Suarez Castillo, Lionel Wilner (en cours!)\n",
    "\n",
    "> Combien de calories dans ma recette de cuisine de ce soir? Combien de calories dans mes courses de la semaine?\n",
    "\n",
    "L'objectif est de reconstituer, à partir de libellés de produits, les caractéristiques nutritionnelles d'une recette.\n",
    "Le problème est que les libellés des tickets de caisse ne sont pas des champs textuels très propres, ils contiennent, \n",
    "par exemple, beaucoup d'abbréviations, toutes n'étant pas évidentes. \n",
    "\n",
    "Voici par exemple une série de noms de produits qu'on va utiliser par la suite: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4e79bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket = ['CROISSANTS X6 400G',\n",
    "          'MAQUEREAUX MOUTAR.',\n",
    "          'IGP OC SAUVIGNON B',\n",
    "          'LAIT 1/2 ECRM UHT',\n",
    "          '6 OEUFS FRAIS LOCA',\n",
    "          'ANANAS C2',\n",
    "          'L POMME FUDJI X6 CAL 75/80 1KG ENV',\n",
    "          'PLT MIEL',\n",
    "          'STELLA ARTOIS X6',\n",
    "          'COTES DU LUBERON AIGUEBRUN 75C']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ba9ed2",
   "metadata": {},
   "source": [
    "A ces produits, s'ajoutent les ingrédients suivants, issus de la\n",
    "[recette du velouté de potiron et carottes de Marmiton](https://www.marmiton.org/recettes/recette_veloute-de-potiron-et-carottes_19009.aspx)\n",
    "qui sera notre plat principal :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f08620",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients = ['500 g de carottes',\n",
    " '2 pommes de terre',\n",
    " \"1 gousse d'ail\",\n",
    " '1/2 l de lait',\n",
    " '1/2 l de bouillon de volaille',\n",
    " \"1 cuillère à soupe de huile d'olive\",\n",
    " '1 kg de potiron',\n",
    " '1 oignon',\n",
    " '10 cl de crème liquide (facultatif)']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e108e6",
   "metadata": {},
   "source": [
    "Essayer de récupérer par webscraping cette liste est un bon exercice pour réviser\n",
    "les concepts [vus précedemment](#webscraping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58200f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "libelles = ticket + ingredients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad240993",
   "metadata": {},
   "source": [
    "On part avec cette liste dans notre supermarché virtuel. L'objectif sera de trouver\n",
    "une méthode permettant passer à l'échelle:\n",
    "automatiser les traitements, effectuer des recherches efficaces, garder une certaine généralité et flexibilité. \n",
    "\n",
    "Ce chapitre montrera par l'exemple l'intérêt d'`Elastic` par rapport à une solution \n",
    "qui n'utiliserait que du Python\n",
    "\n",
    "# Données utilisées"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b08a7e3",
   "metadata": {},
   "source": [
    "## Les bases offrant des informations nutritionnelles \n",
    "\n",
    "Pour un nombre restreint de produits, on pourrait bien-sûr chercher à\n",
    "la main les caractéristiques des produits en utilisant les \n",
    "fonctionalités d'un moteur de recherche:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40591d4",
   "metadata": {},
   "source": [
    "```r\n",
    "knitr::include_graphics(\"fraise.png\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c439fa",
   "metadata": {},
   "source": [
    "Cependant, cette approche serait très fastidieuse et \n",
    "nécessiterait de récuperer, à la main, chaque caractéristique\n",
    "pour chaque produit. Ce n'est donc pas envisageable.\n",
    "\n",
    "Les données disponibles sur Google viennent de l'[USDA](https://fdc.nal.usda.gov/),\n",
    "l'équivalent américain de notre Ministère de l'Agriculture. \n",
    "Cependant, pour des recettes comportant des noms de produits français, ainsi que \n",
    "des produits potentiellement transformés, ce n'est pas très pratique d'utiliser\n",
    "une base de données de produits agricoles en Français. Pour cette raison,\n",
    "nous proposons d'utiliser les deux bases suivantes, qui servent de base au travail de\n",
    "Galiana et al. (à venir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d734da",
   "metadata": {},
   "source": [
    "* L'[OpenFoodFacts database](https://fr.openfoodfacts.org/) qui est une base française, \n",
    "collaborative de produits alimentaires. Issue d'un projet [Data4Good](https://dataforgood.fr/), il s'agit d'une \n",
    "alternative opensource et opendata à la base de données de l'application [Yuka](https://yuka.io/). \n",
    "* La table de composition nutritionnelle [Ciqual](https://ciqual.anses.fr) produite par l'Anses. Celle-ci\n",
    "propose la composition nutritionnelle _moyenne_ des aliments les plus consommés en France. Il s'agit d'une base de données\n",
    "enrichie par rapport à celle de l'USDA puisqu'elle ne se cantonne pas aux produits agricoles non transformés. \n",
    "Avec cette base, il ne s'agit pas de trouver un produit exact mais essayer de trouver un produit type proche du produit\n",
    "dont on désire connaître les caractéristiques. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2a73c5",
   "metadata": {},
   "source": [
    "```r\n",
    "knitr::include_graphics(\"openfood.png\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c745ccdc",
   "metadata": {},
   "source": [
    "## Import \n",
    "\n",
    "Quelques fonctions utiles sont regroupées dans le script `utils.py` et importées dans le notebook. La base OpenFood peut être récupérée en ligne (opération qui peut prendre un peu de temps, on passe ici par le stockage interne de la plateforme en spécifiant `from_latest=False`). La base ciqual, plus légère, est récupérée elle directement en ligne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d31a609",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import import_openfood, import_ciqual\n",
    "openfood = import_openfood(from_latest=False)\n",
    "ciqual = import_ciqual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f15f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "openfood.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d34406f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ciqual.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e81e25d",
   "metadata": {},
   "source": [
    "# Elastic ? Mais ce n'est pas du Python ?!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98ac0d7",
   "metadata": {},
   "source": [
    "# Les produits proches au sens de la distance de Levenstein"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124a93a6",
   "metadata": {},
   "source": [
    "On appelle distance de Levenshtein entre deux chaînes de caractères le coût minimal (en nombre d'opérations) pour transformer la première en la seconde par\n",
    "* substitution\n",
    "* insertion\n",
    "* suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680594b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rapidfuzz # \"Rapid fuzzy string matching in Python and C++ using the Levenshtein Distance\" soit l'équivalent plus rapide de la librarie fuzzywuzzy\n",
    "[rapidfuzz.string_metric.levenshtein('salut','slut', weights =(1,1,1)), # Suppression \n",
    " rapidfuzz.string_metric.levenshtein('salut','saalut', weights =(1,1,1)), # Addition \n",
    " rapidfuzz.string_metric.levenshtein('salut','selut', weights =(1,1,1))] # Substitution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d5d645",
   "metadata": {},
   "source": [
    "## On va chercher les produits ciqual les plus proches de nos libellés en terme de distance textuelle classique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a9273f",
   "metadata": {},
   "source": [
    "On écrit une fonction qui prend en argument une liste de libellés d'intérêt et une liste de candidat au match et renvoie le libellé le plus proche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1259eb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def matchLevenstein(libelles, candidates):\n",
    "    matches = dict()\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    for l in libelles:\n",
    "        # Calcul de la distance de levenstein entre le libellé l et tous les candidats à l'appariemment ! \n",
    "        # Initialisation avec le premier candidat, le plus proche jusqu'à preuve du contraire\n",
    "        closest = candidates[0]\n",
    "        levmin = rapidfuzz.string_metric.levenshtein(l, closest)  \n",
    "        for candidate in candidates[1:]:\n",
    "            if rapidfuzz.string_metric.levenshtein(l, candidate) < levmin:\n",
    "                # Si un candidat se trouve être plus proche, il prend la place \n",
    "                closest = candidate\n",
    "                levmin = rapidfuzz.string_metric.levenshtein(l, candidate)\n",
    "                # (rmq: les cas d'égalité sont ici fréquents.. on favorise les derniers de la liste)\n",
    "        print(l, '-', closest)\n",
    "        matches[l]=closest\n",
    "    \n",
    "    print(80*'-')\n",
    "    print(f\"Temps d'exécution total : {(time.time() - start_time):.2f} secondes ---\")\n",
    "    \n",
    "    return matches\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bef87df",
   "metadata": {},
   "source": [
    "Quid du match dans nos bases de données?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56afd412",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = dict()\n",
    "matches['ciqual_raw'] = matchLevenstein(libelles,list(ciqual['alim_nom_fr']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc36d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches['openfood_raw'] = matchLevenstein(libelles,list(openfood['product_name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b71378b",
   "metadata": {},
   "source": [
    "Cette première étape naïve est décevante ! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e0e872",
   "metadata": {},
   "source": [
    "**On a négligé une étape importante: la normalisation (ou nettoyage des textes)**\n",
    "* harmonisation de la casse, suppression des accents...\n",
    "* suppressions des mots outils (e.g. ici on va d'abord négliger les quantités pour trouver la nature de l'aliment, en particulier pour Ciqual)\n",
    "    \n",
    "**Le temps de calcul n'est pas forcément acceptable**\n",
    "\n",
    "**La distance textuelle choisie** n'est pas toujours pertinente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2952a9e9",
   "metadata": {},
   "source": [
    "On nettoie les libellés en mobilisant des expressions régulières et un dictionnaire de mots outils. On peut adapter le nettoyage à la base, par exemple dans ciqual, la cuisson est souvent renseignée et bruite les appariemments. Plus de détails dans la formation python [\"Analyse textuelle: introduction\"](https://datalab.sspcloud.fr/my-lab/catalogue/inseefrlab-helm-charts-datascience/jupyter/deploiement?init.personnalInit=https://git.lab.sspcloud.fr/g6ginq/formation_text_mining_public/-/raw/master/installPy.sh&onyxia.friendlyName=Text_Mining_Python) disponible sur le datalab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1ff26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import clean_libelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4151f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Après avoir harmonisé la casse et retiré les accents (voir utils.py)\n",
    "stopWords = ['KG','CL','G','L','CRUE?S?', 'PREEMBALLEE?S?']\n",
    "replace_regex = {r'[^A-Z]': ' ', r'\\b[A-Z0-9]{1,2}?\\b':' '} # Retirer tout les caractères qui ne sont pas des lettres (chiffres, ponctuations); Retirer les caractères isolés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4f872e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ciqual = clean_libelle(ciqual, yvar = 'alim_nom_fr', replace_regex = replace_regex, stopWords = stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480a13b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "openfood = clean_libelle(openfood, yvar = 'product_name', replace_regex = replace_regex, stopWords = stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71076a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "libellesDF = pd.DataFrame(libelles, columns = ['libel'])\n",
    "libellesDF = clean_libelle(libellesDF, yvar = 'libel', replace_regex = replace_regex, stopWords = stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2430ebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "libellesDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c302f86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "openfood.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abbc659",
   "metadata": {},
   "outputs": [],
   "source": [
    "ciqual.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148829e2",
   "metadata": {},
   "source": [
    "Est-ce que c'est mieux? Pas encore parfait, mais on progresse sur les produits appariés! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814611e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches['openfood_clean'] = matchLevenstein(libellesDF['libel_clean'],list(openfood['libel_clean']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d058ef5",
   "metadata": {},
   "source": [
    "Pour le temps de calcul, c'est pas encore ça."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edcbef2",
   "metadata": {},
   "source": [
    "## Réduire les temps de recherche\n",
    "\n",
    "Finalement, l'idéal serait de disposer d'un **moteur de recherche** adapté à notre besoin, contenant les produits candidats, que l'on pourrait interroger, rapide en lecture, capable de classer les echos renvoyés par pertinence, que l'on pourrait requêter de manière flexible (par exemple, on pourrait vouloir signaler qu'un echo nous intéresse seulement si la donnée calorique n'est pas manquante). On pourrait même vouloir qu'il effectue pour nous des prétraitements sur les données. \n",
    "\n",
    "**Important pour la suite !**: \n",
    "\n",
    "* Lancer un service Elastic en parallèle sur le datalab via ce lien: https://datalab.sspcloud.fr/launcher/inseefrlab-helm-charts-datascience/elastic \n",
    "En pratique, une fois lancé, pas besoin d'ouvrir ce service Elastic pour continuer à suivre. \n",
    "\n",
    "_NB pour aller plus loin: Le lancement du service a créé dans votre `NAMESPACE Kubernetes` (l'ensemble de tout vos services) un cluster elastic (vous n'avez droit qu'à un cluster par namespace/compte d'utilisateur). Votre service jupyter est associé au même namespace. Pas besoin de tout saisir pour la suite, seulement que cette architecture permet à tout ce beau monde de dialoguer._\n",
    "\n",
    "Le service Elastic doit apparaître, au même titre que ce service de formation jupyter, dans vos services sur le datalab. Vous pouvez aussi vérifier que votre Jupyter sait dialoguer avec votre Elastic, qui est prêt à vous écouter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc86e28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! kubectl get statefulset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5104a52d",
   "metadata": {},
   "source": [
    "Nous allons utiliser la librairie `python` `elasticsearch` pour dialoguer avec notre moteur de recherche elastic. Les instructions ci dessous indiquent comment établir la connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69411156",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "HOST = 'elasticsearch-master'\n",
    "\n",
    "def elastic():\n",
    "    \"\"\"Connection avec Elastic sur le data lab\"\"\"\n",
    "    es = Elasticsearch([{'host': HOST, 'port': 9200}], http_compress=True,  timeout=200)\n",
    "    return es\n",
    "\n",
    "es = elastic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb00b2f",
   "metadata": {},
   "source": [
    "Maintenant que la connection est établie, deux étapes nous attendent:\n",
    "\n",
    "1. **Indexation** Envoyer les documents parmi lesquels on veut chercher des echos pertinents dans notre elastic. Un index est une collection de document. Nous pourrions en créer deux: un pour les produits ciqual, un pour les produits openfood\n",
    "2. **Requête** Chercher les documents les plus pertinents suivant une recherche textuelle flexible. Nous allons rechercher les libellés de notre recette et de notre liste de course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86327e84",
   "metadata": {},
   "source": [
    "On crée donc nos deux index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1f6dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not es.indices.exists('openfood'):\n",
    "    es.indices.create('openfood')\n",
    "if not es.indices.exists('ciqual'):\n",
    "    es.indices.create('ciqual')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f02ba5d",
   "metadata": {},
   "source": [
    "Pour l'instant, nos index sont vides! Ils contiennent 0 documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d54b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "es.count(index = 'openfood')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec44d930",
   "metadata": {},
   "source": [
    "Nous allons en rajouter quelques uns ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8955b165",
   "metadata": {},
   "outputs": [],
   "source": [
    "es.create(index = 'openfood',  id = 1, body = {'product_name': 'Tarte noix de coco', 'product_name_clean': 'TARTE NOIX COCO'})\n",
    "es.create(index = 'openfood',  id = 2, body = {'product_name': 'Noix de coco', 'product_name_clean': 'NOIX COCO'})\n",
    "es.create(index = 'openfood',  id = 3, body = {'product_name': 'Beurre doux', 'product_name_clean': 'BEURRE DOUX'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b31224",
   "metadata": {},
   "outputs": [],
   "source": [
    "es.count(index = 'openfood')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cb0244",
   "metadata": {},
   "source": [
    "Faisons notre première recherche: cherchons des noix de pécan! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bab87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "es.search(index = 'openfood', q = 'noix de pécan')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0309d2",
   "metadata": {},
   "source": [
    "Intéressons nous aux `hits` (résultats pertinents, ou echos) : nous en avons 2, le score maximal parmi les hits est mentionné dans `max_score` et correspond à celui du deuxième document indexé. Elastic nous fournit ici un **score de pertinence** dans notre recherche d'information, et classe ainsi les documents renvoyés.\n",
    "\n",
    "Ici nous utilisons la configuration par défaut. Mais comment est calculé ce score?? Demandons à Elastic de nous expliquer le score du document `2` dans la requête `\"noix de pécan\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9933c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "es.explain(index = 'openfood', id = 2, q = 'noix de pécan')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5d2ce9",
   "metadata": {},
   "source": [
    "## En déduire ici comment est calculée la pertinence\n",
    "\n",
    "Elastic nous explique donc que le score 0.9400072 est le maximum entre deux sous-scores, 0.4991 et 0.9400072. Pour chacun de ces sous scores, le détail de son calcul est donné. Le premier sous-score n'a accordé un score que par rapport au premier mot (noix), tandis que le second a accordé un score sur la base des deux mots déjà connu dans les documents (\"noix\" et \"de\"). Il a ignoré pécan! Jusqu'à présent, ce terme n'est pas connu dans l'index. \n",
    "\n",
    "La pertinence d'un mot pour notre recherche est construite sur une variante de la TF-IDF, considérant qu'un terme est pertinent s'il est souvent présent dans le document (Term Frequency) alors qu'il est peu fréquent dans les autres document (inverse document frequency). Ici les notations des documents 1 et 2 sont très proches, la différence est du à des IDF plus faibles dans le document 1, qui est pénalisé pour être légérement plus long. \n",
    "\n",
    "Bref, tout ça est un peu lourd, mais assez efficace, en tout cas moins rudimentaire que les distances caractères à caractères pour ramener des echos pertinents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecf2265",
   "metadata": {},
   "source": [
    "## Par contre pour l'instant, Elastic n'a pas l'air de gérer les fautes de frappes!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf97fb6",
   "metadata": {},
   "source": [
    "Pas le droit à l'erreur dans la requête:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c6263f",
   "metadata": {},
   "outputs": [],
   "source": [
    "es.search(index = 'openfood',q = 'TART NOI')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bd19fa",
   "metadata": {},
   "source": [
    "Cela s'explique par la représentation des champs ('product_name' par exemple) qu'Elastic a inferré, puisque nous n'avons rien spécifié, représentations qui conditionnent la façon dont les champs sont analysés pour calculer la pertinence. Par exemple, regardons la représentation du champ `product_name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b12f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "es.indices.get_field_mapping(index = 'openfood', fields = 'product_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6486303",
   "metadata": {},
   "source": [
    "Elastic a compris qu'il s'agissait d'un champ textuel, par contre, le type est `keyword` n'autorisant donc pas des analyses approximatives. Pour qu'un echo remonte, un des termes doit matcher exactement. Dommage ! Mais c'est parcequ'on a utilisé le mapping par défaut. En réalité, il est assez simple de préciser un mapping plus riche, autorisant une analyse \"fuzzy\" ou \"flou\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9104d0",
   "metadata": {},
   "source": [
    "# Une meilleure spécification du mapping, ou de comment vont être compris et analysé nos champs textuels lors des recherches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834aba81",
   "metadata": {},
   "source": [
    "**On peut spécifier la façon dont l'on souhaite analyser le texte.** Par exemple, on peut préciser que l'on souhaite enlever des stopwords, raciniser, analyser les termes via des n-grammes pour rendre la recherche plus robuste aux fautes de frappes... Pour une présentation plus complète, voir https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping.html   \n",
    "**L'important à retenir à ce stade est la flexibilité de l'outil.** On fournit dans la suite un fichier `settings_OpenFood.json` qui permet de préciser que nous souhaitons par exemple que les matchs sur n-grammes participent au score. Les n-grammes sont des séquences de n caractères ou plus généralement n éléments qui s'enchaînent séquentiellement. Par exemple, NOI et OIX sont des tri-grammes de caractères dans NOIX. Comparer les n-grammes composant des libellés peut permettre d'avoir dans des comparaisons à fautes de frappe/abbréviations près. Cela fait aussi plus de comparaisons à opérer ! D'où également, l'intérêt d'Elastic, qui intégre facilement et efficacement ces comparaisons. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1c11f8",
   "metadata": {},
   "source": [
    "On va préciser un peu le schéma de données qu'on souhaite _indexer_, et aussi préciser comment les différents champs seront _analysés_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d152d813",
   "metadata": {},
   "source": [
    "### Une indexation plus adaptée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426dadda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "if es.indices.exists('openfood'):\n",
    "    es.indices.delete('openfood')\n",
    "\n",
    "with open('settings_OpenFood.json') as f:\n",
    "    mapping = json.load(f)\n",
    "    \n",
    "es.indices.create(index = \"openfood\", body = mapping)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea993d03",
   "metadata": {},
   "source": [
    "Maintenant, les champs textuels \"product_name\" et \"product_name_clean\" vont pouvoir être analysé aussi via leur n-grammes et après racinisation (et l'un n'exclut pas l'autre!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88724b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "es.indices.get_field_mapping(index = 'openfood', fields = 'product_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52a3666",
   "metadata": {},
   "source": [
    "La fonction suivante va vous faire gagner du temps: **c'est parti, on envoie toute notre base OpenFood pour pouvoir la requêter!** Parcequ'en rester à 3 documents entrés à la main, ce n'est pas sérieux.\n",
    "\n",
    "Du coup ça prend quelques minutes ... mais c'est pour nous en faire gagner ensuite. Cette opération est faite une fois, pour préparer des requêtes potentiellement nombreuses!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a9e550",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import index_elastic\n",
    "index_elastic(es =es, index_name = \"openfood\",setting_file = 'settings_OpenFood.json', df = openfood[['product_name',\"libel_clean\",\"energy_100g\",\"nutriscore_score\"]].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec32280",
   "metadata": {},
   "outputs": [],
   "source": [
    "es.count(index = 'openfood')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b636f62d",
   "metadata": {},
   "source": [
    "## Nos premières requêtes\n",
    "\n",
    "Vérifions qu'on recupère quelques tartes aux noix même si l'on fait plein de fautes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37221e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "es.search(index = 'openfood', q = 'TART NOI', size = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03647f8",
   "metadata": {},
   "source": [
    "Et c'est plutôt rapide non?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0ac252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchElastic(libelles):\n",
    "    matches = dict()\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    for l in libelles:\n",
    "        response = es.search(index = 'openfood', q = l, size = 1)\n",
    "        if len(response['hits']['hits'])>0:\n",
    "            matches[l] = response['hits']['hits'][0]['_source']['libel_clean']\n",
    "    print(80*'-')\n",
    "    print(f\"Temps d'exécution total : {(time.time() - start_time):.2f} secondes ---\")\n",
    "    \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fce6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = matchElastic(libellesDF['libel_clean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db4fd73",
   "metadata": {},
   "source": [
    "Et voilà, on a un outil très rapide de requête (à noter que je dispose d'un elastic probablement configuré différemment du votre, les performances peuvent varier), maintenant **on peut préciser des requêtes plus sophistiquées!**\n",
    "\n",
    "En fait on a pas nettoyé les champs pour rien! On veut maintenant que notre requête porte spécifiquement sur le champ \"libel_clean\" (et pas indifféremment sur tout les champs textuels du document), ou encore en filtrant les produits avec un bon nutriscore.. Par exemple, des huiles d'olive avec un bon nutri score? \n",
    "\n",
    "à vous de déchiffrer cette requête (QUERY DSL)! Vous pouvez aussi explorer les possibilités de requêtes via la [doc Elastic](https://www.elastic.co/guide/en/elasticsearch/reference/6.8/query-dsl.html) et vous entrainer à un écrire avec votre index tout neuf.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2820376",
   "metadata": {},
   "outputs": [],
   "source": [
    "body = '''\n",
    "{\n",
    "  \"size\": \"1\",\n",
    "  \"query\": {\n",
    "    \"bool\": {\n",
    "      \"should\": [\n",
    "        { \"match\": { \"libel_clean\":  { \"query\":  \"HUILE OLIVE\" , \"boost\" : 10}}},\n",
    "        { \"match\": { \"libel_clean.ngr\":   \"HUILE OLIVE\" }}],\n",
    "      \"minimum_should_match\": 1,\n",
    "      \"filter\": [\n",
    "      { \n",
    "            \"range\" : {\n",
    "                \"nutriscore_score\" : {\n",
    "                    \"gte\" : 10,\n",
    "                    \"lte\" : 20\n",
    "                    }\n",
    "                    }\n",
    "                    }\n",
    "      ]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40600ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "es.search(index = 'openfood', body = body)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26083143",
   "metadata": {},
   "source": [
    "Qu'a-t-on demandé ici? De renvoyer 1 et 1 seul echo (`\"size\":\"1\"`) et seulement si celui ci a:\n",
    "* `\"should\"`: Au moins un (`\"minimum_should_match\":\"1\"`) des termes des deux champs `libel_clean` et `libel_clean.ngr` qui matche sur un terme de _HUILE OLIVE_, l'analyse (la définition du \"terme\") étant réalisé soit en tant que `text` (\"libel_clean\") soit en tant que n-gramme `ngr` (\"libel_clean.ngr\", une analyse que nous avons spécifié dans le mapping) \n",
    "* `\"filter\"`: Le champ `float` nutriscore_score doit être compris entre 10 et 20 (\"filter\").  \n",
    "\n",
    "A noter :\n",
    "1. Les clauses (`\"should\"`+`\"minimum_should_match\":\"1\"`) peuvent être remplacé par un `\"must\"`, auquel cas, l'echo doit obligatoirement matché sur chaque clause.\n",
    "2. Préciser dans `\"filter\"` (plutôt que dans \"`should`\") une condition signifie que celle-ci ne participe pas au score de pertinence. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bd5dce",
   "metadata": {},
   "source": [
    "**C'est pas tout ça, mais on a pas encore un appariemment très satisfaisant, en particulier sur les boissons**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96537a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb0e01b",
   "metadata": {},
   "source": [
    "## S'aider de dictionnaires, et les construire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8402827b",
   "metadata": {},
   "source": [
    "Une méthode simple pour faire comprendre par exemple que \"Stella Artois\" est une marque de bière est de créer un dictionnaire de marques de bière. A partir de celui-ci, on pourra déterminer si oui ou non on a affaire à une bière. C'est typiquement de l'information connue, publique. On enrichie ainsi l'information disponible. \n",
    "\n",
    "Oui sauf que à la main, c'est pas très marrant!\n",
    "\n",
    "Alors comment récupérer cela efficacement? Wikipedia offre un service web qui donne accès à ses contenus (à utiliser sans en abuser, voir les bonnes pratiques https://www.mediawiki.org/wiki/API:Etiquette). Cela peut être une idée pour constituer des listes de marques. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0531090c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import re\n",
    "\n",
    "def dictionnary_from_wiki_category(categorie = ['Bière blonde','Vin_français','Marque de bière'], n: int = 10, filters = 'Utilisateur|Discussion|Classement|Liste|Catégorie', sub='\\(.*\\)'):\n",
    "    if isinstance(categorie, list):\n",
    "        categorie = categorie[0]\n",
    "    url = \"https://fr.wikipedia.org/w/api.php?action=query&list=categorymembers&cmtitle=Category:\" + urllib.parse.quote(categorie) + \"&cmlimit=\" + str(n) + \"&format=json\"\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        jsonresp = response.read()\n",
    "    jsonresp = json.loads(jsonresp)['query']['categorymembers']\n",
    "    if len(jsonresp)>1:\n",
    "        res = [re.sub(sub,'',x['title']).strip() for x in jsonresp if not re.match(filters,x['title'])]\n",
    "        return(res)\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a190af49",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionnary_from_wiki_category(\"Marque de bière\", n = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc9f4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionnary_from_wiki_category(\"Fromage français\", n = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6211291",
   "metadata": {},
   "source": [
    "**Et donc?** \n",
    "\n",
    "à ce stade et faute d'information supplémentaire, on peut associer à toutes les appellations de vins rouges, ou encore toutes les appelations de fromage non encore appariées, leur qualité nutritionnelle moyenne (https://ciqual.anses.fr/#/aliments/5210/vin-(aliment-moyen) ou https://ciqual.anses.fr/#/aliments/12999/fromage-(aliment-moyen)). Etant donné la diversité de ces classes dans le panier de consommation des français, cela peut valoir le coup.\n",
    "\n",
    "Cela peut se faire en créant par exemple un index elastic à partir de ces listes de produits wikipédia (associé à une information nutritionnelle \"moyenne\") pour venir y requêter les produits du reliquat. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4a2705",
   "metadata": {},
   "source": [
    "# Considérer les embeddings de mots existants?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c3e7b8",
   "metadata": {},
   "source": [
    "Elastic ramène des echos en général bien ordonnés par pertinence, très bien, mais typiquement, cela peut ratisser large, surtout quand on utile les n-grammes ! Et parfois, il n'y a tout simplement pas l'information dans Ciqual ou Openfood Facts. \n",
    "Il faut donc définir un critère pour décider de classer le premier echo comme un match, **soit une notion de proximité entre deux libellés**. Une possibilité est d'avoir recours aux distances textuelles classiques, dérivées de la distance de levenstein (avec par exemple une normalisation pour tenir compte de la longueur variable des libellés). \n",
    "\n",
    "Une autre option pour définir des distances entre les termes est de s'appuyer sur champ de recherche récent qui cherche à définir des \"plongements de mots\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a15d02f",
   "metadata": {},
   "source": [
    "**Word Embeddings ou plongement de mots:** représentation vectorielle des chaînes de charactères, de mots, de phrases, de la langue en général, obtenu à partir de modèles de Deep Learning entraînés sur des corpus de texte importants. cf [l'introduction à l'analyse textuelle dans ce set de formation qui évoque Word2Vec](https://datalab.sspcloud.fr/my-lab/catalogue/inseefrlab-helm-charts-datascience/jupyter/deploiement?init.personnalInit=https://git.lab.sspcloud.fr/g6ginq/formation_text_mining_public/-/raw/master/installPy.sh&onyxia.friendlyName=Text_Mining_Python).\n",
    "\n",
    "\n",
    "Des plongements de mots spécifiques à la langue française sont mis à dispositions par des équipes de recherches:  \n",
    "https://camembert-model.fr/  \n",
    "https://github.com/getalp/Flaubert   \n",
    "\n",
    "Là aussi, on prend un peu de temps à installer les librairies nécessaires, et à charger les plongements de mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3de416",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q -q -q torch transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac37fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import FlaubertModel, FlaubertTokenizer\n",
    "\n",
    "modelname = 'flaubert/flaubert_base_cased' \n",
    "\n",
    "# Load pretrained model and tokenizer\n",
    "flaubert, log = FlaubertModel.from_pretrained(modelname, output_loading_info=True)\n",
    "flaubert_tokenizer = FlaubertTokenizer.from_pretrained(modelname, do_lowercase=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988a0780",
   "metadata": {},
   "source": [
    "Calculons quelques distances entre quelques libellés bien choisis au sens de l'embedding \"Flaubert\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d6cfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib1 = \"bière framboise\"\n",
    "lib2 = \"barquette framboises\"\n",
    "lib3 = \"bière blonde\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c472e3f",
   "metadata": {},
   "source": [
    "Représentation en `token` (un enchaînement de caractère = 1 entier l'indexant) `flaubert_tokenizer.encode`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c2352d",
   "metadata": {},
   "outputs": [],
   "source": [
    "token1 = torch.tensor([flaubert_tokenizer.encode(lib1)])\n",
    "token2 = torch.tensor([flaubert_tokenizer.encode(lib2)])\n",
    "token3 = torch.tensor([flaubert_tokenizer.encode(lib3)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99c63f3",
   "metadata": {},
   "source": [
    "Représentation vectorielle dense (moyenne des représentations vectorielles de chaque token), en passant les tokens au modèle `flaubert`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06842a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec1 = flaubert(token1)[0].mean(axis = 1)\n",
    "vec2 = flaubert(token2)[0].mean(axis = 1)\n",
    "vec3 = flaubert(token3)[0].mean(axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccd5d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "[torch.sum((vec1-vec2)**2),torch.sum((vec3-vec2)**2),torch.sum((vec1-vec3)**2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2d28b4",
   "metadata": {},
   "source": [
    "Les deux bières sont plus proches l'une de l'autre que les autres couples de libellés. Mais ça demande un peu plus d'exploration à ce stade, voire de retravailler cet embedding pour notre problème. A noter que ces embeddings ne sont pas vraiment pensés pour des libellés courts et bruités, plutôt pour des textes. \n",
    "\n",
    "Reentrainés à la marge pour notre cas d'usage ([\"tranfer learning\"](https://blog.baamtu.com/en/word2vec-camembert-use-embedding-models/\n",
    ")), en supposant que nous disposons d'un échantillon d'entrainement de \"vrai\" couples de libellés appariés), nous pourrions peut être disposer d'une distance textuelle moins rudimentaire que la distance de levenstein.\n",
    "\n",
    "C'est en effet l'ambition des embeddings de mots de représenter la sémantique au delà de la proximité des chaînes de caractères."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484933bb",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07660373",
   "metadata": {},
   "source": [
    "On a pas encore calculé notre apport total de calories sur la base de notre liste, plutôt exploré quelques idées pour traiter le problème. A vous de jouer maintenant avec tout ces ingrédients! Bon appétit\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
