{
 "cells": [
  {
   "cell_type": "raw",
   "id": "f5643856",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Pratique de geopandas: données vélib\"\n",
    "date: 2020-07-09T13:00:00Z\n",
    "draft: false\n",
    "weight: 50\n",
    "slug: geopandasTP\n",
    "tags:\n",
    "  - geopandas\n",
    "  - cartes\n",
    "  - velib\n",
    "categories:\n",
    "  - Exercice\n",
    "type: book\n",
    "summary: |\n",
    "  Ce chapitre illustre les fonctionalités de geopandas à partir des\n",
    "  décomptes de vélo fournis par la ville de Paris en opendata. Il prolonge\n",
    "  le chapitre précédent avec des données un petit peu plus complexes\n",
    "  à manipuler.\n",
    "eval: false\n",
    "echo: false\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a0bf445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"https://github.com/linogaliana/python-datascientist/blob/master/notebooks/course/manipulation/03_geopandas_TP.ipynb\" class=\"github\"><i class=\"fab fa-github\"></i></a>\n",
      "[![Download](https://img.shields.io/badge/Download-Notebook-important?logo=Jupyter)](https://downgit.github.io/#/home?url=https://github.com/linogaliana/python-datascientist/blob/master/notebooks/course/manipulation/03_geopandas_TP.ipynb)\n",
      "[![nbviewer](https://img.shields.io/badge/Visualize-nbviewer-blue?logo=Jupyter)](https://nbviewer.jupyter.org/github/linogaliana/python-datascientist/blob/master/notebooks/course/manipulation/03_geopandas_TP.ipynb)\n",
      "[![Onyxia](https://img.shields.io/badge/SSPcloud-Tester%20via%20SSP--cloud-informational&color=yellow?logo=Python)](https://datalab.sspcloud.fr/launcher/inseefrlab-helm-charts-datascience/jupyter?autoLaunch=true&onyxia.friendlyName=%C2%ABpython-datascience%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%ABnotebooks/course/manipulation%2003_geopandas_TP.ipynb%C2%BB&security.allowlist.enabled=false)<br>\n",
      "[![Binder](https://img.shields.io/badge/Launch-Binder-E66581.svg?logo=data:image/png;base64,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)](https://mybinder.org/v2/gh/linogaliana/python-datascientist/master?filepath=notebooks/course/manipulation/03_geopandas_TP.ipynb)\n",
      "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/github/linogaliana/python-datascientist/blob/master/notebooks/course/manipulation/03_geopandas_TP.ipynb)\n",
      "[![githubdev](https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc)](https://github.dev/linogaliana/python-datascientist/notebooks/course/manipulation/03_geopandas_TP.ipynb)\n"
     ]
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: 'asis'\n",
    "#| include: true\n",
    "#| eval: true\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../../../../') #insert the utils module\n",
    "from utils import print_badges\n",
    "\n",
    "#print_badges(__file__)\n",
    "print_badges(\"content/course/manipulation/03_geopandas_TP.qmd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0aee3e6",
   "metadata": {},
   "source": [
    "Installations préalables : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc9424bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: true\n",
    "#| include: true\n",
    "\n",
    "!pip install pandas fiona shapely pyproj rtree # à faire obligatoirement en premier pour utiliser rtree ou pygeos pour les jointures spatiales\n",
    "!pip install contextily\n",
    "!pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "400d64ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: true\n",
    "\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b81e36",
   "metadata": {},
   "source": [
    "# Lire et enrichir des données spatiales\n",
    "\n",
    "Dans cette partie, nous utiliserons la fonction suivante, qui facilite \n",
    "le téléchargement et le dézippage des données proposées sur `data.gouv`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d62dd407",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: true\n",
    "#| include: true\n",
    "\n",
    "import requests\n",
    "import tempfile\n",
    "import zipfile\n",
    "\n",
    "temporary_location = tempfile.gettempdir()\n",
    "\n",
    "def download_unzip(url, dirname = tempfile.gettempdir(), destname = \"borders\"):\n",
    "  myfile = requests.get(url)\n",
    "  open(dirname + '/' + destname + '.zip', 'wb').write(myfile.content)\n",
    "  with zipfile.ZipFile(dirname + '/' + destname + '.zip', 'r') as zip_ref:\n",
    "      zip_ref.extractall(dirname + '/' + destname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be4a0d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) Chargement des packages utilisés dans la partie tutoriel\n",
    "import geopandas as gpd\n",
    "import contextily as ctx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab06a8b",
   "metadata": {},
   "source": [
    "{{% box status=\"exercise\" title=\"Exercice 1: lire et explorer la structure de fichiers géographiques\" icon=\"fas fa-pencil-alt\" %}}\n",
    "1. Utiliser la fonction `download_unzip` avec l'url <https://www.data.gouv.fr/fr/datasets/r/07b7c9a2-d1e2-4da6-9f20-01a7b72d4b12>\n",
    "pour télécharger les données communales.\n",
    "2. Importer le fichier avec la package `geopandas`\n",
    "(si vous avez laissé les paramètres par défaut,\n",
    "le fichier devrait\n",
    "être à l'emplacement `temporary_location + \"/borders/communes-20190101.json\"`).\n",
    "Vous pouvez le nommer `communes_borders`\n",
    "3. Regarder les premières lignes des données. Identifier la différence avec\n",
    "un DataFrame standard. \n",
    "4. Afficher l'attribut `crs` de `communes_borders`. Ce dernier contrôle la\n",
    "transformation de l'espace tridimensionnel terrestre en une surface plane. \n",
    "5. Afficher les communes de l'Aveyron (département 12) et utiliser la méthode\n",
    "`plot`\n",
    "6. Réprésenter la carte de Paris : quel est le problème ?\n",
    "{{% /box %}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbb6c5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) télécharger les données communales\n",
    "url = \"https://www.data.gouv.fr/fr/datasets/r/07b7c9a2-d1e2-4da6-9f20-01a7b72d4b12\"\n",
    "download_unzip(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "890e4ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Importer le fichier\n",
    "communes_borders = gpd.read_file(temporary_location + \"/borders/communes-20190101.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b35e62c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Regarder les premières lignes\n",
    "communes_borders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d862183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Afficher le crs\n",
    "communes_borders.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f09d10bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) afficher les communes du département 12\n",
    "communes_borders[communes_borders.insee.str.startswith(\"12\")].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b933cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Représenter la carte de Paris. Quel est le problème ?\n",
    "communes_borders[communes_borders.insee.str.startswith(\"75\")].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7140a3e",
   "metadata": {},
   "source": [
    "En effet, on ne dispose ainsi pas des limites des arrondissements parisiens, ce\n",
    "qui appauvrit grandement la carte de Paris. On peut les récupérer directement \n",
    "depuis le site d'open data du grand Paris\n",
    "(cf. [tutoriel du chapitre précédent](geopandas)).\n",
    "\n",
    "\n",
    "{{% box status=\"exercise\" title=\"Exercice 2: compléter des données spatiales issues de sources différentes\" icon=\"fas fa-pencil-alt\" %}}\n",
    "\n",
    "\n",
    "1. Importer les données de découpage des arrondissements parisiens à l'adresse\n",
    "<https://opendata.paris.fr/explore/dataset/arrondissements/download/?format=geojson&timezone=Europe/Berlin&lang=fr>\n",
    "2. Vérifier sur une carte que les découpages des arrondissements sont bien présents\n",
    "3. Vérifier l'attribut `crs`. Est-il cohérent avec celui des données communales ?\n",
    "4. Retirer Paris du jeu de données communales et utiliser les arrondissements\n",
    "pour enrichir (nommer l'objet obtenu `data_borders`). Ici, on peut ne pas se\n",
    "soucier de la variable commune de superficie aux niveaux différents car on\n",
    "va la recréer. En revanche, renommer la variable `c_arinsee` en `insee` avec\n",
    "la méthode `rename` et faire attention aux types des variables\n",
    "5. Créer une variable `dep` stockant le département\n",
    "6. Représenter les communes de la petite couronne parisienne (75, 92, 93, 94)\n",
    "{{% /box %}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86f83977",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) Importer arrondissements\n",
    "arrondissements = gpd.read_file(\"https://opendata.paris.fr/explore/dataset/arrondissements/download/?format=geojson&timezone=Europe/Berlin&lang=fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a7dd542",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2) Vérifier présence arrondissements\n",
    "arrondissements.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b307394",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3) Vérifier l'attribut `crs`. Est-il cohérent ?\n",
    "print(communes_borders.crs)\n",
    "print(communes_borders.crs == arrondissements.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7c1574e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4) Retirer Paris et ajouter les arrondissements\n",
    "arrondissements = arrondissements.rename(columns = {\"c_arinsee\": \"insee\"})\n",
    "arrondissements['dep'] = \"75\"\n",
    "data_paris = communes_borders[~communes_borders.insee.str.startswith(\"75\")].append(arrondissements)\n",
    "data_paris.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26e00866",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5)  Créer une variable `dep`\n",
    "data_paris['dep'] # Il y a des NA qui proviennent de la base communes_borders\n",
    "data_paris['dep'] = data_paris.insee.astype(str).str[:2] # donc on recrée la var dep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b6ee7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6) Représenter les communes du 75, 92, 93, 94\n",
    "data_paris[data_paris['dep'].isin(['75','92','93','94'])].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de87cf6d",
   "metadata": {},
   "source": [
    "# Utiliser des données géographiques comme des couches graphiques\n",
    "\n",
    "Souvent, le découpage communal ne sert qu'en fond de cartes, pour donner des\n",
    "repères. En complément de celui-ci, on peut désirer exploiter\n",
    "un autre jeu de données. On va partir des données de localisation des\n",
    "stations velib, \n",
    "disponibles [sur le site d'open data de la ville de Paris](https://opendata.paris.fr/explore/dataset/velib-emplacement-des-stations/table/) et \n",
    "requêtables directement par l'url\n",
    "<https://opendata.paris.fr/explore/dataset/velib-emplacement-des-stations/download/?format=geojson&timezone=Europe/Berlin&lang=fr>\n",
    "\n",
    "{{% box status=\"exercise\" title=\"Exercice 3: importer et explorer les données velib\" icon=\"fas fa-pencil-alt\" %}}\n",
    "1. Importer les données velib sous le nom `station`\n",
    "2. Représenter sur une carte les 50 stations les plus importantes (variable `capacity`). Vous pouvez également afficher le fonds de carte des arrondissements en ne gardant que les départements de la petite couronne (75, 92, 93, 94).\n",
    "Cette [page](https://geopandas.org/mapping.html#maps-with-layers) peut vous aider pour afficher plusieurs couches à la fois.\n",
    "3. Afficher également les réseaux de transport en communs, disponibles [ici](https://data.iledefrance-mobilites.fr/explore/dataset/traces-du-reseau-ferre-idf/map/?location=7,48.69717,2.33167&basemap=jawg.streets). L'url à requêter est\n",
    "<https://data.iledefrance-mobilites.fr/explore/dataset/traces-du-reseau-ferre-idf/download/?format=geojson&timezone=Europe/Berlin&lang=fr>\n",
    "{{% /box %}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56a08051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Importer les données velib\n",
    "url = \"https://opendata.paris.fr/explore/dataset/velib-emplacement-des-stations/download/?format=geojson&timezone=Europe/Berlin&lang=fr\"\n",
    "stations = gpd.read_file(url)\n",
    "stations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88d0e1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Carte des 50 stations les plus importantes. \n",
    "base = data_paris[data_paris['dep'] == '75'].plot(alpha = 0.2, edgecolor = 'black')\n",
    "stations.sort_values('capacity', ascending = False).head(50).plot(ax = base, color = 'red', alpha = 0.6)\n",
    "transports[transports['mode'] == \"Metro\"].plot(ax = base, color = 'black', alpha = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4dac723a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Réseaux de transport en communs\n",
    "url = \"https://data.iledefrance-mobilites.fr/explore/dataset/traces-du-reseau-ferre-idf/download/?format=geojson&timezone=Europe/Berlin&lang=fr\"\n",
    "transports = gpd.read_file(url)\n",
    "transports.head()\n",
    "print(transports['mode'].unique())\n",
    "base = data_paris[data_paris['dep'] == '75'].plot(alpha = 0.2, edgecolor = 'black') #base carto des arrondissements\n",
    "stations.sort_values('capacity', ascending = False).head(50).plot(ax = base, color = 'red', alpha = 0.6) #points des 50 stations\n",
    "transports[transports['mode'] == \"Metro\"].plot(ax=base, color = 'black', alpha = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7040d01",
   "metadata": {},
   "source": [
    "# Jointures spatiales\n",
    "\n",
    "Les jointures attributaires fonctionnent comme avec un DataFrame `pandas`. Pour conserver un objet spatial *in fine*, il faut faire attention à utiliser en premier (base de gauche) l'objet `geopandas`. En revanche, l'un des intérêts des objets geopandas est qu'on peut également faire une jointure sur la dimension spatiale.\n",
    "\n",
    "La documentation à laquelle se référer est [ici](https://geopandas.org/mergingdata.html#spatial-joins). \n",
    "\n",
    "{{% box status=\"exercise\" title=\"Exercice 4: Associer les stations aux communes et arrondissements auxquels elles appartiennent\" icon=\"fas fa-pencil-alt\" %}}\n",
    "1. Faire une jointure spatiale pour enrichir les données de stations en y ajoutant des informations de `data_paris`. Appeler cet objet `stations_info`\n",
    "2. Représenter la carte des stations du 19e arrondissement (s'aider de la variable `c_ar`). Vous pouvez mettre en fond de carte les arrondissements parisiens. \n",
    "3. Compter le nombre de stations velib et le nombre de places velib par arrondissement ou commune (pour vous aider, vous pouvez compléter vos connaissances avec [ce tutoriel](https://pandas.pydata.org/docs/getting_started/intro_tutorials/06_calculate_statistics.html)). Représenter sur une carte chacune des informations\n",
    "4. Représenter les mêmes informations mais en densité (diviser par la surface de l'arrondissement ou commune en km2)\n",
    "{{% /box %}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2fb72e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.  Jointure spatiale entre stations et data_paris\n",
    "stations_info = gpd.sjoin(stations, data_paris, op = 'within')\n",
    "stations_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30bbbb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Carte des stations du 19e arrondissement\n",
    "# Méthode 1 : En affichant tout Paris\n",
    "base = data_paris[data_paris.dep == \"75\"].plot(alpha = 0.2, edgecolor = 'k') #fond de carte des arrondissements\n",
    "stations_info[stations_info['c_ar'] == 19.0].plot(ax = base, color = 'red', alpha = 0.6) # stations du 19e\n",
    "# Méthode 2 : En affichant seulement le 19e\n",
    "base = data_paris[data_paris['c_ar'] == 19.0].plot(alpha = 0.2, edgecolor = 'k') #fond de carte du 19e\n",
    "stations_info[stations_info['c_ar'] == 19.0].plot(ax = base, color = 'red', alpha = 0.6) #stations du 19e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91bdf9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Nombre de stations et de places vélib par arrondissement\n",
    "stations_agg = stations_info.groupby('insee').agg({'stationcode': 'nunique',\n",
    "                                   'capacity': 'sum'}).reset_index()\n",
    "stations_agg.head()\n",
    "df = data_paris.merge(stations_agg, how = 'inner')\n",
    "df.head()\n",
    "df.plot(column = 'capacity', legend=True)\n",
    "df.plot(column = 'stationcode', legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30cb070f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. En densité\n",
    "cols = ['stationcode','capacity']\n",
    "df[[s + '_density' for s in cols]] = df[cols].div(df.to_crs(2158).area*10**(-6), axis = 0)\n",
    "df.plot(column = 'capacity_density', cmap = 'RdYlBu_r', legend=True)\n",
    "df.plot(column = 'capacity_density', cmap = 'plasma_r', legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f5b338",
   "metadata": {},
   "source": [
    "# Trouver la station la plus proche\n",
    "\n",
    "\n",
    "Une aide [ici](https://pysal.org/scipy2019-intermediate-gds/deterministic/gds1-relations.html#how-about-nearest-neighbor-joins)\n",
    "\n",
    "Cet exemple peut également vous aider à comprendre certains concepts : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb6acb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.ops import Polygon\n",
    "from shapely.ops import nearest_points\n",
    "triangle = Polygon([(0, 0), (1, 0), (0.5, 1), (0, 0)])\n",
    "square = Polygon([(0, 2), (1, 2), (1, 3), (0, 3), (0, 2)])\n",
    "[o.wkt for o in nearest_points(triangle, square)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c00d674",
   "metadata": {},
   "source": [
    "{{% box status=\"exercise\" title=\"Exercice 5 (optionnel): Trouver la station de métro la plus proche d'une station de vélib\" icon=\"fas fa-pencil-alt\" %}}\n",
    "1. Charger la localisation des stations de transports présente ici : https://data.ratp.fr/explore/dataset/accessibilite-des-gares-et-stations-metro-et-rer-ratp/download/?format=geojson&timezone=Europe/Berlin&lang=fr. Appelez-la `stations_transport` et ne gardez que les variables 'nomptar' et 'geometry'. \n",
    "2. Trouver la station de transport la plus proche de la station de vélib \"Edgard Quinet - Gaité\". La ligne de code `ensemble_stations = stations_transport.unary_union` vous sera utile ainsi que l'importation de la fonction `from shapely.ops import nearest_points`.\n",
    "3. Généraliser aux 10 premières lignes de la table `stations` des vélibs en indiquant pour chaque station velib quelle est la station de transport en commun la plus proche dans une nouvelle colonne appelée `Nearest`.\n",
    "\n",
    "{{% /box %}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7cd60f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Charger les stations de transport\n",
    "# lien mort\n",
    "#stations_transport = gpd.read_file(\"https://data.ratp.fr/explore/dataset/positions-geographiques-des-stations-du-reseau-ratp/download/?format=geojson&timezone=Europe/Berlin&lang=fr\")\n",
    "stations_transport = gpd.read_file(\"https://data.ratp.fr/explore/dataset/accessibilite-des-gares-et-stations-metro-et-rer-ratp/download/?format=geojson&timezone=Europe/Berlin&lang=fr\")\n",
    "stations_transport = stations_transport[['nomptar','geometry']].dropna() #car sinon il y a des problèmes dans la gestion géographique\n",
    "stations_transport.head()\n",
    "stations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29b98df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Trouver la station de transport la plus proche de la station de vélib \"Edgard Quinet - Gaité\"\n",
    "ensemble_stations = stations_transport.unary_union\n",
    "ensemble_stations\n",
    "from shapely.ops import nearest_points\n",
    "edgard_quinet_gaite = stations[stations.name == 'Edgar Quinet - Gaité'].iloc[0,] #le iloc est fait pour passer d'un pd à un pd.series, sinon bug.\n",
    "nearest = nearest_points(edgard_quinet_gaite['geometry'], ensemble_stations)[1]\n",
    "stations_transport[stations_transport['geometry'] == nearest][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa8202cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A améliorer dans la forme du code (je suis passée par des listes alors que je n'aurais probablement pas du). KA\n",
    "\n",
    "#3. Fonction qui généralise aux 10 premières stations de la base de données\n",
    "def find_nearest(numero_station):\n",
    "      station_choisie = stations.iloc[numero_station,]\n",
    "      nearest = nearest_points(station_choisie['geometry'], ensemble_stations)[1]\n",
    "      return stations_transport[stations_transport['geometry'] == nearest][:1]['nomptar']\n",
    "\n",
    "dix_premieres_stations = stations.head(10)\n",
    "dix_premieres_stations['Nearest'] = [list(find_nearest(num_station))[0] for num_station in dix_premieres_stations.index]\n",
    "dix_premieres_stations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414f6692",
   "metadata": {},
   "source": [
    "<!-- 3. Quelle ligne de transport est à proximité du plus de velibs ? -->\n",
    "\n",
    "<!-- 4. Calculer la distance de chaque station à la ligne de métro la plus proche. Faire un nuage de points reliant distance au métro et nombre de places en stations -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5688bafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ancienne correction de Lino\n",
    "# un truc comme ça à revoir mais là fait des NaN :'(\n",
    "from shapely.ops import nearest_points\n",
    "temp = stations_transport.unary_union\n",
    "def find_nearest(geometry1, geometry2 = temp, df_point2 = stations_transport):\n",
    "    nearest = nearest_points(geometry1, geometry2)[1]\n",
    "    return df_point2[df_point2['geometry'] == nearest][:1]['nomptar']\n",
    "stations['Nearest'] = stations.apply(lambda row: find_nearest(row.geometry), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41b1a83",
   "metadata": {},
   "source": [
    "<!-- # Exercices supplémentaires -->\n",
    "\n",
    "<!-- ## carte US election 2020 -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f866071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import urllib.request\n",
    "import gzip\n",
    "\n",
    "url = \"https://int.nyt.com/newsgraphics/elections/map-data/2020/national/precincts-with-results.geojson.gz\"\n",
    "# urllib.request.urlretrieve(url, \"votes.gz\")\n",
    "\n",
    "url2 = \"https://www2.census.gov/geo/tiger/GENZ2018/shp/cb_2018_us_state_20m.zip\"\n",
    "urllib.request.urlretrieve(url2, \"states.zip\")\n",
    "\n",
    "import gzip\n",
    "import shutil\n",
    "with gzip.open('votes.gz', 'rb') as f_in:\n",
    "    with open('votes.geojson', 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "        \n",
    "import zipfile\n",
    "with zipfile.ZipFile(\"states.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"states.shp\")\n",
    "\n",
    "votes = gpd.read_file('votes.geojson')\n",
    "states = gpd.read_file(\"states.shp\")\n",
    "votes['states'] = votes['GEOID'].str[:2]\n",
    "\n",
    "# alternative (plus rapide)\n",
    "essai = pd.read_csv(\"https://github.com/MEDSL/2020-elections-official/raw/main/PRESIDENT/PRESIDENT_precinct_general.csv.zip\")\n",
    "essai.dropna(subset = [\"party_simplified\"]).groupby([\"county_fips\",'party_simplified']).agg({\"votes\": \"sum\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
