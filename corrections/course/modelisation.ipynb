{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Partie 3: modéliser\"\n",
        "date: 2020-10-14T13:00:00Z\n",
        "draft: false\n",
        "weight: 35\n",
        "slug: \"modelisation\"\n",
        "type: book\n",
        "summary: |\n",
        "  La facilité à modéliser des processus très diverses a grandement \n",
        "  participé au succès de `Python`. La librairie `scikit` offre une\n",
        "  grande variété de modèles et permet ainsi d'avoir un code\n",
        "  fonctionnel en très peu de temps.\n",
        "icon: square-root-alt\n",
        "icon_pack: fas\n",
        "bibliography: ../../../reference.bib\n",
        "---"
      ],
      "id": "bd30d766"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Principes\n",
        "\n",
        "### Machine Learning ou Econométrie ?\n",
        "\n",
        "Un modèle statistique est une construction mathématique qui formalise une loi\n",
        "ayant généré les données. La différence principale entre *machine learning* (ML) et économétrie\n",
        "est dans le degré de structure imposé par le modélisateur :\n",
        "\n",
        "- En ML,\n",
        "la structure imposée par le *data scientist* est minimale et ce sont plutôt\n",
        "les algorithmes qui, sur des critères de performance statistique, vont\n",
        "déterminer une loi mathématique qui correspond aux données.\n",
        "\n",
        "- En économétrie,\n",
        "les hypothèses de structure des lois sont plus fortes (même dans un cadre semi ou non-paramétrique) et sont plus souvent imposées\n",
        "par le modélisateur.\n",
        "\n",
        "L'adoption du _Machine Learning_ dans la littérature économique a été longue\n",
        "car la structuration des données est souvent le\n",
        "pendant empirique d'hypothèses théoriques sur le comportement des acteurs ou des marchés [@athey2019machine]. \n",
        "Pour caricaturer, l’économétrie s’attacherait à comprendre la causalité de certaines variables sur une autre.\n",
        "Cela implique que ce qui intéresse l'économètre\n",
        "est principalement de l'estimation des paramètres (et l'incertitude\n",
        "sur l'estimation de ceux-ci) qui permettent de quantifier l'effet d'une\n",
        "variation d'une variable sur une autre. \n",
        "Toujours pour caricaturer, \n",
        "le _Machine Learning_ se focaliserait\n",
        "sur un simple objectif prédictif en exploitant les relations de corrélations entre les variables.\n",
        "Dans cette perspective, l'important n'est pas la causalité mais le fait qu'une variation\n",
        "de $x$% d'une variable permette d'anticiper un changement de $\\beta x$ de la variable\n",
        "d'intérêt ; peu importe la raison.\n",
        "Cette approche est néanmoins caricaturale: la recherche est très dynamique \n",
        "sur la question de l'explicabilité et de l'interprétabilité\n",
        "des modèles de _Machine Learning_. Certaines approches sont reliées\n",
        "à des notions théoriques\n",
        "comme les [valeurs de Shapley](https://shap.readthedocs.io/en/latest/index.html).\n",
        "\n",
        "\n",
        "\n",
        "### Apprentissage supervisé ou non supervisé ?\n",
        "\n",
        "On distingue généralement deux types de méthodes, selon qu'on dispose d'information, dans l'échantillon\n",
        "d'apprentissage, sur les valeurs cibles *y* (on utilisera parfois le terme *label*) :\n",
        "\n",
        "* **apprentissage supervisé** : la valeur cible est connue et peut-être utilisée pour évaluer la qualité d'un modèle \n",
        "\n",
        "*Ex : modèles de prédiction du type régression / classification : SVM, kNN, arbres de classification...*\n",
        "\n",
        "* **apprentissage non supervisé** : la valeur cible est inconnue et ce sont des critères statistiques qui vont amener\n",
        "à sélectionner la structure de données la plus plausible. \n",
        "\n",
        "*Ex : modèles de réduction de dimension ou de clustering (PCA, kmeans...)*\n",
        "\n",
        "## Panorama d'un éco-système vaste\n",
        "\n",
        "Grâce aux principaux packages de Machine Learning (`scikit`), Deep Learning (`keras`, `pytorch`, `TensorFlow`...) et économétrie  (`statsmodels`), la modélisation est extrêmement simplifiée. Cela ne doit pas faire oublier l'importance de la structuration et de la préparation des données. Souvent, l'étape la plus cruciale est le choix du modèle le plus adapté à la structure des données.\n",
        "\n",
        "L'aide-mémoire suivante, issue de l'aide de `scikit-learn`, concernant les modèles de Machine Learning peut déjà donner de premiers enseignements sur les différentes familles de modèles:\n",
        "\n",
        "![](https://scikit-learn.org/stable/_static/ml_map.png)\n",
        "\n",
        "\n",
        "## Données\n",
        "\n",
        "La plupart des exemples de cette partie s'appuient sur les résultats des\n",
        "élections US 2020 au niveau comtés. Plusieurs bases sont utilisées pour \n",
        "cela:\n",
        "\n",
        "* Les données électorales sont une reconstruction à partir des données du MIT election lab\n",
        "proposées sur `Github` par [@tonmcg](https://github.com/tonmcg/US_County_Level_Election_Results_08-20)\n",
        "ou directement disponibles sur le site du [MIT Election Lab](https://electionlab.mit.edu/data)\n",
        "* Les données socioéconomiques (population, données de revenu et de pauvreté, \n",
        "taux de chômage, variables d'éducation) proviennent de l'USDA ([source](https://www.ers.usda.gov/data-products/county-level-data-sets/))\n",
        "* Le *shapefile* vient des données du *Census Bureau*. Le fichier peut\n",
        "être téléchargé directement depuis cet url:\n",
        "<https://www2.census.gov/geo/tiger/GENZ2019/shp/cb_2019_us_county_20m.zip>\n",
        "\n",
        "Le code pour construire une base unique à partir de ces sources diverses\n",
        "est disponible ci-dessous : \n"
      ],
      "id": "ad99da40"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "\n",
        "with open('get_data.py', 'r') as f:\n",
        "  for line in f:\n",
        "    if not line.startswith(\"## ----\"):\n",
        "      print(line, end='')"
      ],
      "id": "f1f6e35a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Contenu de la partie\n",
        "\n",
        "\n",
        "{{< list_children >}}\n",
        "\n",
        "\n",
        "\n",
        "Autres champs:\n",
        "* maximum vraisemblance\n",
        "* stats bayésiennes\n",
        "* semi et non paramétrique: méthodes noyaux, GAM\n",
        "\n",
        "## Références\n",
        "\n",
        "::: {#refs}\n",
        ":::"
      ],
      "id": "e212319d"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}