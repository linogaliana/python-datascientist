{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Les nouveaux modes d’accès aux données: le format parquet et les\n",
        "\n",
        "données sur le cloud"
      ],
      "id": "09ad9ad6-e529-4194-ab5c-66fb475e1289"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p class=\"badges\">\n",
        "\n",
        "<a href=\"https://github.com/linogaliana/python-datascientist/blob/master/notebooks/course/NLP/05a_s3.ipynb\" class=\"github\"><i class=\"fab fa-github\"></i></a>\n",
        "<a href=\"https://downgit.github.io/#/home?url=https://github.com/linogaliana/python-datascientist/blob/master/notebooks/course/NLP/05a_s3.ipynb\" target=\"_blank\" rel=\"noopener\"><img src=\"https://img.shields.io/badge/Download-Notebook-important?logo=Jupyter\" alt=\"Download\"></a>\n",
        "<a href=\"https://nbviewer.jupyter.org/github/linogaliana/python-datascientist/blob/master/notebooks/course/NLP/05a_s3.ipynb\" target=\"_blank\" rel=\"noopener\"><img src=\"https://img.shields.io/badge/Visualize-nbviewer-blue?logo=Jupyter\" alt=\"nbviewer\"></a>\n",
        "<a href=\"https://datalab.sspcloud.fr/launcher/inseefrlab-helm-charts-datascience/jupyter?autoLaunch=true&onyxia.friendlyName=%C2%ABpython-datascience%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%ABnotebooks/course/NLP/05a_s3.ipynb%C2%BB&security.allowlist.enabled=false\" target=\"_blank\" rel=\"noopener\"><img src=\"https://img.shields.io/badge/SSPcloud-Tester%20via%20SSP--cloud-informational&amp;color=yellow?logo=Python\" alt=\"Onyxia\"></a><br>\n",
        "<a href=\"https://mybinder.org/v2/gh/linogaliana/python-datascientist/master?filepath={binder_path}\" target=\"_blank\" rel=\"noopener\"><img src=\"https://img.shields.io/badge/Launch-Binder-E66581.svg?logo=data:image/png;base64,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\" alt=\"Binder\"></a>\n",
        "<a href=\"http://colab.research.google.com/github/linogaliana/python-datascientist/blob/master/notebooks/course/NLP/05a_s3.ipynb\" target=\"_blank\" rel=\"noopener\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "<a href=\"https://github.dev/linogaliana/python-datascientist/notebooks/course/NLP/05a_s3.ipynb\" target=\"_blank\" rel=\"noopener\"><img src=\"https://img.shields.io/static/v1?logo=visualstudiocode&label=&message=Open%20in%20Visual%20Studio%20Code&labelColor=2c2c32&color=007acc&logoColor=007acc\" alt=\"githubdev\"></a>\n",
        "\n",
        "</p>\n",
        "\n",
        "</p>"
      ],
      "id": "f8f640c0-2556-45ca-8a84-26b90e2face3"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Elements de contexte\n",
        "\n",
        "## Principe du stockage de la donnée\n",
        "\n",
        "Pour comprendre les apports du format `Parquet`, il est nécessaire\n",
        "de faire un détour pour comprendre la manière dont une information\n",
        "est stockée et accessible à un langage de traitement de la donnée.\n",
        "\n",
        "Il existe deux approches dans le monde du stockage de la donnée.\n",
        "La première est celle de la **base de données relationnelle**. La seconde est le\n",
        "principe du **fichier**.\n",
        "La différence entre les deux est dans la manière dont l’accès aux\n",
        "données est organisé.\n",
        "\n",
        "## Les fichiers\n",
        "\n",
        "Dans un fichier, les données sont organisées selon un certain format et\n",
        "le logiciel de traitement de la donnée va aller chercher et structurer\n",
        "l’information en fonction de ce format. Par exemple, dans un fichier\n",
        "`.csv`, les différentes informations seront stockées au même niveau\n",
        "avec un caractère pour les séparer (la virgule `,` dans les `.csv` anglosaxons, le point virgule dans les `.csv` français, la tabulation dans les `.tsv`). Le fichier suivant\n",
        "\n",
        "``` raw\n",
        "nom ; profession \n",
        "Astérix ; \n",
        "Obélix ; Tailleur de menhir ;\n",
        "Assurancetourix ; Barde\n",
        "```\n",
        "\n",
        "sera ainsi organisé naturellement sous forme tabulée par `Python`"
      ],
      "id": "22d23f44-1393-4634-bdee-a834c98b0bdf"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nom</th>\n",
              "      <th>profession</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Astérix</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Obélix</td>\n",
              "      <td>Tailleur de menhir</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Assurancetourix</td>\n",
              "      <td>Barde</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          }
        }
      ],
      "source": [],
      "id": "220ab22f-b483-45c1-9d6f-86fcf35f907b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A propos des fichiers de ce type, on parle de **fichiers plats** car\n",
        "les enregistrements relatifs à une observation sont stockés ensemble,\n",
        "sans hiérarchie.\n",
        "\n",
        "Certains formats de données vont permettre d’organiser les informations\n",
        "de manière différente. Par exemple, le format `JSON` va\n",
        "hiérarchiser différemment la même information `{=html} <a name=\"cite_note-1\"></a>1. [^](#cite_ref-1)`\n",
        "\n",
        "``` raw\n",
        "[\n",
        "  {\n",
        "    \"nom\": \"Astérix\"\n",
        "  },\n",
        "  {\n",
        "    \"nom\": \"Obélix\",\n",
        "    \"profession\": \"Tailleur de menhir\"\n",
        "  },\n",
        "  {\n",
        "    \"nom\": \"Assurancetourix\",\n",
        "    \"profession\": \"Barde\"\n",
        "  }\n",
        "]\n",
        "```"
      ],
      "id": "55d7e9ae-e3e4-4789-b169-43124cc78329"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<a name=\"cite_note-1\"></a>1. [^](#cite_ref-1)"
      ],
      "id": "e62b7e72-d0a0-41af-bfab-f8f246dad080"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La différence entre le CSV et le format `JSON` va au-delà d’un simple “formattage” des données.\n",
        "\n",
        "    Par sa nature non tabulaire, le format JSON permet des mises à jour beaucoup plus facile de la donnée dans les entrepôts de données.\n",
        "\n",
        "Par exemple, un site web qui collecte de nouvelles données n’aura pas à mettre à jour l’ensemble de ses enregistrements antérieurs\n",
        "pour stocker la nouvelle donnée (par exemple pour indiquer que pour tel ou tel client cette donnée n’a pas été collectée)\n",
        "mais pourra la stocker dans\n",
        "un nouvel item. Ce sera à l’outil de requête (`Python` ou un autre outil)\n",
        "de créer une relation entre les enregistrements stockés à des endroits\n",
        "différents.\n",
        "\n",
        "    Ce type d'approche flexible est l'un des fondements de l'approche NoSQL,\n",
        "\n",
        "sur laquelle nous allons revenir, qui a permis l’émergence de technologies au coeur de l’écosystème actuel du *big-data* comme `Hadoop` ou `ElasticSearch`.\n",
        "\n",
        "Cette fois, quand on n’a pas d’information, on ne se retrouve pas avec nos deux séparateurs accolés (cf. la ligne *“Astérix”*) mais l’information\n",
        "n’est tout simplement pas collectée."
      ],
      "id": "59a52c03-fcfa-4692-8f4c-9ef6a4236399"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\" role=\"alert\">\n",
        "\n",
        "Il se peut très bien que l’information sur une observation soit disséminée\n",
        "dans plusieurs fichiers dont les formats diffèrent. Par exemple, dans le domaine des données géographiques,\n",
        "lorsqu’une donnée est disponible sous format de fichier(s), elle peut l’être de deux manières.\n",
        "Soit la donnée est stockée dans un seul fichier qui mélange contours géographiques et valeurs attributaires\n",
        "(la valeur associée à cette observation géographique, par exemple le taux d’abstention). Ce principe est celui du `geojson`.\n",
        "Soit la donnée est stockée dans plusieurs fichiers qui sont spécialisés: un fichier va stocker les contours géographiques,\n",
        "l’autre les données attributaires et d’autres fichiers des informations annexes (comme le système de projection). Ce principe est celui du `shapefile`.\n",
        "C’est alors le logiciel qui requête\n",
        "les données (`Python` par exemple) qui saura où aller chercher l’information\n",
        "dans les différents fichiers et associer celle-ci de manière cohérente.\n",
        "\n",
        "</div>"
      ],
      "id": "e5487f8f-72fa-4f27-8de1-25dd8027f1ab"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Un concept supplémentaire dans le monde du fichier est celui du **file system**. Le  \n",
        "*file system* est le système de localisation et de nommage des fichiers.\n",
        "Pour simplifier, le file système est la manière dont votre ordinateur saura\n",
        "retrouver, dans son système de stockage, les bits présents dans tel ou tel fichier\n",
        "appartenant à tel ou tel dossier.\n",
        "\n",
        "## Les bases de données\n",
        "\n",
        "La logique des bases de données est différente. Elle est plus systémique.\n",
        "Un système de gestion de base de données (*Database Management System*)\n",
        "est un logiciel qui gère à la fois le stockage d’un ensemble de données reliée,\n",
        "permet de mettre à jour celle-ci (ajout ou suppression d’informations, modification\n",
        "des caractéristiques d’une table…)\n",
        "et qui gère également\n",
        "les modalités d’accès à la donnée (type de requête, utilisateurs\n",
        "ayant les droits en lecture ou en écriture…).\n",
        "\n",
        "La relation entre les entités présentes dans une base de données\n",
        "prend généralement la forme d’un **schéma en étoile**. Une base va centraliser\n",
        "les informations disponibles qui seront ensuite détaillées dans des tables\n",
        "dédiées.\n",
        "\n",
        "![](https://www.databricks.com/wp-content/uploads/2022/04/star-schema-erd.png)\n",
        "Source: [La documentation `Databricks` sur le schéma en étoile](https://www.databricks.com/fr/glossary/star-schema)\n",
        "\n",
        "Le logiciel associé à la base de données fera ensuite le lien\n",
        "entre ces tables à partir de requêtes `SQL`. L’un des logiciels les plus efficaces dans ce domaine\n",
        "est [`PostgreSQL`](https://www.postgresql.org/). `Python` est tout à fait\n",
        "utilisable pour passer une requête SQL à un gestionnaire de base de données.\n",
        "Les packages [`sqlalchemy`](https://www.sqlalchemy.org/) et [`psycopg2`](https://www.psycopg.org/docs/)\n",
        "peuvent servir à utiliser `PostgreSQL` pour requêter une\n",
        "base de donnée ou la mettre à jour.\n",
        "\n",
        "La logique de la base de données est donc très différente de celle du fichier.\n",
        "Ces derniers sont beaucoup plus légers pour plusieurs raisons.\n",
        "D’abord, parce qu’ils sont moins adhérents à\n",
        "un logiciel gestionnaire. Là où le fichier ne nécessite, pour la gestion,\n",
        "qu’un *file system*, installé par défaut sur\n",
        "tout système d’exploitation, une base de données va nécessiter un\n",
        "logiciel spécialisé. L’inconvénient de l’approche fichier, sous sa forme\n",
        "standard, est qu’elle\n",
        "ne permet pas une gestion fine des droits d’accès et amène généralement à une\n",
        "duplication de la donnée pour éviter que la source initiale soit\n",
        "ré-écrite (involontairement ou de manière intentionnelle par un utilisateur malveillant).\n",
        "Résoudre ce problème est l’une des\n",
        "innovations des systèmes *cloud*, sur lesquelles nous reviendrons en évoquant le\n",
        "système `S3`.\n",
        "Un deuxième inconvénient de l’approche base de données par\n",
        "rapport à l’approche fichier, pour un utilisateur de `Python`,\n",
        "est que les premiers nécessitent l’intermédiation du logiciel de gestion\n",
        "de base de données là où, dans le second cas, on va se contenter d’une\n",
        "librairie, donc un système beaucoup plus léger,\n",
        "qui sait comment transformer la donnée brute en `DataFrame`.\n",
        "Pour ces raisons, entre autres, les bases de données sont donc moins à la\n",
        "mode dans l’écosystème récent de la *data-science* que les fichiers.\n",
        "\n",
        "## Le format `parquet`\n",
        "\n",
        "Le format `CSV` a rencontré un grand succès par sa simplicité: il\n",
        "est lisible par un humain (un bloc-note suffit pour l’ouvrir et\n",
        "apercevoir les premières lignes), sa nature plate lui permet\n",
        "de bien correspondre au concept de données tabulées sans hiérarchie\n",
        "qui peuvent être rapidement valorisées, il est universel (il n’est\n",
        "pas adhérent à un logiciel). Cependant, le CSV présente\n",
        "plusieurs inconvénients qui justifient l’émergence d’un format\n",
        "concurrent:\n",
        "\n",
        "-   le CSV est un format **lourd** car les informations ne sont pas compressées\n",
        "    (ce qui le rend lisible facilement depuis un bloc-note) mais aussi\n",
        "    parce que toutes les données sont stockées de la même manière.\n",
        "    C’est la\n",
        "    librairie faisant l’import qui va essayer d’optimiser le typage des données\n",
        "    pour trouver le typage qui utilise le moins de mémoire possible sans\n",
        "    altération de l’information. En effet, si `pandas` détermine qu’une colonne\n",
        "    présente les valeurs `6 ; 5 ; 0`, il va privilégier l’utilisation du type\n",
        "    `int` au type `double` qui sera lui même préféré au type `object` (objets\n",
        "    de type données textuelles). Cependant, pour faire cela, `pandas` va devoir\n",
        "    scanner un nombre suffisant de valeurs, ce qui demande du temps et expose\n",
        "    à des erreurs (en se fondant sur trop peu de valeurs, on peut se tromper\n",
        "    de typage) ;\n",
        "-   le stockage étant **orienté ligne**,\n",
        "    accéder à une information donnée dans un `CSV` implique\n",
        "    de le lire le fichier en entier, sélectionner la ou les colonnes\n",
        "    d’intérêt et ensuite les lignes désirées. Par exemple, si on désire\n",
        "    connaître uniquement la profession de la deuxième ligne dans l’exemple\n",
        "    plus haut :point_up:, un algorithme de recherche devra:\n",
        "    prendre le fichier, déterminer que la profession est la deuxième colonne,\n",
        "    et ensuite aller chercher la deuxième ligne dans cette colonne. Si\n",
        "    on désire accéder à un sous-ensemble de lignes dont les indices\n",
        "    sont connus, le `CSV` est intéressant. Cependant,\n",
        "    si on désire accéder à un sous-ensemble\n",
        "    de colonnes dans un fichier (ce qui est un cas d’usage plus fréquent\n",
        "    pour les *data-scientists*), alors le `CSV` n’est pas le format le plus\n",
        "    approprié ;\n",
        "-   mettre à jour la donnée est coûteux car cela implique de réécrire\n",
        "    l’ensemble du fichier. Par exemple, si après une première\n",
        "    analyse de la donnée,\n",
        "    on désire ajouter une colonne, on ne peut accoler ces nouvelles informations\n",
        "    à celles déjà existantes, il est nécessaire de réécrire l’ensemble\n",
        "    du fichier. Pour reprendre l’exemple de nos gaulois préférés, si on veut\n",
        "    ajouter une colonne `cheveux` entre les deux déjà existantes,\n",
        "    il faudra changer totalement le fichier:\n",
        "\n",
        "``` raw\n",
        "\"\"\"\n",
        "nom ; cheveux ; profession\n",
        "Astérix; blond; ; \n",
        "Obélix; roux; Tailleur de menhir\n",
        "Assurancetourix; blond; Barde\n",
        "\"\"\"\n",
        "```"
      ],
      "id": "294b745e-6f87-4584-9b8a-826d46159ed0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\" role=\"alert\">\n",
        "\n",
        "La plupart des logiciels d’analyse de données proposent\n",
        "un format de fichier pour sauvegarder des bases de données. On\n",
        "peut citer le `.pickle` (`Python`), le `.rda` ou `.RData` (`R`),\n",
        "le `.dta` (`Stata`) ou le `.sas7bdat` (`SAS`). L’utilisation\n",
        "de ces formats est problématique car cela revient à se lier\n",
        "les mains pour l’analyse ultérieure des données, surtout\n",
        "lorsqu’il s’agit d’un format propriétaire (comme avec\n",
        "`SAS` ou `Stata`). Par exemple, `Python` ne\n",
        "sait pas nativement lire un `.sas7bdat`. Il existe des librairies\n",
        "pour le faire (notamment `Pandas`) mais le format\n",
        "étant propriétaire, les développeurs de la librairie ont dû tâtonner et\n",
        "on n’est ainsi jamais assuré qu’il n’y ait pas d’altération de la donnée.\n",
        "\n",
        "Malgré tous les inconvénients du `.csv` listés plus haut, il présente\n",
        "l’immense avantage, par rapport à ces formats, de l’universalité.\n",
        "Il vaut ainsi mieux privilégier un `.csv` à ces formats pour le stockage\n",
        "de la donnée. Ceci dit, comme vise à le montrer ce chapitre, il vaut\n",
        "mieux privilégier le format `parquet` au `CSV`.\n",
        "\n",
        "</div>"
      ],
      "id": "ead07a67-611f-4ee1-b916-3494e733d160"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pour répondre à ces limites du `CSV`, le format `parquet`,\n",
        "qui est un [projet open-source `Apache`](https://apache.org/), a émergé.\n",
        "La première différence entre le format `parquet` et le `CSV` est\n",
        "que le premier repose sur un **stockage orienté colonne** là où\n",
        "le second est orienté ligne. Pour comprendre la différence, voici un\n",
        "exemple issu du [blog d’upsolver](https://www.upsolver.com/blog/apache-parquet-why-use):\n",
        "\n",
        "![](https://www.upsolver.com/wp-content/uploads/2020/05/Screen-Shot-2020-05-26-at-17.52.58.png)\n",
        "\n",
        "Dans notre exemple précédent, cela donnera une information prenant\n",
        "la forme suivante (ignorez l’élément `pyarrow.Table`, nous\n",
        "reviendrons dessus) :"
      ],
      "id": "40718826-a11b-4b4f-a65e-f9696332377a"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "pyarrow.Table\n",
              "nom : string\n",
              "profession: string\n",
              "----\n",
              "nom : [[\"Astérix \",\"Obélix \",\"Assurancetourix \"]]\n",
              "profession: [[\"\",\"Tailleur de menhir\",\"Barde\"]]"
            ]
          }
        }
      ],
      "source": [],
      "id": "9e474a26-4ab1-424b-9b1f-544e9dc38e51"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pour reprendre l’exemple fil rouge :point_up:, il sera ainsi beaucoup plus\n",
        "facile de récupérer la deuxième ligne de la colonne `profession`:\n",
        "on ne considère que le vecteur `profession` et on récupère la deuxième\n",
        "valeur.\n",
        "Le requêtage d’échantillon de données ne nécessite donc pas l’import de\n",
        "l’ensemble des données. A cela s’ajoute des fonctionnalités supplémentaires\n",
        "des librairies d’import de données parquet (par exemple `pyarrow` ou `spark`)\n",
        "qui vont faciliter des recherches complexes basées, par exemple, sur des\n",
        "requêtes de type `SQL`, ou permettant l’utilisation de données plus volumineuses que la RAM.\n",
        "\n",
        "Le format `parquet` présente d’autres avantages par rapport au\n",
        "`CSV`:\n",
        "\n",
        "-   Le format `parquet` est (très) compressé, ce qui réduit la volumétrie\n",
        "    des données sur disque ;\n",
        "-   Des métadonnées, notamment le typage des variables, sont stockées en complément dans le fichier.\n",
        "    Cette partie, nommée le *footer* du fichier `parquet`, permet que l’import des données soit\n",
        "    optimisé sans risque d’altération de celle-ci. Pour un producteur de données, c’est une manière\n",
        "    d’assurer la qualité des données. Par exemple, un fournisseur de\n",
        "    données de type code-barre sera\n",
        "    certain que les données `000012` ne seront pas considérées identiques à un code-barre `12`.\n",
        "-   Il est possible de partitionner un jeu de données en fonction de différents niveaux (par\n",
        "    exemple des niveaux géographiques) en une arborescence de fichiers `parquet`. Cela\n",
        "    permet de travailler sur un échantillon pour facilement passer à l’échelle ensuite.\n",
        "    Par exemple, une structure partitionnée, empruntée\n",
        "    à la [documentation `Spark`](https://spark.apache.org/docs/latest/sql-data-sources-parquet.html#partition-discovery)\n",
        "    peut prendre la forme suivante:\n",
        "\n",
        "``` raw\n",
        "path\n",
        "└── to\n",
        "    └── table\n",
        "        ├── gender=male\n",
        "        │   ├── ...\n",
        "        │   │\n",
        "        │   ├── country=US\n",
        "        │   │   └── data.parquet\n",
        "        │   ├── country=CN\n",
        "        │   │   └── data.parquet\n",
        "        │   └── ...\n",
        "        └── gender=female\n",
        "            ├── ...\n",
        "            │\n",
        "            ├── country=US\n",
        "            │   └── data.parquet\n",
        "            ├── country=CN\n",
        "            │   └── data.parquet\n",
        "            └── ...\n",
        "```\n",
        "\n",
        "Qu’on lise un ou plusieurs fichiers, on finira avec le schéma suivant:\n",
        "\n",
        "``` raw\n",
        "root\n",
        "|-- name: string (nullable = true)\n",
        "|-- age: long (nullable = true)\n",
        "|-- gender: string (nullable = true)\n",
        "|-- country: string (nullable = true)\n",
        "```\n",
        "\n",
        "Ces différents avantages expliquent le succès du format `parquet` dans le monde du\n",
        "*big-data*. Le paragraphe suivant, extrait du [post d’upsolver]() déjà cité,\n",
        "résume bien l’intérêt:\n",
        "\n",
        "> Complex data such as logs and event streams would need to be represented as a table with hundreds or thousands of columns, and many millions of rows. Storing this table in a row based format such as CSV would mean:\n",
        ">\n",
        "> -   Queries will take longer to run since more data needs to be scanned, rather than only querying the subset of columns we need to answer a query (which typically requires aggregating based on dimension or category)\n",
        "> -   Storage will be more costly since CSVs are not compressed as efficiently as Parquet\n",
        "\n",
        "Cependant, `parquet` ne devrait pas intéresser que les producteurs\n",
        "ou utilisateurs de données *big-data*. C’est l’ensemble\n",
        "des producteurs de données qui bénéficient des fonctionalités\n",
        "de `parquet`.\n",
        "\n",
        "Pour en savoir plus sur `Arrow`,\n",
        "des éléments supplémentaires sur `Parquet` sont disponibles sur ce très bon\n",
        "post de blog d’[upsolver](https://www.upsolver.com/blog/apache-parquet-why-use)\n",
        "et [sur la page officielle du projet `Parquet`](https://parquet.apache.org/).\n",
        "\n",
        "## Lire un `parquet` en `Python`: la librairie `pyarrow`\n",
        "\n",
        "La librairie `pyarrow` permet la lecture et l’écriture\n",
        "de fichiers `parquet` avec `Python`<a name=\"cite_ref-3\"></a>[<sup>\\[3\\]</sup>](#cite_note-3) Elle repose\n",
        "sur un type particulier de *dataframe*, le `pyarrow.Table`\n",
        "qui peut être utilisé en substitut ou en complément\n",
        "du `DataFrame`\n",
        "de `pandas`. Il est recommandé de régulièrement\n",
        "consulter la documentation officielle de `pyarrow`\n",
        "concernant [la lecture et écriture de fichiers](https://arrow.apache.org/docs/python/parquet.html) et celle relative\n",
        "aux [manipulations de données](https://arrow.apache.org/cookbook/py/data.html)."
      ],
      "id": "f59ea937-695f-4a58-812a-6bc2de608b09"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "raw_mimetype": "text/html"
      },
      "source": [
        "<a name=\"cite_note-3\"></a>3. [^](#cite_ref-3)"
      ],
      "id": "e7fec419-fd62-4d00-97f0-132a0b47c250"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Elle permet aussi la lecture et l’écriture\n",
        "de `.csv`.\n",
        "\n",
        "Pour illustrer les fonctionalités de `pyarrow`,\n",
        "repartons de notre CSV initial que nous allons\n",
        "enrichir d’une nouvelle variable numérique\n",
        "et que nous\n",
        "allons\n",
        "convertir en objet `pyarrow` avant de l’écrire au format `parquet`:"
      ],
      "id": "0d50a94f-7ffc-41cc-8838-d38d5ea648dd"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "\n",
        "s = \"\"\"\n",
        "nom;cheveux;profession\n",
        "Astérix;blond;; \n",
        "Obélix;roux;Tailleur de menhir\n",
        "Assurancetourix;blond;Barde\n",
        "\"\"\"\n",
        "\n",
        "source = io.BytesIO(s.encode())\n",
        "\n",
        "df = pd.read_csv(source, sep = \";\")\n",
        "df[\"taille\"] = [155, 190, 175]\n",
        "table = pa.Table.from_pandas(df)\n",
        "\n",
        "table\n",
        "\n",
        "pq.write_table(table, 'example.parquet')"
      ],
      "id": "a89e5002-8bc9-4d19-bb53-04e450407882"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-warning\" role=\"alert\">\n",
        "\n",
        "L’utilisation des noms `pa` pour `pyarrow` et `pq` pour\n",
        "`pyarrow.parquet` est une convention communautaire\n",
        "qu’il est recommandé de suivre.\n",
        "\n",
        "</div>"
      ],
      "id": "caebf58b-bfcd-4d5f-954d-bc449df25d97"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pour importer et traiter ces données, on peut conserver\n",
        "les données sous le format `pyarrow.Table`\n",
        "ou transformer en `pandas.DataFrame`. La deuxième\n",
        "option est plus lente mais présente l’avantage\n",
        "de permettre ensuite d’appliquer toutes les\n",
        "manipulations offertes par l’écosystème\n",
        "`pandas` qui est généralement mieux connu que\n",
        "celui d’`Arrow`.\n",
        "\n",
        "Supposons que ne s’intéresse qu’à la taille et à la couleur\n",
        "de cheveux de nos gaulois. Avec `pyarrow`, on pourra utiliser `pyarrow.compute` pour\n",
        "effectuer des opérations directement :"
      ],
      "id": "c92afcb2-e931-48ff-bb4f-c7e1c00abc83"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "table = pq.read_table('example.parquet', columns=['taille', 'cheveux'])\n",
        "\n",
        "import pyarrow.compute as pc\n",
        "table.group_by(\"cheveux\").aggregate([(\"taille\", \"sum\")])"
      ],
      "id": "63262b81-2b91-4ada-9dfe-f4d7f526b180"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Le système de stockage `S3`\n",
        "\n",
        "## Qu’est-ce que le système de stockage `S3` ?\n",
        "\n",
        "Dans les entreprises et administrations, un nombre croissant de données sont\n",
        "disponibles depuis un système de stockage\n",
        "nommé `S3`.\n",
        "Le système S3 (*Simple Storage System*) est un système de stockage développé\n",
        "par Amazon et qui est maintenant devenu une référence pour le stockage en ligne.\n",
        "Il s’agit d’une architecture à la fois\n",
        "sécurisée (données cryptées, accès restreints) et performante.\n",
        "\n",
        "Le concept central du système S3 est le *bucket*.\n",
        "Un *bucket* est un espace (privé ou partagé) où on peut stocker une\n",
        "arborescence de fichiers. Pour accéder aux fichiers figurant\n",
        "dans un *bucket* privé, il fournit des jetons d’accès (l’équivalent d’un mot de passe)\n",
        "reconnus par le serveur de stockage. On peut alors lire et écrire dans le *bucket*.\n",
        "\n",
        "Le SSP cloud\n",
        "[![Onyxia](https://img.shields.io/badge/SSPcloud-Tester%20via%20SSP--cloud-informational&color=yellow?logo=Python.png)](https://datalab.sspcloud.fr/launcher/inseefrlab-helm-charts-datascience/jupyter?onyxia.friendlyName=%C2%ABpython-datascientist%C2%BB&resources.requests.memory=%C2%AB4Gi%C2%BB) repose par exemple sur cette infrastructure technique.\n",
        "\n",
        "## Comment faire avec Python ?\n",
        "\n",
        "### Les librairies principales\n",
        "\n",
        "L’interaction entre ce système distant de fichiers et une session locale de Python\n",
        "est possible grâce à des API. Les deux principales librairies sont les suivantes:\n",
        "\n",
        "-   [boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html), une librairie créée et maintenue par Amazon ;\n",
        "-   [s3fs](https://s3fs.readthedocs.io/en/latest/), une librairie qui permet d’interagir avec les fichiers stockés à l’instar d’un filesystem classique.\n",
        "\n",
        "Ces deux librairies offrent toutes deux la possibilité de se connecter depuis `Python`,\n",
        "à un dépôt de fichiers distant, de lister les fichiers disponibles dans un\n",
        "*bucket*, d’en télécharger un ou plusieurs ou de faire de l’*upload*"
      ],
      "id": "ccf04cfb-52c6-4312-8c77-4aebab1cdd3c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\" role=\"alert\">\n",
        "\n",
        "Les exemples suivants seront réplicables pour les utilisateurs de la plateforme\n",
        "SSP-cloud\n",
        "\n",
        "</div>"
      ],
      "id": "62901a00-e99c-4317-b0b0-87aea745cc72"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Personnellement, j’ai une petite préférence pour `boto3` que je trouve plus\n",
        "intuitif.\n",
        "\n",
        "### Quelques cas spéciaux\n",
        "\n",
        "La librairie ultra-performante [`arrow`](https://arrow.apache.org/docs/python/)\n",
        "propose également un accès à des fichiers sur\n",
        "`S3` comme s’ils étaient disponibles sur un *filesystem*\n",
        "local. Un exemple, assez court, est disponible\n",
        "[dans la documentation officielle](https://arrow.apache.org/docs/python/filesystems.html#s3)\n",
        "\n",
        "Les utilisateurs de\n",
        "[`Snakemake`](https://snakemake.readthedocs.io/en/stable/snakefiles/remote_files.html)\n",
        "peuvent également\n",
        "lire ou écrire des tables intermédiaires sur `S3`\n",
        "comme s’ils utilisaient un\n",
        "système de fichier local. En arrière-plan, `snakemake`\n",
        "va utiliser `boto3` pour communiquer avec le système\n",
        "de stockage\n",
        "\n",
        "Un outil très performant utilisant la ligne de commande est également\n",
        "disponible. Son nom est `mc` pour\n",
        "[`Minio Client`](https://docs.min.io/docs/minio-client-complete-guide.html).\n",
        "Il propose les mêmes\n",
        "opérations que la ligne de commande linux mais avec un système distant.\n",
        "\n",
        "## Connexion à un bucket\n",
        "\n",
        "Par la suite, on va utiliser des alias pour les trois valeurs suivantes, qui servent\n",
        "à s’authentifier.\n",
        "\n",
        "``` python\n",
        "key_id = 'MY_KEY_ID'\n",
        "access_key = 'MY_ACCESS_KEY'\n",
        "token = \"MY_TOKEN\"\n",
        "```\n",
        "\n",
        "Ces valeurs peuvent être également disponibles dans\n",
        "les variables d’environnement de `Python`. Comme il s’agit d’une information\n",
        "d’authentification personnelle, il ne faut pas stocker les vraies valeurs de ces\n",
        "variables dans un projet, sous peine de partager des traits d’identité sans le\n",
        "vouloir lors d’un partage de code.\n",
        "\n",
        "{{< tabs tabTotal=“4” >}}\n",
        "\n",
        "{{% tab tabName=“boto3” %}}\n",
        "\n",
        "Avec `boto3`, on créé d’abord un client puis on exécute des requêtes dessus.\n",
        "Pour initialiser un client, il suffit, en supposant que l’url du dépôt S3 est\n",
        "`\"https://minio.lab.sspcloud.fr\"`, de faire:\n",
        "\n",
        "``` python\n",
        "import boto3\n",
        "s3 = boto3.client(\"s3\",endpoint_url = \"https://minio.lab.sspcloud.fr\")\n",
        "```\n",
        "\n",
        "{{% /tab %}}\n",
        "{{% tab tabName=“S3FS” %}}\n",
        "\n",
        "La logique est identique avec `s3fs`.\n",
        "\n",
        "Si on a des jetons d’accès à jour et dans les variables d’environnement\n",
        "adéquates:\n",
        "\n",
        "``` python\n",
        "import s3fs\n",
        "fs = s3fs.S3FileSystem(\n",
        "  client_kwargs={'endpoint_url': 'https://minio.lab.sspcloud.fr'})\n",
        "```\n",
        "\n",
        "{{% /tab %}}\n",
        "{{% tab tabName=“Arrow” %}}\n",
        "\n",
        "La logique d’`Arrow` est proche de celle de `s3fs`. Seuls les noms\n",
        "d’arguments changent\n",
        "\n",
        "Si on a des jetons d’accès à jour et dans les variables d’environnement\n",
        "adéquates:\n",
        "\n",
        "``` python\n",
        "from pyarrow import fs\n",
        "s3 = fs.S3FileSystem(endpoint_override=\"http://\"+\"minio.lab.sspcloud.fr\")\n",
        "```\n",
        "\n",
        "{{% /tab %}}\n",
        "\n",
        "{{% tab tabName=“Snakemake” %}}\n",
        "\n",
        "La logique de `Snakemake` est, quant à elle,\n",
        "plus proche de celle de `boto3`. Seuls les noms\n",
        "d’arguments changent\n",
        "\n",
        "Si on a des jetons d’accès à jour et dans les variables d’environnement\n",
        "adéquates:\n",
        "\n",
        "``` python\n",
        "from snakemake.remote.S3 import RemoteProvider as S3RemoteProvider\n",
        "S3 = S3RemoteProvider(host = \"https://\" + os.getenv('AWS_S3_ENDPOINT'))\n",
        "```\n",
        "\n",
        "{{% /tab %}}\n",
        "\n",
        "{{< /tabs >}}\n",
        "\n",
        "Il se peut que la connexion à ce stade soit refusée (`HTTP error 403`).\n",
        "Cela peut provenir\n",
        "d’une erreur dans l’URL utilisé. Cependant, cela reflète plus généralement\n",
        "des paramètres d’authentification erronés.\n",
        "\n",
        "{{< tabs tabTotal=“4” >}}\n",
        "\n",
        "{{% tab tabName=“boto3” %}}\n",
        "\n",
        "Les paramètres d’authentification sont des arguments supplémentaires:\n",
        "\n",
        "``` python\n",
        "import boto3\n",
        "s3 = boto3.client(\"s3\",endpoint_url = \"https://minio.lab.sspcloud.fr\",\n",
        "                  aws_access_key_id=key_id, \n",
        "                  aws_secret_access_key=access_key, \n",
        "                  aws_session_token = token)\n",
        "```\n",
        "\n",
        "{{% /tab %}}\n",
        "\n",
        "{{% tab tabName=“S3FS” %}}\n",
        "\n",
        "La logique est la même, seuls les noms d’arguments diffèrent\n",
        "\n",
        "``` python\n",
        "import s3fs\n",
        "fs = s3fs.S3FileSystem(\n",
        "  client_kwargs={'endpoint_url': 'https://'+'minio.lab.sspcloud.fr'},\n",
        "  key = key_id, secret = access_key,\n",
        "  token = token)\n",
        "```\n",
        "\n",
        "{{% /tab %}}\n",
        "\n",
        "{{% tab tabName=“Arrow” %}}\n",
        "\n",
        "Tout est en argument cette fois:\n",
        "\n",
        "``` python\n",
        "from pyarrow import fs\n",
        "\n",
        "s3 = fs.S3FileSystem(\n",
        "    access_key = key_id,\n",
        "    secret_key = access_key,\n",
        "    session_token = token,\n",
        "    endpoint_override = 'https://'+'minio.lab.sspcloud.fr',\n",
        "    scheme = \"https\"\n",
        "    )\n",
        "```\n",
        "\n",
        "{{% /tab %}}\n",
        "\n",
        "{{% tab tabName=“Snakemake” %}}\n",
        "\n",
        "La logique est la même, seuls les noms d’arguments diffèrent\n",
        "\n",
        "``` python\n",
        "from snakemake.remote.S3 import RemoteProvider as S3RemoteProvider\n",
        "S3 = S3RemoteProvider(host = \"https://\" + os.getenv('AWS_S3_ENDPOINT'), access_key_id=key_id, secret_access_key=access_key)\n",
        "```\n",
        "\n",
        "{{% /tab %}}\n",
        "\n",
        "{{< /tabs >}}"
      ],
      "id": "16300e88-b88d-4dc4-aeeb-b5a15303bc00"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\" role=\"alert\">\n",
        "\n",
        "Dans le SSP-cloud,\n",
        "lorsque l’initialisation du service `Jupyter` du SSP-cloud est récente\n",
        "(moins de 12 heures), il est possible d’utiliser\n",
        "automatiquement les jetons stockés automatiquement à la création du dépôt.\n",
        "\n",
        "Si on désire accéder aux données du SSP-cloud depuis une session python du\n",
        "datalab (service VSCode, Jupyter…),\n",
        "il faut remplacer l’url par `http://minio.lab.sspcloud.fr`\n",
        "\n",
        "</div>"
      ],
      "id": "10e838f2-2a1e-44f8-9919-b319a89342c4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lister les fichiers\n",
        "\n",
        "S’il n’y a pas d’erreur à ce stade, c’est que la connexion est bien effective.\n",
        "Pour le vérifier, on peut essayer de faire la liste des fichiers disponibles\n",
        "dans un `bucket` auquel on désire accéder.\n",
        "\n",
        "Par exemple, on peut vouloir\n",
        "tester l’accès aux bases `FILOSOFI` (données de revenu localisées disponibles\n",
        "sur <https://www.insee.fr>) au sein du bucket `donnees-insee`.\n",
        "\n",
        "{{< tabs tabTotal=“5” >}}\n",
        "\n",
        "{{% tab tabName=“boto3” %}}\n",
        "\n",
        "Pour cela,\n",
        "la méthode `list_objects` offre toutes les options nécessaires:\n",
        "\n",
        "``` python\n",
        "for key in s3.list_objects(Bucket='donnees-insee', Prefix='FILOSOFI')['Contents']:\n",
        "    print(key['Key'])\n",
        "```\n",
        "\n",
        "{{% /tab %}}\n",
        "\n",
        "{{% tab tabName=“S3FS” %}}\n",
        "\n",
        "Pour lister les fichiers, c’est la méthode `ls` (celle-ci ne liste pas par\n",
        "défaut les fichiers de manière récursive comme `boto3`):"
      ],
      "id": "a90067af-9520-456b-8b34-361bf20245d4"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "fs.ls(\"donnees-insee\")"
      ],
      "id": "b3c8ed0c-9654-4de5-93e9-005f9cdcee07"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "{{% /tab %}}\n",
        "\n",
        "{{% tab tabName=“Arrow” %}}\n",
        "\n",
        "``` python\n",
        "from pyarrow import fs\n",
        "s3 = fs.S3FileSystem(endpoint_override='http://'+'minio.lab.sspcloud.fr')\n",
        "s3.get_file_info(fs.FileSelector('donnees-insee', recursive=True))\n",
        "```\n",
        "\n",
        "{{% /tab %}}\n",
        "\n",
        "{{% tab tabName=“mc” %}}\n",
        "\n",
        "``` shell\n",
        "mc ls -r\n",
        "```\n",
        "\n",
        "{{% /tab %}}\n",
        "\n",
        "{{< /tabs >}}\n",
        "\n",
        "## Télécharger un fichier depuis s3 pour l’enregistrer en local\n",
        "\n",
        "Cette méthode n’est en général pas recommandée car, comme on va le voir\n",
        "par la suite, il est possible de lire à la volée des fichiers. Cependant,\n",
        "télécharger un fichier depuis le *cloud* pour l’écrire sur le disque\n",
        "local peut parfois être utile (par exemple, lorsqu’il est nécessaire\n",
        "de dézipper un fichier).\n",
        "\n",
        "{{< tabs tabTotal=“4” >}}\n",
        "\n",
        "{{% tab tabName=“boto3” %}}\n",
        "\n",
        "On utilise cette fois la méthode `download_file`\n",
        "\n",
        "``` python\n",
        "s3.download_file('donnees-insee', \"FILOSOFI/2014/FILOSOFI_COM.csv\", 'data.csv')\n",
        "```\n",
        "\n",
        "{{% /tab %}}\n",
        "\n",
        "{{% tab tabName=“S3FS” %}}\n",
        "\n",
        "``` python\n",
        "fs.download('donnees-insee/FILOSOFI/2014/FILOSOFI_COM.csv','test.csv')\n",
        "```\n",
        "\n",
        "{{% /tab %}}\n",
        "\n",
        "{{% tab tabName=“Snakemake” %}}\n",
        "\n",
        "``` python\n",
        "from snakemake.remote.S3 import RemoteProvider as S3RemoteProvider\n",
        "S3 = S3RemoteProvider(host = \"https://\" + os.getenv('AWS_S3_ENDPOINT'))\n",
        "bucket = \"mon-bucket\"\n",
        "\n",
        "rule ma_super_regle_s3:\n",
        "    input:\n",
        "        fichier = S3.remote(f'{bucket}/moninput.csv')\n",
        "    output:\n",
        "        fichier='mon_dossier_local/monoutput.csv'\n",
        "    run:\n",
        "        shell(\"cp {input[0]} {output[0]}\")\n",
        "```\n",
        "\n",
        "{{% /tab %}}\n",
        "\n",
        "{{% tab tabName=“mc” %}}"
      ],
      "id": "c0904ac8-8435-419f-8ee7-3ce6526e775e"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "mc cp \"donnees-insee/FILOSOFI/2014/FILOSOFI_COM.csv\" 'data.csv'"
      ],
      "id": "72ef503b-f896-4255-8e5b-3aa9f97bdb18"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "{{% /tab %}}\n",
        "\n",
        "{{< /tabs >}}\n",
        "\n",
        "## Lire un fichier directement\n",
        "\n",
        "La méthode précédente n’est pas optimale. En effet, l’un des intérêts des API\n",
        "est qu’on peut traiter un fichier sur `S3` comme s’il s’agissait d’un fichier\n",
        "sur son PC. Cela est d’ailleurs une manière plus sécurisée de procéder puisqu’on\n",
        "lit les données à la volée, sans les écrire dans un filesystem local.\n",
        "\n",
        "{{< tabs tabTotal=“4” >}}\n",
        "\n",
        "{{% tab tabName=“boto3” %}}\n",
        "\n",
        "``` python\n",
        "obj = s3.get_object(Bucket='donnees-insee', Key=\"FILOSOFI/2014/FILOSOFI_COM.csv\")\n",
        "df = pd.read_csv(obj['Body'], sep = \";\")\n",
        "df.head(2)\n",
        "```\n",
        "\n",
        "{{% /tab %}}\n",
        "\n",
        "{{% tab tabName=“S3FS” %}}\n",
        "\n",
        "Le code suivant devrait permettre d’effectuer la même opération avec `s3fs`\n",
        "\n",
        "``` python\n",
        "df = pd.read_csv(fs.open('{}/{}'.format('donnees-insee', \"FILOSOFI/2014/FILOSOFI_COM.csv\"),\n",
        "                         mode='rb')\n",
        "                 )\n",
        "\n",
        "df.head(2)\n",
        "```\n",
        "\n",
        "{{% /tab %}}\n",
        "\n",
        "{{% tab tabName=“Snakemake” %}}\n",
        "\n",
        "``` python\n",
        "from snakemake.remote.S3 import RemoteProvider as S3RemoteProvider\n",
        "S3 = S3RemoteProvider(host = \"https://\" + os.getenv('AWS_S3_ENDPOINT'))\n",
        "bucket = \"mon-bucket\"\n",
        "\n",
        "rule ma_super_regle_s3:\n",
        "    input:\n",
        "        fichier = S3.remote(f'{bucket}/moninput.csv')\n",
        "    run:\n",
        "        import pandas as pd\n",
        "        df = pd.read_csv(input.fichier)\n",
        "        # PLUS D'OPERATIONS\n",
        "```\n",
        "\n",
        "{{% /tab %}}\n",
        "\n",
        "{{% tab tabName=“Arrow” %}}\n",
        "\n",
        "`Arrow` est une librairie qui permet de lire des `CSV`.\n",
        "Il est néanmoins\n",
        "beaucoup plus pratique d’utiliser le format `parquet` avec `arrow`.\n",
        "Dans un premier temps, on configure le *filesystem* avec les\n",
        "fonctionalités d’`Arrow` (cf. précédemment)."
      ],
      "id": "53ba2c8b-c81d-48f7-9d7d-f2a29f1c2e00"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyarrow import fs\n",
        "\n",
        "s3 = fs.S3FileSystem(endpoint_override='http://'+'minio.lab.sspcloud.fr')"
      ],
      "id": "f2315874-e4ca-4e45-a338-8e4708702f31"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pour lire un csv, on fera:\n",
        "\n",
        "``` python\n",
        "from pyarrow import csv\n",
        "\n",
        "with s3.open_input_file(\"donnees-insee/FILOSOFI/2014/FILOSOFI_COM.csv\") as file:\n",
        "    df = csv.read_csv(file, parse_options=csv.ParseOptions(delimiter=\";\")).to_pandas()\n",
        "\n",
        "df.head(2)\n",
        "```\n",
        "\n",
        "Pour un fichier au format parquet, on privilégiera:\n",
        "\n",
        "``` python\n",
        "import pyarrow.parquet as pq\n",
        "#bucket = \"\"\n",
        "#parquet_file=\"\"\n",
        "df = pq.ParquetDataset(f'{bucket}/{parquet_file}', filesystem=s3).read_pandas().to_pandas()\n",
        "```\n",
        "\n",
        "{{% /tab %}}\n",
        "\n",
        "{{< /tabs >}}\n",
        "\n",
        "## Uploader un fichier\n",
        "\n",
        "{{< tabs tabTotal=“5” >}}\n",
        "\n",
        "{{% tab tabName=“boto3” %}}\n",
        "\n",
        "``` python\n",
        "s3.upload_file(file_name, bucket, object_name)\n",
        "```\n",
        "\n",
        "{{% /tab %}}\n",
        "\n",
        "{{% tab tabName=“S3FS” %}}\n",
        "\n",
        "``` python\n",
        "fs.upload(bucket + \"/\" + file_name)\n",
        "```\n",
        "\n",
        "{{% /tab %}}\n",
        "\n",
        "{{% tab tabName=“Arrow” %}}\n",
        "\n",
        "Supposons que `df` soit un `pd.DataFrame`\n",
        "Dans un système local, on convertirait\n",
        "en table `Arrow` puis on écrirait en `parquet`\n",
        "([voir la documentation officielle](https://arrow.apache.org/docs/python/parquet.html#reading-and-writing-single-files)).\n",
        "Quand on est sur un système `S3`, il s’agit seulement d’ajouter\n",
        "notre connexion à `S3` dans l’argument `filesystem`\n",
        "([voir la page sur ce sujet dans la documentation Arrow](https://arrow.apache.org/docs/python/filesystems.html#filesystem-s3))\n",
        "\n",
        "``` python\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "\n",
        "table = pa.Table.from_pandas(df)\n",
        "pq.write_table(table, f\"{bucket}/{path}\", filesystem=s3)\n",
        "```\n",
        "\n",
        "{{% /tab %}}\n",
        "\n",
        "{{% tab tabName=“Snakemake” %}}\n",
        "\n",
        "``` python\n",
        "from snakemake.remote.S3 import RemoteProvider as S3RemoteProvider\n",
        "S3 = S3RemoteProvider(host = \"https://\" + os.getenv('AWS_S3_ENDPOINT'))\n",
        "bucket = \"mon-bucket\"\n",
        "\n",
        "rule ma_super_regle_s3:\n",
        "    input:\n",
        "        fichier='mon_dossier_local/moninput.csv'\n",
        "    output:\n",
        "        fichier=S3.remote(f'{bucket}/monoutput.csv')\n",
        "    run:\n",
        "        shell(\"cp output.fichier input.fichier\")\n",
        "```\n",
        "\n",
        "{{% /tab %}}\n",
        "\n",
        "{{% tab tabName=“mc” %}}\n",
        "\n",
        "``` python\n",
        "mc cp 'data.csv' \"MONBUCKET/monoutput.csv\"\n",
        "```\n",
        "\n",
        "{{% /tab %}}\n",
        "\n",
        "{{< /tabs >}}\n",
        "\n",
        "## Pour aller plus loin\n",
        "\n",
        "-   [La documentation sur MinIO du SSPCloud](https://docs.sspcloud.fr/onyxia-guide/stockage-de-donnees)"
      ],
      "id": "113790da-5940-46b1-83dd-7763624622b2"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  }
}