{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Les nouveaux modes d'acc√®s aux donn√©es: le format parquet et les donn√©es sur le cloud\"\n",
        "date: 2022-08-28T15:00:00Z\n",
        "draft: false\n",
        "weight: 20\n",
        "slug: readS3\n",
        "type: book\n",
        "tags:\n",
        "  - S3\n",
        "  - boto3\n",
        "categories:\n",
        "  - Tutoriel\n",
        "summary: |\n",
        "  Dans les entreprises et administrations, un nombre croissant \n",
        "  d'infrastructure se basent sur des _clouds_, qui sont des sessions \n",
        "  non persistentes o√π les donn√©es ne sont pas stock√©es dans les m√™mes\n",
        "  serveurs que les machines qui ex√©cutent du code. L'une des technologies\n",
        "  dominantes dans le domaine est un syst√®me de stockage nomm√© `S3`,\n",
        "  d√©velopp√© par [Amazon](https://docs.aws.amazon.com/fr_fr/AmazonS3/latest/userguide/Welcome.html). \n",
        "  \n",
        "  `Python`, √† travers plusieurs _packages_ (notamment `boto3`, `s3fs` ou `pyarrow`),\n",
        "  permet d'utiliser ce syst√®me de stockage distant comme si on\n",
        "  acc√©dait √† des fichiers depuis son poste personnel. Cette r√©volution est \n",
        "  √©troitement associ√©e √† l'√©mergence du format de\n",
        "  donn√©es [`Apache Parquet`](https://parquet.apache.org/), format utilisable en\n",
        "  `Python` par le biais du package [`pyarrow`](https://arrow.apache.org/docs/python/index.html)\n",
        "  ou avec [`Spark`](https://spark.apache.org/) et pr√©sentant\n",
        "  de nombreux avantages pour l'analyse de donn√©es (vitesse d'import, possibilit√© de traiter\n",
        "  des donn√©es plus volumineuses que la RAM...)\n",
        "eval: false\n",
        "---"
      ],
      "id": "9bb59d28"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.cell .markdown}"
      ],
      "id": "d311aaa4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| output: 'asis'\n",
        "#| include: true\n",
        "#| eval: true\n",
        "\n",
        "import sys\n",
        "sys.path.insert(1, '../../../../') #insert the utils module\n",
        "from utils import print_badges\n",
        "\n",
        "#print_badges(__file__)\n",
        "print_badges(\"content/course/NLP/05a_s3.qmd\")"
      ],
      "id": "4aaf4cbe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "Ce chapitre est une introduction √† la question\n",
        "du stockage des donn√©es et aux innovations \n",
        "r√©centes dans ce domaine. L'objectif\n",
        "est d'abord de pr√©senter les avantages\n",
        "du format `Parquet` et la mani√®re dont \n",
        "on peut utiliser les\n",
        "librairies [`pyarrow`](https://arrow.apache.org/docs/python/index.html)\n",
        "ou [`duckdb`](https://duckdb.org/docs/api/python/overview.html) pour traiter\n",
        "de mani√®re efficace des donn√©es volumineuses\n",
        "au format `Parquet`. Ensuite, on pr√©sentera\n",
        "la mani√®re dont ce format `parquet` s'int√®gre\n",
        "bien avec des syst√®mes de stockage _cloud_,\n",
        "qui tendent √† devenir la norme dans le monde\n",
        "de la _data science_. \n",
        "\n",
        "# Elements de contexte\n",
        "\n",
        "## Principe du stockage de la donn√©e\n",
        "\n",
        "Pour comprendre les apports du format `Parquet`, il est n√©cessaire\n",
        "de faire un d√©tour pour comprendre la mani√®re dont une information\n",
        "est stock√©e et accessible √† un langage de traitement de la donn√©e.\n",
        "\n",
        "Il existe deux approches dans le monde du stockage de la donn√©e. \n",
        "La premi√®re est celle de la __base de donn√©es relationnelle__. La seconde est le\n",
        "principe du __fichier__. \n",
        "La diff√©rence entre les deux est dans la mani√®re dont l'acc√®s aux\n",
        "donn√©es est organis√©. \n",
        "\n",
        "## Les fichiers\n",
        "\n",
        "Dans un fichier, les donn√©es sont organis√©es selon un certain format et\n",
        "le logiciel de traitement de la donn√©e va aller chercher et structurer\n",
        "l'information en fonction de ce format. Par exemple, dans un fichier \n",
        "`.csv`, les diff√©rentes informations seront stock√©es au m√™me niveau\n",
        "avec un caract√®re pour les s√©parer (la virgule `,` dans les `.csv` anglosaxons, le point virgule dans les `.csv` fran√ßais, la tabulation dans les `.tsv`). Le fichier suivant\n",
        "\n",
        "```raw\n",
        "nom ; profession \n",
        "Ast√©rix ; \n",
        "Ob√©lix ; Tailleur de menhir ;\n",
        "Assurancetourix ; Barde\n",
        "```\n",
        "\n",
        "sera ainsi organis√© naturellement sous forme tabul√©e par `Python`\n"
      ],
      "id": "59a73181"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| eval: true\n",
        "\n",
        "import pandas as pd\n",
        "from io import StringIO\n",
        "pd.read_csv(\n",
        "    StringIO(\n",
        "        \"\"\"\n",
        "        nom ; profession\n",
        "        Ast√©rix ; \n",
        "        Ob√©lix ; Tailleur de menhir\n",
        "        Assurancetourix ; Barde\n",
        "        \"\"\"\n",
        "    ),\n",
        "    sep = \";\"\n",
        ")"
      ],
      "id": "44015a3f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A propos des fichiers de ce type, on parle de __fichiers plats__ car\n",
        "les enregistrements relatifs √† une observation sont stock√©s ensemble,\n",
        "sans hi√©rarchie.  \n",
        "\n",
        "Certains formats de donn√©es vont permettre d'organiser les informations\n",
        "de mani√®re diff√©rente. Par exemple, le format `JSON` va\n",
        "hi√©rarchiser diff√©remment la m√™me information [^1]:\n",
        "\n",
        "```raw\n",
        "[\n",
        "  {\n",
        "    \"nom\": \"Ast√©rix\"\n",
        "  },\n",
        "  {\n",
        "    \"nom\": \"Ob√©lix\",\n",
        "    \"profession\": \"Tailleur de menhir\"\n",
        "  },\n",
        "  {\n",
        "    \"nom\": \"Assurancetourix\",\n",
        "    \"profession\": \"Barde\"\n",
        "  }\n",
        "]\n",
        "```\n",
        "\n",
        "::: {.cell .markdown}\n",
        "\n",
        "```{=html}\n",
        "<div class=\"alert alert-warning\" role=\"alert\">\n",
        "<h3 class=\"alert-heading\"><i class=\"fa-solid fa-lightbulb\"></i> Hint </h3>\n",
        "```\n",
        "\n",
        "La diff√©rence entre le CSV et le format `JSON` va au-del√† d'un simple \"formattage\" des donn√©es.\n",
        "\n",
        "Par sa nature non tabulaire, le format JSON permet des mises √† jour beaucoup plus facile de la donn√©e dans les entrep√¥ts de donn√©es.\n",
        "\n",
        "Par exemple, un site web qui collecte de nouvelles donn√©es n'aura pas √† mettre √† jour l'ensemble de ses enregistrements ant√©rieurs\n",
        "pour stocker la nouvelle donn√©e (par exemple pour indiquer que pour tel ou tel client cette donn√©e n'a pas √©t√© collect√©e)\n",
        "mais pourra la stocker dans\n",
        "un nouvel item. Ce sera √† l'outil de requ√™te (`Python` ou un autre outil)\n",
        "de cr√©er une relation entre les enregistrements stock√©s √† des endroits\n",
        "diff√©rents.\n",
        "\n",
        "Ce type d'approche flexible est l'un des fondements de l'approche `NoSQL`,\n",
        "sur laquelle nous allons revenir, qui a permis l'√©mergence de technologies au coeur de l'√©cosyst√®me actuel du _big-data_ comme `Hadoop` ou `ElasticSearch`. \n",
        "\n",
        "\n",
        "```{=html}\n",
        "</div>\n",
        "```\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "Cette fois, quand on n'a pas d'information, on ne se retrouve pas avec nos deux s√©parateurs accol√©s (cf. la ligne _\"Ast√©rix\"_) mais l'information\n",
        "n'est tout simplement pas collect√©e. \n",
        "\n",
        "::: {.cell .markdown}\n",
        "\n",
        "```{=html}\n",
        "<div class=\"alert alert-info\" role=\"alert\">\n",
        "<h3 class=\"alert-heading\"><i class=\"fa-solid fa-comment\"></i> Note</h3>\n",
        "```\n",
        "\n",
        "Il se peut tr√®s bien que l'information sur une observation soit diss√©min√©e\n",
        "dans plusieurs fichiers dont les formats diff√®rent.\n",
        "\n",
        "Par exemple, dans le domaine des donn√©es g√©ographiques,\n",
        "lorsqu'une donn√©e est disponible sous format de fichier(s), elle peut l'√™tre de deux mani√®res!\n",
        "\n",
        "- Soit la donn√©e est stock√©e dans un seul fichier qui m√©lange contours g√©ographiques et valeurs attributaires\n",
        "(la valeur associ√©e √† cette observation g√©ographique, par exemple le taux d'abstention). Ce principe est celui du `geojson`.\n",
        "- Soit la donn√©e est stock√©e dans plusieurs fichiers qui sont sp√©cialis√©s: un fichier va stocker les contours g√©ographiques,\n",
        "l'autre les donn√©es attributaires et d'autres fichiers des informations annexes (comme le syst√®me de projection). Ce principe est celui du `shapefile`.\n",
        "C'est alors le logiciel qui requ√™te\n",
        "les donn√©es (`Python` par exemple) qui saura o√π aller chercher l'information\n",
        "dans les diff√©rents fichiers et associer celle-ci de mani√®re coh√©rente.\n",
        "\n",
        "\n",
        "```{=html}\n",
        "</div>\n",
        "```\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "Un concept suppl√©mentaire dans le monde du fichier est celui du __file system__. Le  _file system_ est\n",
        "le syst√®me de localisation et de nommage des fichiers. \n",
        "Pour simplifier, le _file system_ est la mani√®re dont votre ordinateur saura\n",
        "retrouver, dans son syst√®me de stockage, les bits pr√©sents dans tel ou tel fichier\n",
        "appartenant √† tel ou tel dossier.  \n",
        "\n",
        "## Les bases de donn√©es\n",
        "\n",
        "\n",
        "La logique des bases de donn√©es est diff√©rente. Elle est plus syst√©mique. \n",
        "Un syst√®me de gestion de base de donn√©es (_Database Management System_)\n",
        "est un logiciel qui g√®re √† la fois le stockage d'un ensemble de donn√©es reli√©e,\n",
        "permet de mettre √† jour celle-ci (ajout ou suppression d'informations, modification\n",
        "des caract√©ristiques d'une table...)\n",
        "et qui g√®re √©galement\n",
        "les modalit√©s d'acc√®s √† la donn√©e (type de requ√™te, utilisateurs\n",
        "ayant les droits en lecture ou en √©criture...). \n",
        "\n",
        "La relation entre les entit√©s pr√©sentes dans une base de donn√©es\n",
        "prend g√©n√©ralement la forme d'un __sch√©ma en √©toile__. Une base va centraliser\n",
        "les informations disponibles qui seront ensuite d√©taill√©es dans des tables\n",
        "d√©di√©es. \n",
        "\n",
        "![](https://www.databricks.com/wp-content/uploads/2022/04/star-schema-erd.png)\n",
        "Source: [La documentation `Databricks` sur le sch√©ma en √©toile](https://www.databricks.com/fr/glossary/star-schema)\n",
        "\n",
        "Le logiciel associ√© √† la base de donn√©es fera ensuite le lien\n",
        "entre ces tables √† partir de requ√™tes `SQL`. L'un des logiciels les plus efficaces dans ce domaine\n",
        "est [`PostgreSQL`](https://www.postgresql.org/). `Python` est tout √† fait\n",
        "utilisable pour passer une requ√™te SQL √† un gestionnaire de base de donn√©es. \n",
        "Les packages [`sqlalchemy`](https://www.sqlalchemy.org/) et [`psycopg2`](https://www.psycopg.org/docs/)\n",
        "peuvent servir √† utiliser `PostgreSQL` pour requ√™ter une\n",
        "base de donn√©e ou la mettre √† jour. \n",
        "\n",
        "La logique de la base de donn√©es est donc tr√®s diff√©rente de celle du fichier.\n",
        "Ces derniers sont beaucoup plus l√©gers pour plusieurs raisons. \n",
        "D'abord, parce qu'ils sont moins adh√©rents √† \n",
        "un logiciel gestionnaire. L√† o√π le fichier ne n√©cessite, pour la gestion,\n",
        "qu'un _file system_, install√© par d√©faut sur\n",
        "tout syst√®me d'exploitation, une base de donn√©es va n√©cessiter un\n",
        "logiciel sp√©cialis√©. L'inconv√©nient de l'approche fichier, sous sa forme\n",
        "standard, est qu'elle\n",
        "ne permet pas une gestion fine des droits d'acc√®s et am√®ne g√©n√©ralement √† une \n",
        "duplication de la donn√©e pour √©viter que la source initiale soit\n",
        "r√©-√©crite (involontairement ou de mani√®re intentionnelle par un utilisateur malveillant).\n",
        "R√©soudre ce probl√®me est l'une des\n",
        "innovations des syst√®mes _cloud_, sur lesquelles nous reviendrons en √©voquant le\n",
        "syst√®me `S3`.\n",
        "Un deuxi√®me inconv√©nient de l'approche base de donn√©es par\n",
        "rapport √† l'approche fichier, pour un utilisateur de `Python`,\n",
        "est que les premiers n√©cessitent l'interm√©diation du logiciel de gestion \n",
        "de base de donn√©es l√† o√π, dans le second cas, on va se contenter d'une\n",
        "librairie, donc un syst√®me beaucoup plus l√©ger, \n",
        "qui sait comment transformer la donn√©e brute en `DataFrame`. \n",
        "Pour ces raisons, entre autres, les bases de donn√©es sont donc moins √† la \n",
        "mode dans l'√©cosyst√®me r√©cent de la _data-science_ que les fichiers.\n",
        "\n",
        "# Le format `parquet`\n",
        "\n",
        "\n",
        "Le format `CSV` a rencontr√© un grand succ√®s par sa simplicit√©: il \n",
        "est lisible par un humain (un bloc-note suffit pour l'ouvrir et\n",
        "apercevoir les premi√®res lignes), sa nature plate lui permet\n",
        "de bien correspondre au concept de donn√©es tabul√©es sans hi√©rarchie \n",
        "qui peuvent √™tre rapidement valoris√©es, il est universel (il n'est\n",
        "pas adh√©rent √† un logiciel). Cependant, le CSV pr√©sente\n",
        "plusieurs inconv√©nients qui justifient l'√©mergence d'un format\n",
        "concurrent:\n",
        "\n",
        "- le CSV est un format __lourd__ car les informations ne sont pas compress√©es \n",
        "(ce qui le rend lisible facilement depuis un bloc-note) mais aussi\n",
        "parce que toutes les donn√©es sont stock√©es de la m√™me mani√®re.\n",
        "C'est la\n",
        "librairie faisant l'import qui va essayer d'optimiser le typage des donn√©es\n",
        "pour trouver le typage qui utilise le moins de m√©moire possible sans\n",
        "alt√©ration de l'information. En effet, si `pandas` d√©termine qu'une colonne\n",
        "pr√©sente les valeurs `6 ; 5 ; 0`, il va privil√©gier l'utilisation du type\n",
        "`int` au type `double` qui sera lui m√™me pr√©f√©r√© au type `object` (objets\n",
        "de type donn√©es textuelles). Cependant, pour faire cela, `pandas` va devoir\n",
        "scanner un nombre suffisant de valeurs, ce qui demande du temps et expose \n",
        "√† des erreurs (en se fondant sur trop peu de valeurs, on peut se tromper\n",
        "de typage) ;\n",
        "- le stockage √©tant __orient√© ligne__, \n",
        "acc√©der √† une information donn√©e dans un `CSV` implique\n",
        "de le lire le fichier en entier, s√©lectionner la ou les colonnes\n",
        "d'int√©r√™t et ensuite les lignes d√©sir√©es. Par exemple, si on d√©sire\n",
        "conna√Ætre uniquement la profession de la deuxi√®me ligne dans l'exemple\n",
        "plus haut :point_up:, un algorithme de recherche devra:\n",
        "prendre le fichier, d√©terminer que la profession est la deuxi√®me colonne,\n",
        "et ensuite aller chercher la deuxi√®me ligne dans cette colonne. Si\n",
        "on d√©sire acc√©der √† un sous-ensemble de lignes dont les indices\n",
        "sont connus, le `CSV` est int√©ressant. Cependant,\n",
        "si on d√©sire acc√©der √† un sous-ensemble\n",
        "de colonnes dans un fichier (ce qui est un cas d'usage plus fr√©quent\n",
        "pour les _data-scientists_), alors le `CSV` n'est pas le format le plus\n",
        "appropri√© ;\n",
        "- mettre √† jour la donn√©e est co√ªteux car cela implique de r√©√©crire\n",
        "l'ensemble du fichier. Par exemple, si apr√®s une premi√®re\n",
        "analyse de la donn√©e,\n",
        "on d√©sire ajouter une colonne, on ne peut accoler ces nouvelles informations\n",
        "√† celles d√©j√† existantes, il est n√©cessaire de r√©√©crire l'ensemble \n",
        "du fichier. Pour reprendre l'exemple de nos gaulois pr√©f√©r√©s, si on veut\n",
        "ajouter une colonne `cheveux` entre les deux d√©j√† existantes,\n",
        "il faudra changer totalement le fichier: \n",
        "\n",
        "```raw\n",
        "\"\"\"\n",
        "nom ; cheveux ; profession\n",
        "Ast√©rix; blond; ; \n",
        "Ob√©lix; roux; Tailleur de menhir\n",
        "Assurancetourix; blond; Barde\n",
        "\"\"\"\n",
        "```\n",
        "\n",
        "::: {.cell .markdown}\n",
        "\n",
        "```{=html}\n",
        "<div class=\"alert alert-info\" role=\"alert\">\n",
        "<h3 class=\"alert-heading\"><i class=\"fa-solid fa-comment\"></i> Note</h3>\n",
        "```\n",
        "\n",
        "La plupart des logiciels d'analyse de donn√©es proposent \n",
        "un format de fichier pour sauvegarder des bases de donn√©es. On\n",
        "peut citer le `.pickle` (`Python`), le `.rda` ou `.RData` (`R`),\n",
        "le `.dta` (`Stata`) ou le `.sas7bdat` (`SAS`). L'utilisation\n",
        "de ces formats est probl√©matique car cela revient √† se lier\n",
        "les mains pour l'analyse ult√©rieure des donn√©es, surtout\n",
        "lorsqu'il s'agit d'un format propri√©taire (comme avec\n",
        "`SAS` ou `Stata`). Par exemple, `Python` ne\n",
        "sait pas nativement lire un `.sas7bdat`. Il existe des librairies\n",
        "pour le faire (notamment `Pandas`) mais le format\n",
        "√©tant propri√©taire, les d√©veloppeurs de la librairie ont d√ª t√¢tonner et\n",
        "on n'est ainsi jamais assur√© qu'il n'y ait pas d'alt√©ration de la donn√©e. \n",
        "\n",
        "Malgr√© tous les inconv√©nients du `.csv` list√©s plus haut, il pr√©sente \n",
        "l'immense avantage, par rapport √† ces formats, de l'universalit√©. \n",
        "Il vaut ainsi mieux privil√©gier un `.csv` √† ces formats pour le stockage\n",
        "de la donn√©e. Ceci dit, comme vise √† le montrer ce chapitre, il vaut\n",
        "mieux privil√©gier le format `parquet` au `CSV`.\n",
        "\n",
        "```{=html}\n",
        "</div>\n",
        "```\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "Pour r√©pondre √† ces limites du `CSV`, le format `parquet`, \n",
        "qui est un [projet open-source `Apache`](https://apache.org/), a √©merg√©.\n",
        "La premi√®re diff√©rence entre le format `parquet` et le `CSV` est\n",
        "que le premier repose sur un __stockage orient√© colonne__ l√† o√π\n",
        "le second est orient√© ligne. Pour comprendre la diff√©rence, voici un\n",
        "exemple issu du [blog d'upsolver](https://www.upsolver.com/blog/apache-parquet-why-use): \n",
        "\n",
        "![](https://www.upsolver.com/wp-content/uploads/2020/05/Screen-Shot-2020-05-26-at-17.52.58.png)\n",
        "\n",
        "Dans notre exemple pr√©c√©dent, cela donnera une information prenant \n",
        "la forme suivante (ignorez l'√©l√©ment `pyarrow.Table`, nous\n",
        "reviendrons dessus) :\n"
      ],
      "id": "f38dd5b7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| eval: true\n",
        "from pyarrow import csv\n",
        "import io\n",
        "\n",
        "s = \"\"\"\n",
        "nom ;profession\n",
        "Ast√©rix ;\n",
        "Ob√©lix ;Tailleur de menhir\n",
        "Assurancetourix ;Barde\n",
        "\"\"\"\n",
        "\n",
        "source = io.BytesIO(s.encode())\n",
        "\n",
        "df = csv.read_csv(source, parse_options = csv.ParseOptions(delimiter=\";\"))\n",
        "df"
      ],
      "id": "b8910386",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pour reprendre l'exemple fil rouge :point_up:, il sera ainsi beaucoup plus\n",
        "facile de r√©cup√©rer la deuxi√®me ligne de la colonne `profession`:\n",
        "on ne consid√®re que le vecteur `profession` et on r√©cup√®re la deuxi√®me\n",
        "valeur. \n",
        "Le requ√™tage d'√©chantillon de donn√©es ne n√©cessite donc pas l'import de \n",
        "l'ensemble des donn√©es. A cela s'ajoute des fonctionnalit√©s suppl√©mentaires\n",
        "des librairies d'import de donn√©es parquet (par exemple `pyarrow` ou `spark`)\n",
        "qui vont faciliter des recherches complexes bas√©es, par exemple, sur des\n",
        "requ√™tes de type `SQL`, ou permettant l'utilisation de donn√©es plus volumineuses que la RAM. \n",
        "\n",
        "Le format `parquet` pr√©sente d'autres avantages par rapport au\n",
        "`CSV`: \n",
        "\n",
        "- Le format `parquet` est (tr√®s) compress√©, ce qui r√©duit la volum√©trie\n",
        "des donn√©es sur disque ;\n",
        "- Des m√©tadonn√©es, notamment le typage des variables, sont stock√©es en compl√©ment dans le fichier.\n",
        "Cette partie, nomm√©e le _footer_ du fichier `parquet`, permet que l'import des donn√©es soit \n",
        "optimis√© sans risque d'alt√©ration de celle-ci. Pour un producteur de donn√©es, c'est une mani√®re\n",
        "d'assurer la qualit√© des donn√©es. Par exemple, un fournisseur de\n",
        "donn√©es de type code-barre sera\n",
        "certain que les donn√©es `000012` ne seront pas consid√©r√©es identiques √† un code-barre `12`.\n",
        "- Il est possible de partitionner un jeu de donn√©es en fonction de diff√©rents niveaux (par\n",
        "exemple des niveaux g√©ographiques) en une arborescence de fichiers `parquet`. Cela\n",
        "permet de travailler sur un √©chantillon pour facilement passer √† l'√©chelle ensuite.\n",
        "Par exemple, une structure partitionn√©e, emprunt√©e\n",
        "√† la [documentation `Spark`](https://spark.apache.org/docs/latest/sql-data-sources-parquet.html#partition-discovery)\n",
        "peut prendre la forme suivante:\n",
        "\n",
        "```raw\n",
        "path\n",
        "‚îî‚îÄ‚îÄ to\n",
        "    ‚îî‚îÄ‚îÄ table\n",
        "        ‚îú‚îÄ‚îÄ gender=male\n",
        "        ‚îÇ   ‚îú‚îÄ‚îÄ ...\n",
        "        ‚îÇ   ‚îÇ\n",
        "        ‚îÇ   ‚îú‚îÄ‚îÄ country=US\n",
        "        ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ data.parquet\n",
        "        ‚îÇ   ‚îú‚îÄ‚îÄ country=CN\n",
        "        ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ data.parquet\n",
        "        ‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
        "        ‚îî‚îÄ‚îÄ gender=female\n",
        "            ‚îú‚îÄ‚îÄ ...\n",
        "            ‚îÇ\n",
        "            ‚îú‚îÄ‚îÄ country=US\n",
        "            ‚îÇ   ‚îî‚îÄ‚îÄ data.parquet\n",
        "            ‚îú‚îÄ‚îÄ country=CN\n",
        "            ‚îÇ   ‚îî‚îÄ‚îÄ data.parquet\n",
        "            ‚îî‚îÄ‚îÄ ...\n",
        "```\n",
        "\n",
        "Qu'on lise un ou plusieurs fichiers, on finira avec le sch√©ma suivant:\n",
        "\n",
        "```raw\n",
        "root\n",
        "|-- name: string (nullable = true)\n",
        "|-- age: long (nullable = true)\n",
        "|-- gender: string (nullable = true)\n",
        "|-- country: string (nullable = true)\n",
        "```\n",
        "\n",
        "Ces diff√©rents avantages expliquent le succ√®s du format `parquet` dans le monde du\n",
        "_big-data_. Le paragraphe suivant, extrait du [post d'upsolver]() d√©j√† cit√©, \n",
        "r√©sume bien l'int√©r√™t:\n",
        "\n",
        "> Complex data such as logs and event streams would need to be represented as a table with hundreds or thousands of columns, and many millions of rows. Storing this table in a row based format such as CSV would mean:\n",
        "> \n",
        "> - Queries will take longer to run since more data needs to be scanned, rather than only querying the subset of columns we need to answer a query (which typically requires aggregating based on dimension or category)\n",
        "> - Storage will be more costly since CSVs are not compressed as efficiently as Parquet\n",
        "\n",
        "Cependant, **`Parquet` ne devrait pas int√©resser que les producteurs ou utilisateurs de donn√©es _big-data_**.\n",
        "C'est l'ensemble\n",
        "des producteurs de donn√©es qui b√©n√©ficient des fonctionalit√©s\n",
        "de `Parquet`. \n",
        "\n",
        "Pour en savoir plus sur `Arrow`,\n",
        "des √©l√©ments suppl√©mentaires sur `Parquet` sont disponibles sur ce tr√®s bon\n",
        "post de blog d'[upsolver](https://www.upsolver.com/blog/apache-parquet-why-use)\n",
        "et [sur la page officielle du projet `Parquet`](https://parquet.apache.org/).\n",
        "\n",
        "## Lire un `parquet` en `Python`: la librairie `pyarrow`\n",
        "\n",
        "La librairie `pyarrow` permet la lecture et l'√©criture\n",
        "de fichiers `parquet` avec `Python`[^3]. Elle repose\n",
        "sur un type particulier de _dataframe_, le `pyarrow.Table`\n",
        "qui peut √™tre utilis√© en substitut ou en compl√©ment\n",
        "du `DataFrame` \n",
        "de `pandas`. Il est recommand√© de r√©guli√®rement\n",
        "consulter la documentation officielle de `pyarrow` \n",
        "concernant [la lecture et √©criture de fichiers](https://arrow.apache.org/docs/python/parquet.html) et celle relative\n",
        "aux [manipulations de donn√©es](https://arrow.apache.org/cookbook/py/data.html).\n",
        "\n",
        "[^3]: Elle permet aussi la lecture et l'√©criture \n",
        "de `.csv`.\n",
        "\n",
        "Pour illustrer les fonctionalit√©s de `pyarrow`,\n",
        "repartons de notre CSV initial que nous allons\n",
        "enrichir d'une nouvelle variable num√©rique\n",
        "et que nous\n",
        "allons \n",
        "convertir en objet `pyarrow` avant de l'√©crire au format `parquet`:\n"
      ],
      "id": "4c884709"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: true\n",
        "import pandas as pd\n",
        "from io import StringIO \n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "\n",
        "s = \"\"\"\n",
        "nom;cheveux;profession\n",
        "Ast√©rix;blond;\n",
        "Ob√©lix;roux;Tailleur de menhir\n",
        "Assurancetourix;blond;Barde\n",
        "\"\"\"\n",
        "\n",
        "source = StringIO(s)\n",
        "\n",
        "df = pd.read_csv(source, sep = \";\", index_col=False)\n",
        "df[\"taille\"] = [155, 190, 175]\n",
        "table = pa.Table.from_pandas(df)\n",
        "\n",
        "table\n",
        "\n",
        "pq.write_table(table, 'example.parquet')"
      ],
      "id": "73c8d742",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.cell .markdown}\n",
        "\n",
        "```{=html}\n",
        "<div class=\"alert alert-warning\" role=\"alert\">\n",
        "<h3 class=\"alert-heading\"><i class=\"fa-solid fa-lightbulb\"></i> Hint </h3>\n",
        "```\n",
        "\n",
        "L'utilisation des noms `pa` pour `pyarrow` et `pq` pour\n",
        "`pyarrow.parquet` est une convention communautaire\n",
        "qu'il est recommand√© de suivre.\n",
        "\n",
        "```{=html}\n",
        "</div>\n",
        "```\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "Pour importer et traiter ces donn√©es, on peut conserver\n",
        "les donn√©es sous le format `pyarrow.Table`\n",
        "ou transformer en `pandas.DataFrame`. La deuxi√®me\n",
        "option est plus lente mais pr√©sente l'avantage\n",
        "de permettre ensuite d'appliquer toutes les\n",
        "manipulations offertes par l'√©cosyst√®me\n",
        "`pandas` qui est g√©n√©ralement mieux connu que\n",
        "celui d'`Arrow`. \n",
        "\n",
        "Supposons qu'on ne s'int√©resse qu'√† la taille et √† la couleur\n",
        "de cheveux de nos gaulois. \n",
        "Il n'est pas n√©cessaire d'importer l'ensemble de la base, cela\n",
        "ferait perdre du temps pour rien. On appelle\n",
        "cette approche le __`column pruning`__ qui consiste √† \n",
        "ne parcourir, dans le fichier, que les colonnes qui nous\n",
        "int√©ressent. Du fait du stockage orient√© colonne du `parquet`,\n",
        "il suffit de ne consid√©rer que les blocs qui nous \n",
        "int√©ressent (alors qu'avec un CSV il faudrait scanner tout\n",
        "le fichier avant de pouvoir √©liminer certaines colonnes).\n",
        "Ce principe du `column pruning` se mat√©rialise avec\n",
        "l'argument `columns` dans `parquet`.\n",
        "\n",
        "Ensuite, avec `pyarrow`, on pourra utiliser `pyarrow.compute` pour\n",
        "effectuer des op√©rations directement sur une table\n",
        "`Arrow` :\n"
      ],
      "id": "fa9c3c15"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "import pyarrow.compute as pc\n",
        "\n",
        "table = pq.read_table('example.parquet', columns=['taille', 'cheveux'])\n",
        "\n",
        "table.group_by(\"cheveux\").aggregate([(\"taille\", \"mean\")])"
      ],
      "id": "c8263cb5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La mani√®re √©quivalente de proc√©der en passant\n",
        "par l'interm√©diaire de `pandas` est\n"
      ],
      "id": "7e580065"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: true\n",
        "table = pq.read_table('example.parquet', columns=['taille', 'cheveux'])\n",
        "\n",
        "table.to_pandas().groupby(\"cheveux\")[\"taille\"].mean()"
      ],
      "id": "49cd1e50",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ici, comme les donn√©es sont peu volumineuses, deux des\n",
        "avantages du `parquet` par rapport\n",
        "au `CSV` (donn√©es moins\n",
        "volumineuses et vitesse de l'import)\n",
        "ne s'appliquent pas vraiment. \n",
        "\n",
        "\n",
        "::: {.cell .markdown}\n",
        "\n",
        "```{=html}\n",
        "<div class=\"alert alert-info\" role=\"alert\">\n",
        "<h3 class=\"alert-heading\"><i class=\"fa-solid fa-comment\"></i> Note</h3>\n",
        "```\n",
        "\n",
        "\n",
        "Un autre principe d'optimisation de la performance qui est\n",
        "au coeur de la librairie `Arrow` est le `filter pushdown`\n",
        "(ou `predicate pushdown`). \n",
        "\n",
        "Quand on ex√©cute un filtre de s√©lection de ligne \n",
        "juste apr√®s avoir charg√© un jeu de donn√©es,\n",
        "`Arrow` va essayer de le mettre en oeuvre lors de l'√©tape de lecture\n",
        "et non apr√®s. Autrement dit, `Arrow` va modifier le plan \n",
        "d'ex√©cution pour pousser le filtre en amont de la s√©quence d'ex√©cution\n",
        "afin de ne pas essayer de lire les lignes inutiles. \n",
        "\n",
        "\n",
        "```{=html}\n",
        "</div>\n",
        "```\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Le syst√®me de stockage `S3`\n",
        "\n",
        "Si les fichiers `parquet` sont une \n",
        "solution avantageuse pour \n",
        "les _data-scientists_, ils ne r√©solvent\n",
        "pas tous les inconv√©nients de\n",
        "l'approche fichier. \n",
        "En particulier, la question de la\n",
        "duplication des donn√©es pour la mise\n",
        "√† disposition s√©curis√©e des sources\n",
        "n'est pas r√©solue. Pour que \n",
        "l'utilisateur `B` n'alt√®re pas les\n",
        "donn√©es de l'utilisateur `A`, il est n√©cessaire\n",
        "qu'ils travaillent sur deux fichiers\n",
        "diff√©rents, dont l'un peut √™tre une copie\n",
        "de l'autre. \n",
        "\n",
        "# Les donn√©es sur le _cloud_\n",
        "\n",
        "La mise √† disposition de donn√©es dans\n",
        "les syst√®mes de stockage _cloud_ est\n",
        "une r√©ponse √† ce probl√®me.\n",
        "Les _data lake_ qui se sont d√©velopp√©s dans les \n",
        "institutions et entreprises utilisatrices de donn√©es\n",
        "\n",
        "\n",
        "Le principe d'un stockage cloud\n",
        "est le m√™me que celui d'une\n",
        "`Dropbox` ou d'un `Drive` mais adapt√© √†\n",
        "l'analyse de donn√©es. Un utilisateur de donn√©es\n",
        "acc√®de √† un fichier stock√© sur un serveur distant\n",
        "_comme s'il_ √©tait dans son _file system_ local[^4]. \n",
        "Donc, du point de vue de l'utilisateur `Python`, \n",
        "il n'y a pas de diff√©rence fondamentale. Cependant,\n",
        "les donn√©es ne sont pas heberg√©es dans un dossier\n",
        "local (par exemple `Mes Documents/monsuperfichier`)\n",
        "mais sur un serveur distant auquel l'utilisateur\n",
        "de `Python` acc√®de √† travers un √©change r√©seau.\n",
        "\n",
        "![](featured.png)\n",
        "\n",
        "Dans l'univers du _cloud_, la hi√©rarchisation des donn√©es\n",
        "dans des dossiers et des fichiers bien rang√©s \n",
        "est d'ailleurs moins\n",
        "importante que dans le monde du _file system_ local. \n",
        "Lorsque vous essayez de retrouver un fichier dans\n",
        "votre arborescence de fichiers, vous utilisez parfois\n",
        "la barre de recherche de votre explorateur de fichiers,\n",
        "avec des r√©sultats mitig√©s[^4]. Dans le monde du _cloud_,\n",
        "les fichiers sont parfois accumul√©s de mani√®re plus \n",
        "chaotique car les outils de recherche sont plus \n",
        "efficaces[^4]. \n",
        "\n",
        "[^4]: D'ailleurs, les g√©n√©rations n'ayant connu nativement\n",
        "que ce type de stockage ne sont pas familiaris√©es\n",
        "au concept de _file system_ et pr√©f√®rent \n",
        "payer le temps de recherche. Voir\n",
        "[cet article](https://futurism.com/the-byte/gen-z-kids-file-systems)\n",
        "sur le sujet. \n",
        "\n",
        "En ce qui concerne la s√©curit√© des donn√©es,\n",
        "la gestion des droits de lecture et √©criture peut √™tre\n",
        "fine: on peut autoriser certains utilisateurs uniquement \n",
        "√† la lecture, d'autres peuvent avoir les droits\n",
        "d'√©criture pour modifier les donn√©es. Cela permet\n",
        "de concilier les avantages des bases de donn√©es (la s√©curisation\n",
        "des donn√©es) avec ceux des fichiers. \n",
        "\n",
        "## Qu'est-ce que le syst√®me de stockage `S3` ?\n",
        "\n",
        "Dans les entreprises et administrations,\n",
        "un nombre croissant de donn√©es sont\n",
        "disponibles depuis un syst√®me de stockage\n",
        "nomm√© `S3`. \n",
        "Le syst√®me `S3` (*Simple Storage System*) est un syst√®me de stockage d√©velopp√©\n",
        "par Amazon et qui est maintenant devenu une r√©f√©rence pour le stockage en ligne.\n",
        "Il s'agit d'une architecture √† la fois\n",
        "s√©curis√©e (donn√©es crypt√©es, acc√®s restreints) et performante.\n",
        "\n",
        "Le concept central du syst√®me S3 est le __*bucket*__.\n",
        "Un *bucket* est un espace (priv√© ou partag√©) o√π on peut stocker une\n",
        "arborescence de fichiers. Pour acc√©der aux fichiers figurant\n",
        "dans un *bucket* priv√©, il faut des jetons d'acc√®s (l'√©quivalent d'un mot de passe)\n",
        "reconnus par le serveur de stockage. On peut alors lire et √©crire dans le *bucket*.\n",
        "\n",
        "\n",
        "::: {.cell .markdown}\n",
        "\n",
        "```{=html}\n",
        "<div class=\"alert alert-info\" role=\"alert\">\n",
        "<h3 class=\"alert-heading\"><i class=\"fa-solid fa-comment\"></i> Note</h3>\n",
        "```\n",
        "\n",
        "\n",
        "Les exemples suivants seront r√©plicables pour les utilisateurs de la plateforme\n",
        "SSP-cloud\n"
      ],
      "id": "3829f535"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| output: 'asis'\n",
        "#| include: true\n",
        "#| eval: true\n",
        "print_badges(\"content/course/NLP/05a_s3.qmd\", onyxia_only=True)"
      ],
      "id": "2520ce71",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ils peuvent √©galement l'√™tre pour des utilisateurs ayant un \n",
        "acc√®s √† AWS, il suffit de changer l'URL du `endpoint` \n",
        "pr√©sent√© ci-dessous. \n",
        "\n",
        "\n",
        "```{=html}\n",
        "</div>\n",
        "```\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "## Comment faire avec Python ?\n",
        "\n",
        "### Les librairies principales\n",
        "\n",
        "L'interaction entre ce syst√®me distant de fichiers et une session locale de Python\n",
        "est possible gr√¢ce √† des API. Les deux principales librairies sont les suivantes:\n",
        "\n",
        "* [boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html), une librairie cr√©√©e et maintenue par Amazon ;\n",
        "* [s3fs](https://s3fs.readthedocs.io/en/latest/), une librairie qui permet d'interagir avec les fichiers stock√©s √† l'instar d'un filesystem classique.\n",
        "\n",
        "La librairie `pyarrow` que nous avons d√©j√† pr√©sent√© permet √©galement\n",
        "de traiter des donn√©es stock√©es sur le _cloud_ comme si elles\n",
        "√©taient sur le serveur local. C'est extr√™mement pratique \n",
        "et permet de fiabiliser la lecture ou l'√©criture de fichiers\n",
        "dans une architecture _cloud_. \n",
        "Un exemple, assez court, est disponible \n",
        "[dans la documentation officielle](https://arrow.apache.org/docs/python/filesystems.html#s3)\n",
        "\n",
        "Il existe √©galement d'autres librairies permettant de g√©rer\n",
        "des _pipelines_ de donn√©es (chapitre √† venir) de mani√®re\n",
        "quasi indiff√©rente entre une architecture locale et une architecture\n",
        "_cloud_. Parmi celles-ci, nous pr√©senterons quelques exemples \n",
        "avec `snakemake`. \n",
        "En arri√®re-plan, `snakemake`\n",
        "va utiliser `boto3` pour communiquer avec le syst√®me\n",
        "de stockage.\n",
        "\n",
        "\n",
        "Enfin, selon le m√™me principe du _comme si_ les donn√©es\n",
        "√©taient en local, il existe l'outil en ligne de commande\n",
        "`mc` ([`Minio Client`](https://docs.min.io/docs/minio-client-complete-guide.html)) qui permet de g√©rer par des lignes\n",
        "de commande Linux les d√©p√¥ts distants comme s'ils √©taient\n",
        "locaux. \n",
        "\n",
        "Toutes ces librairies offrent la possibilit√© de se connecter depuis `Python`,\n",
        "√† un d√©p√¥t de fichiers distant, de lister les fichiers disponibles dans un\n",
        "*bucket*, d'en t√©l√©charger un ou plusieurs ou de faire de l'*upload*\n",
        "Nous allons pr√©senter quelques unes des op√©rations les plus fr√©quentes,\n",
        "en mode _cheatsheet_. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Connexion √† un bucket\n",
        "\n",
        "Par la suite, on va utiliser des alias pour les trois valeurs suivantes, qui servent\n",
        "√† s'authentifier. \n",
        "\n",
        "```python\n",
        "key_id = 'MY_KEY_ID'\n",
        "access_key = 'MY_ACCESS_KEY'\n",
        "token = \"MY_TOKEN\"\n",
        "```\n",
        "\n",
        "Ces valeurs peuvent √™tre √©galement disponibles dans \n",
        "les variables d'environnement de `Python`. Comme il s'agit d'une information\n",
        "d'authentification personnelle, il ne faut pas stocker les vraies valeurs de ces\n",
        "variables dans un projet, sous peine de partager des traits d'identit√© sans le\n",
        "vouloir lors d'un partage de code. \n",
        "\n",
        "::: {.cell .markdown}\n",
        "\n",
        "```{=html}\n",
        "<details><summary><code>boto3</code> üëá</summary>\n",
        "```\n",
        "\n",
        "\n",
        "Avec `boto3`, on cr√©√© d'abord un client puis on ex√©cute des requ√™tes dessus.\n",
        "Pour initialiser un client, il suffit, en supposant que l'url du d√©p√¥t S3 est\n",
        "`\"https://minio.lab.sspcloud.fr\"`, de faire:\n",
        "\n",
        "```python\n",
        "import boto3\n",
        "s3 = boto3.client(\"s3\",endpoint_url = \"https://minio.lab.sspcloud.fr\")\n",
        "```\n",
        "\n",
        "\n",
        "```{=html}\n",
        "</details>\n",
        "```\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "::: {.cell .markdown}\n",
        "\n",
        "```{=html}\n",
        "<details><summary><code>S3FS</code> üëá</summary>\n",
        "```\n",
        "\n",
        "\n",
        "La logique est identique avec `s3fs`. \n",
        "\n",
        "Si on a des jetons d'acc√®s √† jour et dans les variables d'environnement\n",
        "ad√©quates:\n",
        "\n",
        "```python\n",
        "import s3fs\n",
        "fs = s3fs.S3FileSystem(\n",
        "  client_kwargs={'endpoint_url': 'https://minio.lab.sspcloud.fr'})\n",
        "```\n",
        "\n",
        "\n",
        "```{=html}\n",
        "</details>\n",
        "```\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "::: {.cell .markdown}\n",
        "\n",
        "```{=html}\n",
        "<details><summary><code>Arrow</code> üëá</summary>\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "La logique d'`Arrow` est proche de celle de `s3fs`. Seuls les noms\n",
        "d'arguments changent\n",
        "\n",
        "Si on a des jetons d'acc√®s √† jour et dans les variables d'environnement\n",
        "ad√©quates:\n",
        "\n",
        "```python\n",
        "from pyarrow import fs\n",
        "s3 = fs.S3FileSystem(endpoint_override=\"http://\"+\"minio.lab.sspcloud.fr\")\n",
        "```\n",
        "\n",
        "\n",
        "```{=html}\n",
        "</details>\n",
        "```\n",
        "\n",
        ":::\n",
        "\n",
        "::: {.cell .markdown}\n",
        "\n",
        "```{=html}\n",
        "<details><summary><code>Snakemake</code> üëá</summary>\n",
        "```\n",
        "\n",
        "\n",
        "La logique de `Snakemake` est, quant √† elle,\n",
        "plus proche de celle de `boto3`. Seuls les noms\n",
        "d'arguments changent\n",
        "\n",
        "Si on a des jetons d'acc√®s √† jour et dans les variables d'environnement\n",
        "ad√©quates:\n",
        "\n",
        "```python\n",
        "from snakemake.remote.S3 import RemoteProvider as S3RemoteProvider\n",
        "S3 = S3RemoteProvider(host = \"https://\" + os.getenv('AWS_S3_ENDPOINT'))\n",
        "```\n",
        "\n",
        "\n",
        "```{=html}\n",
        "</details>\n",
        "```\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Il se peut que la connexion √† ce stade soit refus√©e (`HTTP error 403`).\n",
        "Cela peut provenir \n",
        "d'une erreur dans l'URL utilis√©. Cependant, cela refl√®te plus g√©n√©ralement\n",
        "des param√®tres d'authentification erron√©s.\n",
        "\n",
        "\n",
        "\n",
        "::: {.cell .markdown}\n",
        "\n",
        "```{=html}\n",
        "<details><summary><code>boto3</code> üëá</summary>\n",
        "```\n",
        "\n",
        "\n",
        "Les param√®tres d'authentification sont des arguments suppl√©mentaires:\n",
        "\n",
        "```python\n",
        "import boto3\n",
        "s3 = boto3.client(\"s3\",endpoint_url = \"https://minio.lab.sspcloud.fr\",\n",
        "                  aws_access_key_id=key_id, \n",
        "                  aws_secret_access_key=access_key, \n",
        "                  aws_session_token = token)\n",
        "```\n",
        "\n",
        "\n",
        "```{=html}\n",
        "</details>\n",
        "```\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "::: {.cell .markdown}\n",
        "\n",
        "```{=html}\n",
        "<details><summary><code>S3FS</code> üëá</summary>\n",
        "```\n",
        "\n",
        "\n",
        "La logique est la m√™me, seuls les noms d'arguments diff√®rent\n",
        "\n",
        "```python\n",
        "import s3fs\n",
        "fs = s3fs.S3FileSystem(\n",
        "  client_kwargs={'endpoint_url': 'https://'+'minio.lab.sspcloud.fr'},\n",
        "  key = key_id, secret = access_key,\n",
        "  token = token)\n",
        "```\n",
        "\n",
        "\n",
        "```{=html}\n",
        "</details>\n",
        "```\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "::: {.cell .markdown}\n",
        "\n",
        "```{=html}\n",
        "<details><summary><code>Arrow</code> üëá</summary>\n",
        "```\n",
        "\n",
        "\n",
        "Tout est en argument cette fois:\n",
        "\n",
        "```python\n",
        "from pyarrow import fs\n",
        "\n",
        "s3 = fs.S3FileSystem(\n",
        "    access_key = key_id,\n",
        "    secret_key = access_key,\n",
        "    session_token = token,\n",
        "    endpoint_override = 'https://'+'minio.lab.sspcloud.fr',\n",
        "    scheme = \"https\"\n",
        "    )\n",
        "```\n",
        "\n",
        "\n",
        "```{=html}\n",
        "</details>\n",
        "```\n",
        "\n",
        ":::\n",
        "\n",
        "::: {.cell .markdown}\n",
        "\n",
        "```{=html}\n",
        "<details><summary><code>Snakemake</code> üëá</summary>\n",
        "```\n",
        "\n",
        "\n",
        "La logique est la m√™me, seuls les noms d'arguments diff√®rent\n",
        "\n",
        "```python\n",
        "from snakemake.remote.S3 import RemoteProvider as S3RemoteProvider\n",
        "S3 = S3RemoteProvider(host = \"https://\" + os.getenv('AWS_S3_ENDPOINT'), access_key_id=key_id, secret_access_key=access_key)\n",
        "```\n",
        "\n",
        "\n",
        "```{=html}\n",
        "</details>\n",
        "```\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "::: {.cell .markdown}\n",
        "\n",
        "```{=html}\n",
        "<div class=\"alert alert-info\" role=\"alert\">\n",
        "<h3 class=\"alert-heading\"><i class=\"fa-solid fa-comment\"></i> Note</h3>\n",
        "```\n",
        "\n",
        "\n",
        "Dans le SSP-cloud, \n",
        "lorsque l'initialisation du service `Jupyter` du SSP-cloud est r√©cente\n",
        "(moins de 12 heures), il est possible d'utiliser\n",
        "automatiquement les jetons stock√©s automatiquement √† la cr√©ation du d√©p√¥t. \n",
        "\n",
        "Si on d√©sire acc√©der aux donn√©es du SSP-cloud depuis une session python du\n",
        "datalab (service VSCode, Jupyter...),\n",
        "il faut remplacer l'url par `http://minio.lab.sspcloud.fr`\n",
        "\n",
        "```{=html}\n",
        "</div>\n",
        "```\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "## Lister les fichiers\n",
        "\n",
        "S'il n'y a pas d'erreur √† ce stade, c'est que la connexion est bien effective.\n",
        "Pour le v√©rifier, on peut essayer de faire la liste des fichiers disponibles\n",
        "dans un `bucket` auquel on d√©sire acc√©der.\n",
        "\n",
        "Par exemple, on peut vouloir\n",
        "tester l'acc√®s aux bases `FILOSOFI` (donn√©es de revenu localis√©es disponibles\n",
        "sur <https://www.insee.fr>) au sein du bucket `donnees-insee`. \n",
        "\n",
        "\n",
        "\n",
        "::: {.cell .markdown}\n",
        "\n",
        "```{=html}\n",
        "<details><summary><code>boto3</code> üëá</summary>\n",
        "```\n",
        "\n",
        "\n",
        "Pour cela,\n",
        "la m√©thode `list_objects` offre toutes les options n√©cessaires:\n",
        "\n",
        "```python\n",
        "import boto3\n",
        "s3 = boto3.client(\"s3\",endpoint_url = \"https://minio.lab.sspcloud.fr\")\n",
        "for key in s3.list_objects(Bucket='donnees-insee', Prefix='diffusion/FILOSOFI')['Contents']:\n",
        "    print(key['Key'])\n",
        "```\n",
        "\n",
        "\n",
        "```{=html}\n",
        "</details>\n",
        "```\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "::: {.cell .markdown}\n",
        "\n",
        "```{=html}\n",
        "<details><summary><code>S3FS</code> üëá</summary>\n",
        "```\n",
        "\n",
        "\n",
        "Pour lister les fichiers, c'est la m√©thode `ls` (celle-ci ne liste pas par\n",
        "d√©faut les fichiers de mani√®re r√©cursive comme `boto3`):\n",
        "\n",
        "```python\n",
        "import s3fs\n",
        "fs = s3fs.S3FileSystem(\n",
        "  client_kwargs={'endpoint_url': 'https://minio.lab.sspcloud.fr'})\n",
        "fs.ls(\"donnees-insee/diffusion\")\n",
        "```\n",
        "\n",
        "\n",
        "```{=html}\n",
        "</details>\n",
        "```\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "::: {.cell .markdown}\n",
        "\n",
        "```{=html}\n",
        "<details><summary><code>Arrow</code> üëá</summary>\n",
        "```\n",
        "\n",
        "\n",
        "```python\n",
        "from pyarrow import fs\n",
        "s3 = fs.S3FileSystem(endpoint_override='https://'+'minio.lab.sspcloud.fr')\n",
        "s3.get_file_info(fs.FileSelector('donnees-insee/diffusion', recursive=True))\n",
        "```\n",
        "\n",
        "\n",
        "```{=html}\n",
        "</details>\n",
        "```\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "::: {.cell .markdown}\n",
        "\n",
        "```{=html}\n",
        "<details><summary><code>mc</code> üëá</summary>\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "```shell\n",
        "mc ls -r\n",
        "```\n",
        "\n",
        "\n",
        "```{=html}\n",
        "</details>\n",
        "```\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## T√©l√©charger un fichier depuis `S3` pour l'enregistrer en local\n",
        "\n",
        "Cette m√©thode n'est en g√©n√©ral pas recommand√©e car, comme on va le voir\n",
        "par la suite, il est possible de lire √† la vol√©e des fichiers. Cependant,\n",
        "t√©l√©charger un fichier depuis le _cloud_ pour l'√©crire sur le disque\n",
        "local peut parfois √™tre utile (par exemple, lorsqu'il est n√©cessaire\n",
        "de d√©zipper un fichier). \n",
        "\n",
        "\n",
        "::: {.cell .markdown}\n",
        "\n",
        "```{=html}\n",
        "<details><summary><code>boto3</code> üëá</summary>\n",
        "```\n",
        "\n",
        "\n",
        "On utilise cette fois la m√©thode `download_file`\n",
        "\n",
        "```python\n",
        "import boto3\n",
        "s3 = boto3.client(\"s3\",endpoint_url = \"https://minio.lab.sspcloud.fr\")\n",
        "s3.download_file('donnees-insee', \"diffusion/FILOSOFI/2014/FILOSOFI_COM.csv\", 'data.csv')\n",
        "```\n",
        "\n",
        "\n",
        "```{=html}\n",
        "</details>\n",
        "```\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "::: {.cell .markdown}\n",
        "\n",
        "```{=html}\n",
        "<details><summary><code>S3FS</code> üëá</summary>\n",
        "```\n",
        "\n",
        "\n",
        "```python\n",
        "import s3fs\n",
        "fs = s3fs.S3FileSystem(\n",
        "  client_kwargs={'endpoint_url': 'https://minio.lab.sspcloud.fr'})\n",
        "fs.download('donnees-insee/diffusion/FILOSOFI/2014/FILOSOFI_COM.csv','test.csv')\n",
        "```\n",
        "\n",
        "\n",
        "```{=html}\n",
        "</details>\n",
        "```\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "::: {.cell .markdown}\n",
        "\n",
        "```{=html}\n",
        "<details><summary><code>Snakemake</code> üëá</summary>\n",
        "```\n",
        "\n",
        "\n",
        "```python\n",
        "from snakemake.remote.S3 import RemoteProvider as S3RemoteProvider\n",
        "S3 = S3RemoteProvider(host = \"https://\" + os.getenv('AWS_S3_ENDPOINT'))\n",
        "bucket = \"mon-bucket\"\n",
        "\n",
        "rule ma_super_regle_s3:\n",
        "    input:\n",
        "        fichier = S3.remote(f'{bucket}/moninput.csv')\n",
        "    output:\n",
        "        fichier='mon_dossier_local/monoutput.csv'\n",
        "    run:\n",
        "        shell(\"cp {input[0]} {output[0]}\")\n",
        "```\n",
        "\n",
        "\n",
        "```{=html}\n",
        "</details>\n",
        "```\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "::: {.cell .markdown}\n",
        "\n",
        "```{=html}\n",
        "<details><summary><code>mc</code> üëá</summary>\n",
        "```\n",
        "\n",
        "\n",
        "```python\n",
        "mc cp \"donnees-insee/FILOSOFI/2014/FILOSOFI_COM.csv\" 'data.csv'\n",
        "```\n",
        "\n",
        "\n",
        "```{=html}\n",
        "</details>\n",
        "```\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Lire un fichier directement\n",
        "\n",
        "La m√©thode pr√©c√©dente n'est pas optimale. En effet, l'un des int√©r√™ts des API\n",
        "est qu'on peut traiter un fichier sur `S3` comme s'il s'agissait d'un fichier\n",
        "sur son PC. Cela est d'ailleurs une mani√®re plus s√©curis√©e de proc√©der puisqu'on\n",
        "lit les donn√©es √† la vol√©e, sans les √©crire dans un filesystem local. \n",
        "\n",
        "\n",
        "::: {.cell .markdown}\n",
        "\n",
        "```{=html}\n",
        "<details><summary><code>boto3</code> üëá</summary>\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "```python\n",
        "import boto3\n",
        "s3 = boto3.client(\"s3\",endpoint_url = \"https://minio.lab.sspcloud.fr\")\n",
        "obj = s3.get_object(Bucket='donnees-insee', Key=\"diffusion/FILOSOFI/2014/FILOSOFI_COM.csv\")\n",
        "df = pd.read_csv(obj['Body'], sep = \";\")\n",
        "df.head(2)\n",
        "```\n",
        "\n",
        "\n",
        "```{=html}\n",
        "</details>\n",
        "```\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "::: {.cell .markdown}\n",
        "\n",
        "```{=html}\n",
        "<details><summary><code>S3FS</code> üëá</summary>\n",
        "```\n",
        "\n",
        "\n",
        "Le code suivant devrait permettre d'effectuer la m√™me op√©ration avec `s3fs`\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "import s3fs\n",
        "fs = s3fs.S3FileSystem(\n",
        "  client_kwargs={'endpoint_url': 'https://minio.lab.sspcloud.fr'})\n",
        "df = pd.read_csv(fs.open('{}/{}'.format('donnees-insee', \"diffusion/FILOSOFI/2014/FILOSOFI_COM.csv\"),\n",
        "                         mode='rb'), sep = \";\"\n",
        "                 )\n",
        "\n",
        "df.head(2)\n",
        "```\n",
        "\n",
        "\n",
        "```{=html}\n",
        "</details>\n",
        "```\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "::: {.cell .markdown}\n",
        "\n",
        "```{=html}\n",
        "<details><summary><code>Snakemake</code> üëá</summary>\n",
        "```\n",
        "\n",
        "\n",
        "```python\n",
        "from snakemake.remote.S3 import RemoteProvider as S3RemoteProvider\n",
        "S3 = S3RemoteProvider(host = \"https://\" + os.getenv('AWS_S3_ENDPOINT'))\n",
        "bucket = \"mon-bucket\"\n",
        "\n",
        "rule ma_super_regle_s3:\n",
        "    input:\n",
        "        fichier = S3.remote(f'{bucket}/moninput.csv')\n",
        "    run:\n",
        "        import pandas as pd\n",
        "        df = pd.read_csv(input.fichier)\n",
        "        # PLUS D'OPERATIONS\n",
        "```\n",
        "\n",
        "\n",
        "```{=html}\n",
        "</details>\n",
        "```\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "::: {.cell .markdown}\n",
        "\n",
        "```{=html}\n",
        "<details><summary><code>Arrow</code> üëá</summary>\n",
        "```\n",
        "\n",
        "\n",
        "`Arrow` est une librairie qui permet de lire des `CSV`.\n",
        "Il est n√©anmoins\n",
        "beaucoup plus pratique d'utiliser le format `parquet` avec `arrow`. \n",
        "Dans un premier temps, on configure le _filesystem_ avec les \n",
        "fonctionalit√©s d'`Arrow` (cf. pr√©c√©demment). \n"
      ],
      "id": "cfa36283"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pyarrow import fs\n",
        "\n",
        "s3 = fs.S3FileSystem(endpoint_override='http://'+'minio.lab.sspcloud.fr')"
      ],
      "id": "317e6d52",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pour lire un csv, on fera:\n",
        "\n",
        "```python\n",
        "from pyarrow import fs\n",
        "from pyarrow import csv\n",
        "\n",
        "s3 = fs.S3FileSystem(endpoint_override='https://'+'minio.lab.sspcloud.fr')\n",
        "\n",
        "with s3.open_input_file(\"donnees-insee/diffusion/FILOSOFI/2014/FILOSOFI_COM.csv\") as file:\n",
        "    df = csv.read_csv(file, parse_options=csv.ParseOptions(delimiter=\";\")).to_pandas()\n",
        "```\n",
        "\n",
        "Pour un fichier au format parquet, la d√©marche est plus simple gr√¢ce √† l'argument\n",
        "`filesystem` dans `pyarrow.parquet.ParquetDataset` :\n",
        "\n",
        "```python\n",
        "import pyarrow.parquet as pq\n",
        "\n",
        "#bucket = \"\"\n",
        "#parquet_file=\"\"\n",
        "df = pq.ParquetDataset(f'{bucket}/{parquet_file}', filesystem=s3).read_pandas().to_pandas()\n",
        "```\n",
        "\n",
        "\n",
        "```{=html}\n",
        "</details>\n",
        "```\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Uploader un fichier\n",
        "\n",
        "::: {.cell .markdown}\n",
        "\n",
        "```{=html}\n",
        "<details><summary><code>boto3</code> üëá</summary>\n",
        "```\n",
        "\n",
        "\n",
        "```python\n",
        "s3.upload_file(file_name, bucket, object_name)\n",
        "```\n",
        "\n",
        "\n",
        "```{=html}\n",
        "</details>\n",
        "```\n",
        "\n",
        ":::\n",
        "\n",
        "::: {.cell .markdown}\n",
        "\n",
        "```{=html}\n",
        "<details><summary><code>S3FS</code> üëá</summary>\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "```python\n",
        "fs.put(filepath, f\"{bucket}/{object_name}\", recursive=True)\n",
        "```\n",
        "\n",
        "\n",
        "```{=html}\n",
        "</details>\n",
        "```\n",
        "\n",
        ":::\n",
        "\n",
        "::: {.cell .markdown}\n",
        "\n",
        "```{=html}\n",
        "<details><summary><code>Arrow</code> üëá</summary>\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "Supposons que `df` soit un `pd.DataFrame` \n",
        "Dans un syst√®me local, on convertirait\n",
        "en table `Arrow` puis on √©crirait en `parquet`\n",
        "([voir la documentation officielle](https://arrow.apache.org/docs/python/parquet.html#reading-and-writing-single-files)).\n",
        "Quand on est sur un syst√®me `S3`, il s'agit seulement d'ajouter\n",
        "notre connexion √† `S3` dans l'argument `filesystem`\n",
        "([voir la page sur ce sujet dans la documentation Arrow](https://arrow.apache.org/docs/python/filesystems.html#filesystem-s3))\n",
        "\n",
        "```python\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "\n",
        "table = pa.Table.from_pandas(df)\n",
        "pq.write_table(table, f\"{bucket}/{path}\", filesystem=s3)\n",
        "```\n",
        "\n",
        "\n",
        "```{=html}\n",
        "</details>\n",
        "```\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "::: {.cell .markdown}\n",
        "\n",
        "```{=html}\n",
        "<details><summary><code>Snakemake</code> üëá</summary>\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "```python\n",
        "from snakemake.remote.S3 import RemoteProvider as S3RemoteProvider\n",
        "S3 = S3RemoteProvider(host = \"https://\" + os.getenv('AWS_S3_ENDPOINT'))\n",
        "bucket = \"mon-bucket\"\n",
        "\n",
        "rule ma_super_regle_s3:\n",
        "    input:\n",
        "        fichier='mon_dossier_local/moninput.csv'\n",
        "    output:\n",
        "        fichier=S3.remote(f'{bucket}/monoutput.csv')\n",
        "    run:\n",
        "        shell(\"cp output.fichier input.fichier\")\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "```{=html}\n",
        "</details>\n",
        "```\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "::: {.cell .markdown}\n",
        "\n",
        "```{=html}\n",
        "<details><summary><code>mc</code> üëá</summary>\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "```python\n",
        "mc cp 'data.csv' \"MONBUCKET/monoutput.csv\"\n",
        "```\n",
        "\n",
        "\n",
        "```{=html}\n",
        "</details>\n",
        "```\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Pour aller plus loin\n",
        "\n",
        "- [La documentation sur MinIO du SSPCloud](https://docs.sspcloud.fr/onyxia-guide/stockage-de-donnees)"
      ],
      "id": "1af69d0f"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}