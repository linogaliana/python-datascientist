{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1737ba63",
   "metadata": {},
   "source": [
    "#  Clustering\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079ed838",
   "metadata": {},
   "source": [
    "<a href=\"https://github.com/linogaliana/python-datascientist/blob/master//__w/python-datascientist/python-datascientist/notebooks/course/modelisation/5_clustering.ipynb\" class=\"github\"><i class=\"fab fa-github\"></i></a>\n",
    "[![Download](https://img.shields.io/badge/Download-Notebook-important?logo=Jupyter)](https://downgit.github.io/#/home?url=https://github.com/linogaliana/python-datascientist/blob/master//__w/python-datascientist/python-datascientist/notebooks/course/modelisation/5_clustering.ipynb)\n",
    "[![nbviewer](https://img.shields.io/badge/Visualize-nbviewer-blue?logo=Jupyter)](https://nbviewer.jupyter.org/github/linogaliana/python-datascientist/blob/master//__w/python-datascientist/python-datascientist/notebooks/course/modelisation/5_clustering.ipynb)\n",
    "[![Onyxia](https://img.shields.io/badge/SSPcloud-Tester%20via%20SSP--cloud-informational&color=yellow?logo=Python)](https://datalab.sspcloud.fr/launcher/inseefrlab-helm-charts-datascience/jupyter?autoLaunch=true&onyxia.friendlyName=%C2%ABpython-datascience%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%ABmodelisation%205_clustering%C2%BB&security.allowlist.enabled=false)\n",
    "<br>\n",
    "[![Binder](https://img.shields.io/badge/Launch-Binder-E66581.svg?logo=data:image/png;base64,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)](https://mybinder.org/v2/gh/linogaliana/python-datascientist/master?filepath=/__w/python-datascientist/python-datascientist/notebooks/course/modelisation/5_clustering.ipynb)\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/github/linogaliana/python-datascientist/blob/master//__w/python-datascientist/python-datascientist/notebooks/course/modelisation/5_clustering.ipynb)\n",
    "[![githubdev](https://open.vscode.dev/badges/open-in-vscode.svg)](https://github.dev/linogaliana/python-datascientist//__w/python-datascientist/python-datascientist/notebooks/course/modelisation/5_clustering.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5a02d7",
   "metadata": {},
   "source": [
    "Nous allons continuer avec le jeu de données de [résultat des élections US 2020 au niveau des comtés](#preprocessing)\n",
    "\n",
    "Jusqu'à présent, nous avons fait de l'apprentissage supervisé puisque nous\n",
    "connaissions la vraie valeur de la variable à expliquer/prédire (`y`). Ce n'est plus le cas avec\n",
    "l'apprentissage non supervisé.\n",
    "\n",
    "Le *clustering* est un champ d'application de l'apprentissage non-supervisé.\n",
    "Il s'agit d'exploiter l'information disponible pour regrouper des observations\n",
    "qui se ressemblent.\n",
    "\n",
    "L'objectif est de créer des clusters d'observations pour lesquels :\n",
    "\n",
    "* au sein de chaque cluster, les observations sont homogènes (variance intra-cluster minimale)\n",
    "* les clusters ont des profils hétérogènes, c'est-à-dire qu'ils se distinguent les uns des autres (variance inter-cluster maximale)\n",
    "\n",
    "En *Machine Learning*, les méthodes de clustering sont très utilisées pour\n",
    "faire de la recommandation. En faisant, par exemple, des classes homogènes de\n",
    "consommateurs, il est plus facile d'identifier et cibler des comportements\n",
    "propres à chaque classe de consommateurs.\n",
    "\n",
    "Ces méthodes ont également un intérêt en économie et sciences sociales parce qu'elles permettent\n",
    "de regrouper des observations sans *a priori* et ainsi interpréter une variable\n",
    "d'intérêt à l'aune de ces résultats. Cette [publication sur la ségrégation spatiale utilisant des données de téléphonie mobile](https://www.insee.fr/fr/statistiques/4925200)\n",
    "utilise par exemple cette approche.\n",
    "\n",
    "Les méthodes de *clustering* peuvent aussi intervenir en amont d'un problème de classification (dans des\n",
    "problèmes d'apprentissage semi-supervisé).\n",
    "Le manuel *Hands-on machine learning with scikit-learn, Keras et TensorFlow* présente dans le\n",
    "chapitre dédié à l'apprentissage non supervisé quelques exemples.\n",
    "\n",
    "Dans certaines bases de données, on peut se retrouver avec quelques exemples labellisés mais la plupart sont\n",
    "non labellisés. Les labels ont par exemple été faits manuellement par des experts.\n",
    "\n",
    "Par exemple, supposons que dans la [base MNIST des chiffres manuscrits](https://fr.wikipedia.org/wiki/Base_de_donn%C3%A9es_MNIST), les chiffres ne soient pas labellisés\n",
    "et que l'on se demande quelle est la meilleure stratégie pour labelliser cette base.\n",
    "On pourrait regarder des images de chiffres manuscrits au hasard de la base et les labelliser.\n",
    "Les auteurs du livre montrent qu'il existe toutefois une meilleure stratégie.\n",
    "Il vaut mieux appliquer un algorithme de clustering en amont pour regrouper les images ensemble et avoir une\n",
    "image représentative par groupe, et labelliser ces images représentatives au lieu de labelliser au hasard."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c6a01c",
   "metadata": {},
   "source": [
    "Les méthodes de *clustering* sont nombreuses.\n",
    "Nous allons nous pencher sur la plus intuitive : les *k-means*.\n",
    "\n",
    "# Données\n",
    "\n",
    "Comme précédemment, le code de chargement des données \n",
    "est disponible [sur Github](https://github.com/linogaliana/python-datascientist/blob/master/content/course/modelisation/get_data.py).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183d3d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install geopandas\n",
    "\n",
    "import requests\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/linogaliana/python-datascientist/master/content/course/modelisation/get_data.py'\n",
    "r = requests.get(url, allow_redirects=True)\n",
    "open('getdata.py', 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c20612",
   "metadata": {},
   "source": [
    "```\n",
    "## 3585\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49370a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getdata\n",
    "votes = getdata.create_votes_dataframes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf32f114",
   "metadata": {},
   "source": [
    "```\n",
    "## Error in py_call_impl(callable, dots$args, dots$keywords): AttributeError: module 'getdata' has no attribute 'create_votes_dataframes'\n",
    "## \n",
    "## Detailed traceback: \n",
    "##   File \"<string>\", line 1, in <module>\n",
    "```\n",
    "\n",
    "## Principe\n",
    "\n",
    "L'objectif des *k-means* est de partitioner l'espace des observations en trouvant des points (*centroids*) jouant le rôle de centres de gravité pour lesquels les observations proches peuvent être regroupées dans une classe homogène.\n",
    "L'algorithme *k-means* fonctionne par itération, en initialisant les centroïdes puis en les mettant à jour à chaque\n",
    "itération, jusqu'à ce que les centroïdes se stabilisent. Quelques exemples de *clusters* issus de la méthode *k-means* : \n",
    "\n",
    "![](https://scikit-learn.org/stable/_images/sphx_glr_plot_kmeans_assumptions_001.png)\n",
    "\n",
    "L'objectif des *k-means* est de trouver une partition des données $S=\\{S_1,...,S_K\\}$ telle que\n",
    "$$\n",
    "\\arg\\min_{S} \\sum_{i=1}^K \\sum_{x \\in S_i} ||x - \\mu_i||^2\n",
    "$$\n",
    "avec $\\mu_i$ la moyenne des $x_i$ dans l'ensemble de points $S_i$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7250d521",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bcaccb",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972af713",
   "metadata": {},
   "source": [
    "**Exercice 1 : Principe des k-means**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb56ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages utiles\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from sklearn.cluster import KMeans #pour kmeans\n",
    "import seaborn as sns #pour scatterplots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aec7ccf",
   "metadata": {},
   "source": [
    "1. Importer les données et se restreindre aux variables `'Unemployment_rate_2019', 'Median_Household_Income_2019', 'Percent of adults with less than a high school diploma, 2015-19', \"Percent of adults with a bachelor's degree or higher, 2015-19\"` et bien-sûr  `'per_gop'`. Appelez cette base restreinte `df2` et enlevez les valeurs manquantes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e335386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Chargement de la base restreinte.\n",
    "xvars = ['Unemployment_rate_2019', 'Median_Household_Income_2019', 'Percent of adults with less than a high school diploma, 2015-19', \"Percent of adults with a bachelor's degree or higher, 2015-19\"]\n",
    "\n",
    "df2 = votes[xvars + [\"per_gop\"]].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e7ddcc",
   "metadata": {},
   "source": [
    "```\n",
    "## Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name 'votes' is not defined\n",
    "## \n",
    "## Detailed traceback: \n",
    "##   File \"<string>\", line 1, in <module>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68510a0b",
   "metadata": {},
   "source": [
    "2. Faire un *k-means* avec $k=4$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3be160",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. kmeans avec k=4\n",
    "model = KMeans(n_clusters=4)\n",
    "model.fit(df2[xvars])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c11adb5",
   "metadata": {},
   "source": [
    "```\n",
    "## Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name 'df2' is not defined\n",
    "## \n",
    "## Detailed traceback: \n",
    "##   File \"<string>\", line 1, in <module>\n",
    "```\n",
    "\n",
    "3. Créer une variable `label` dans `votes` stockant le résultat de la typologie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0bcba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Création de la variable label dans votes\n",
    "votes['label'] = model.labels_\n",
    "#votes['label'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a848b143",
   "metadata": {},
   "source": [
    "```\n",
    "## Error in py_call_impl(callable, dots$args, dots$keywords): AttributeError: 'KMeans' object has no attribute 'labels_'\n",
    "## \n",
    "## Detailed traceback: \n",
    "##   File \"<string>\", line 1, in <module>\n",
    "```\n",
    "\n",
    "4. Afficher cette typologie sur une carte.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7ecf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Carte de la typologie\n",
    "p = votes.plot(column = \"label\", cmap = \"inferno\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afa79e4",
   "metadata": {},
   "source": [
    "```\n",
    "## Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name 'votes' is not defined\n",
    "## \n",
    "## Detailed traceback: \n",
    "##   File \"<string>\", line 1, in <module>\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce54e9c",
   "metadata": {},
   "source": [
    "```r\n",
    "knitr::include_graphics(\"typo_map.png\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1fe330",
   "metadata": {},
   "source": [
    "5. Choisir les variables `Median_Household_Incomme_2019` et `Unemployment_rate_2019` et représenter le nuage de points en colorant différemment\n",
    "en fonction du label obtenu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bc0b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Nuage de points de 2 variables et coloration selon le label\n",
    "plt.figure()\n",
    "p = sns.scatterplot(data=votes, x=\"Median_Household_Income_2019\", y=\"Unemployment_rate_2019\", hue = \"label\", palette=\"deep\", alpha = 0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffea1f1",
   "metadata": {},
   "source": [
    "```\n",
    "## Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name 'votes' is not defined\n",
    "## \n",
    "## Detailed traceback: \n",
    "##   File \"<string>\", line 1, in <module>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b80089d",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.set(xscale=\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7bc12f",
   "metadata": {},
   "source": [
    "```\n",
    "## [None]\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0193187",
   "metadata": {},
   "source": [
    "```r\n",
    "knitr::include_graphics(\"scatter.png\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a6d2bd",
   "metadata": {},
   "source": [
    "6. Représenter la distribution du vote pour chaque *cluster*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86241eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Distribution du vote selon chaque cluster\n",
    "plt.figure()\n",
    "p2 = sns.displot(data=votes, x=\"per_gop\", hue=\"label\", alpha = 0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9446de41",
   "metadata": {},
   "source": [
    "```\n",
    "## Error in py_call_impl(callable, dots$args, dots$keywords): NameError: name 'votes' is not defined\n",
    "## \n",
    "## Detailed traceback: \n",
    "##   File \"<string>\", line 1, in <module>\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af17ab76",
   "metadata": {},
   "source": [
    "```r\n",
    "knitr::include_graphics(\"displot.png\")\n",
    "```\n",
    "\n",
    "```\n",
    "## Error in knitr::include_graphics(\"displot.png\"): Cannot find the file(s): \"displot.png\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69c8188",
   "metadata": {},
   "source": [
    "Il faut noter plusieurs points sur l'algorithme implémenté par défaut par scikit learn, que l'on peut lire dans\n",
    "la documentation :\n",
    "- l'algorithme implémenté par défaut est kmeans ++ (cf. paramètre `init`). Cela signifie que\n",
    "l'initialisation des centroïdes est faite de manière intelligente pour que les centroïdes initiaux soient choisis\n",
    "afin de ne pas être trop proches.\n",
    "- l'algorithme va être démarré avec `n_init` centroïdes différents et le modèle va choisir la meilleure initialisation\n",
    "en fonction de l'**inertia** du modèle, par défaut égale à 10.\n",
    "\n",
    "Le modèle renvoie les `cluster_centers_`, les labels `labels_`, l'inertia `inertia_` et le nombre d'itérations\n",
    "`n_iter_`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44190cc8",
   "metadata": {},
   "source": [
    "## Choisir le nombre de clusters\n",
    "\n",
    "Le nombre de clusters est fixé par le modélisateur.\n",
    "Il existe plusieurs façons de fixer ce nombre :\n",
    "\n",
    "* connaissance a priori du problème ;\n",
    "* analyse d'une métrique spécifique pour définir le nombre de clusters à choisir ;\n",
    "* etc.\n",
    "\n",
    "Il y a un arbitrage à faire\n",
    "entre biais et variance :\n",
    "un trop grand nombre de clusters implique une variance\n",
    "intra-cluster très faible (sur-apprentissage, même s'il n'est jamais possible de déterminer\n",
    "le vrai type d'une observation puisqu'on est en apprentissage non supervisé).\n",
    "\n",
    "Sans connaissance a priori du nombre de clusters, on peut recourir à deux familles de méthodes :\n",
    "\n",
    "* **La méthode du coude** (*elbow method*): On prend le point d'inflexion de la courbe\n",
    "de performance du modèle. Cela représente le moment où ajouter un cluster\n",
    "(complexité croissante du modèle) n'apporte que des gains modérés dans la\n",
    "modélisation des données.\n",
    "\n",
    "* **Le score de silhouette** : On mesure la similarité entre un point et les autres points\n",
    "du cluster par rapport aux autres clusters. Plus spécifiquement :\n",
    "\n",
    "> Silhouette value is a measure of how similar an object is to its own cluster\n",
    "> (cohesion) compared to other clusters (separation). The silhouette ranges\n",
    "> from −1 to +1, where a high value indicates that the object is\n",
    "> well matched to its own cluster and poorly matched to neighboring\n",
    "> clusters. If most objects have a high value, then the clustering\n",
    "> configuration is appropriate. If many points have a low or negative\n",
    "> value, then the clustering configuration may have too many or too few clusters\n",
    ">\n",
    "> Source: [Wikipedia](https://en.wikipedia.org/wiki/Silhouette_(clustering))\n",
    "\n",
    "Le score de silhouette d'une observation est donc égal à\n",
    "`(m_nearest_cluster - m_intra_cluster)/max( m_nearest_cluster,m_intra_cluster)`\n",
    "où `m_intra_cluster` est la moyenne des distances de l'observation aux observations du même cluster\n",
    "et `m_nearest_cluster` est la moyenne des distances de l'observation aux observations du cluster le plus proche."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26341439",
   "metadata": {},
   "source": [
    "Le package `yellowbrick` fournit une extension utile à `scikit` pour représenter\n",
    "facilement la performance en *clustering*.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d959d2d",
   "metadata": {},
   "source": [
    "```r\n",
    "knitr::include_graphics(\"elbow-yellowbrick.png\")\n",
    "```\n",
    "\n",
    "```\n",
    "## Error in knitr::include_graphics(\"elbow-yellowbrick.png\"): Cannot find the file(s): \"elbow-yellowbrick.png\"\n",
    "```\n",
    "\n",
    "Pour la méthode du coude, la courbe\n",
    "de performance du modèle marque un coude léger à $k=4$. Le modèle initial\n",
    "semblait donc approprié.\n",
    "\n",
    "`yellowbrick` permet également de représenter des silhouettes mais\n",
    "l'interprétation est moins aisée et le coût computationnel plus élevé :\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7037e65e",
   "metadata": {},
   "source": [
    "```r\n",
    "knitr::include_graphics(\"silhouette-yellowbrick.png\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa4c5db",
   "metadata": {},
   "source": [
    "Le score de silhouette offre une représentation plus riche que la courbe coudée.\n",
    "\n",
    "Sur ce graphique, les barres verticales en rouge et en pointillé représentent le score de silhouette\n",
    "global pour chaque `k` choisi. On voit par exemple que pour tous les `k` représentés ici, le\n",
    "score de silhouette se situe entre 0.5 et 0.6 et varie peu.\n",
    "Ensuite, pour un `k` donné, on va avoir la représentation des scores de silhouette de chaque\n",
    "observation, regroupées par cluster.\n",
    "Par exemple, pour `k = 4`, ici, on voit bien quatre couleurs différentes qui sont les 4 clusters modélisés.\n",
    "Les ordonnées sont toutes les observations clusterisées et en abscisses on a le score de silhouette de\n",
    "chaque observation. Si au sein d'un cluster, les observations ont un score de silhouette plus faible que le\n",
    "score de silhouette global (ligne verticale en rouge), cela signifie que les observations du clusters sont\n",
    "trop proches des autres clusters.\n",
    "\n",
    "Grâce à cette représentation, on peut aussi se rendre compte de la taille relative des clusters. Par exemple,\n",
    "avec `k = 3`, on voit qu'on a deux clusters conséquents et un plus \"petit\" cluster relativement aux deux autres.\n",
    "Cela peut nous permettre de choisir des clusters de tailles homogènes ou non.\n",
    "\n",
    "Enfin, quand le score de silhouette est négatif, cela signifie que la moyenne des distances de l'observation\n",
    "aux observations du cluster le plus proche est inférieure à la moyenne des distances de l'observation aux\n",
    "observations de son cluster. Cela signifie que l'observation est mal classée.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93143ea6",
   "metadata": {},
   "source": [
    "## Autres méthodes de clustering\n",
    "\n",
    "Il existe de nombreuses autres méthodes de clustering. Parmi les plus connues, on peut citer deux exemples en particulier :\n",
    "\n",
    "- DBSCAN\n",
    "- les mélanges de Gaussiennes\n",
    "\n",
    "### DBSCAN\n",
    "\n",
    "L'algorithme DBSCAN est implémenté dans `sklearn.cluster`. Il peut être utilisé pour faire de la détection d'anomalies\n",
    "notamment.\n",
    "En effet, cette méthode repose sur le clustering en régions où la densité\n",
    "des observations est continue, grâce à la notion de voisinage selon une certaine distance epsilon.\n",
    "Pour chaque observation, on va regarder si dans son voisinage selon une distance epsilon, il y a des voisins. S'il y a au\n",
    "moins `min_samples` voisins, alors l'observation sera une *core instance*.\n",
    "\n",
    "Les observations qui ne sont pas des *core instances* et qui n'en ont pas dans leur voisinage selon une distance espilon\n",
    "vont être détectées comme des anomalies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc42daa",
   "metadata": {},
   "source": [
    "### Les mélanges de gaussiennes\n",
    "\n",
    "En ce qui concerne la théorie, voir le cours [Probabilités numériques et statistiques computationnelles, M1 Jussieu, V.Lemaire et T.Rebafka](http://www.proba.jussieu.fr/pageperso/rebafka/#enseignement)\n",
    "Se référer notamment aux notebooks pour l'algorithme EM pour mélange gaussien.\n",
    "\n",
    "Dans `sklearn`, les mélanges gaussiens sont implémentés dans `sklearn.mixture` comme `GaussianMixture`.\n",
    "Les paramètres importants sont alors le nombre de gaussiennes `n_components` et le nombre d'initiatisations `n_init`.\n",
    "Il est possible de faire de la détection d'anomalie savec les mélanges de gaussiennes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e7cfa7",
   "metadata": {},
   "source": [
    "Il existe de nombreuses autres méthodes de clustering :\n",
    "\n",
    "- Local outlier factor ;\n",
    "- bayesian gaussian mixture models ;\n",
    "- différentes méthodes de clustering hiérarchique ;\n",
    "- etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
