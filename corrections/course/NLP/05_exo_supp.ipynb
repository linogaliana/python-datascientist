{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0c0b222",
   "metadata": {},
   "source": [
    "#  Exercices supplémentaires\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9c58e2",
   "metadata": {},
   "source": [
    "<a href=\"https://github.com/linogaliana/python-datascientist/blob/master//__w/python-datascientist/python-datascientist/notebooks/course/NLP/05_exo_supp.ipynb\" class=\"github\"><i class=\"fab fa-github\"></i></a>\n",
    "[![Download](https://img.shields.io/badge/Download-Notebook-important?logo=Jupyter)](https://downgit.github.io/#/home?url=https://github.com/linogaliana/python-datascientist/blob/master//__w/python-datascientist/python-datascientist/notebooks/course/NLP/05_exo_supp.ipynb)\n",
    "[![nbviewer](https://img.shields.io/badge/Visualize-nbviewer-blue?logo=Jupyter)](https://nbviewer.jupyter.org/github/linogaliana/python-datascientist/blob/master//__w/python-datascientist/python-datascientist/notebooks/course/NLP/05_exo_supp.ipynb)\n",
    "[![Onyxia](https://img.shields.io/badge/SSPcloud-Tester%20via%20SSP--cloud-informational&color=yellow?logo=Python)](https://datalab.sspcloud.fr/launcher/inseefrlab-helm-charts-datascience/jupyter?autoLaunch=true&onyxia.friendlyName=%C2%ABpython-datascience%C2%BB&init.personalInit=%C2%ABhttps%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmaster%2Fsspcloud%2Finit-jupyter.sh%C2%BB&init.personalInitArgs=%C2%ABNLP%2005_exo_supp%C2%BB&security.allowlist.enabled=false)\n",
    "<br>\n",
    "[![Binder](https://img.shields.io/badge/Launch-Binder-E66581.svg?logo=data:image/png;base64,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)](https://mybinder.org/v2/gh/linogaliana/python-datascientist/master?filepath=/__w/python-datascientist/python-datascientist/notebooks/course/NLP/05_exo_supp.ipynb)\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/github/linogaliana/python-datascientist/blob/master//__w/python-datascientist/python-datascientist/notebooks/course/NLP/05_exo_supp.ipynb)\n",
    "[![githubdev](https://open.vscode.dev/badges/open-in-vscode.svg)](https://github.dev/linogaliana/python-datascientist//__w/python-datascientist/python-datascientist/notebooks/course/NLP/05_exo_supp.ipynb)\n",
    "\n",
    "Cette page approfondit certains aspects présentés dans les autres tutoriels. Il s'agit d'une suite d'exercice, avec corrections, pour présenter d'autres aspects du NLP ou pratiquer sur des données différentes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3eca6e",
   "metadata": {},
   "source": [
    "# Exploration des libellés de l'openfood database\n",
    "\n",
    "L'objectif de cet exercice est d'analyser les termes les plus fréquents\n",
    "dans les noms de produits de l'openfood database. Au passage, cela permet de réviser les étapes de *preprocessing* (LIEN XXXXX) et d'explorer les enjeux de reconnaissance d'entités nommées. \n",
    "\n",
    "Dans cet exercice:\n",
    "\n",
    "* tokenisation (`nltk`)\n",
    "* retrait des stop words (`nltk`)\n",
    "* nuage de mots (`wordcloud`)\n",
    "* reconnaissance du langage (`fasttext`)\n",
    "* reconnaissance d'entités nommées (`spacy`)\n",
    "\n",
    "le tout sur l'OpenFood Database, une base de données alimentaire qui est enrichie de manière collaborative. \n",
    "\n",
    "Pour pouvoir utiliser les modèles pré-entraînés de `spaCy`, il faut les télécharger. La méthode préconisée est d'utiliser, depuis un terminal, la commande suivante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f344d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "python -m spacy download fr_core_news_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197088fc",
   "metadata": {},
   "source": [
    "Dans un notebook jupyter, il se peut qu'il soit nécessaire de relancer le kernel.\n",
    "\n",
    "Si l'accès à la ligne de commande n'est pas possible, ou si la commande échoue, il est possible de télécharger le modèle pré-entraîné directement depuis une session `Python`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67626bd",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "spacy.cli.download('fr_core_news_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594c1897",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9626f341",
   "metadata": {},
   "source": [
    "1. Importer le modèle de reconnaissance de langage qui sera utilisé par la suite\n",
    "ainsi que le corpus Français utilisé par `spacy`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f207dc77",
   "metadata": {},
   "source": [
    "2. Importer les données de l'[openfood database](https://fr.openfoodfacts.org/data) à partir du code suivant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639bd9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "urllib.request.urlretrieve('https://static.openfoodfacts.org/data/en.openfoodfacts.org.products.csv', \"%s.openfood.csv\" % temp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67b7d99",
   "metadata": {},
   "source": [
    "```\n",
    "## ('/tmp/tmp2bkp6se9.openfood.csv', <http.client.HTTPMessage object at 0x7feb4c58fa30>)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e938fd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_openfood = pd.read_csv(\"%s.openfood.csv\" % temp_dir, delimiter=\"\\t\",\n",
    "                          usecols=['product_name'], encoding = 'utf-8', dtype = \"str\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3598dad9",
   "metadata": {},
   "source": [
    "Ces données devraient avoir l'aspect suivant:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609ef82a",
   "metadata": {},
   "source": [
    "```\n",
    "##      product_name\n",
    "## 0  jeunes pousses\n",
    "## 1         L.casei\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd4a56d",
   "metadata": {},
   "source": [
    "3. Créer une fonction de nettoyage des noms de produits effectuant les \n",
    "étapes suivantes:\n",
    "\n",
    "* tokeniser le texte en question\n",
    "* retirer la ponctuation et les _stopwords_\n",
    "\n",
    "Appliquer cette fonction à l'ensemble des noms de produits (variable\n",
    "`product_name`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50afb27a",
   "metadata": {},
   "source": [
    "4. Effectuer un nuage de mot sur les libellés avant et après nettoyage\n",
    "pour comprendre la structure du corpus en question.\n",
    "Le résultat devrait avoir l'apparence suivante\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2586552a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import wordcloud as wc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def graph_wordcloud(data, by = None, valueby = None, yvar = \"Text\"):\n",
    "    if (by is not None) & (valueby is not None):        \n",
    "        txt = data[data[by]==valueby][yvar].astype(str)\n",
    "    else:\n",
    "        txt = data[yvar].astype(str)\n",
    "    all_text = ' '.join([text for text in txt])\n",
    "    wordcloud = wc.WordCloud(width=800, height=500,\n",
    "                          random_state=21,\n",
    "                      max_words=2000).generate(all_text)\n",
    "    return wordcloud\n",
    "\n",
    "def graph_wordcloud_by(data, by, yvar = \"Text\"):\n",
    "    n_topics = data[by].unique().tolist()\n",
    "    width=20\n",
    "    height=80\n",
    "    rows = len(n_topics)//2\n",
    "    cols = 2\n",
    "    fig=plt.figure(figsize=(width, height))\n",
    "    axes = []\n",
    "    for i in range(cols*rows):\n",
    "        b = graph_wordcloud(data, by = by, valueby = n_topics[i], yvar = yvar)\n",
    "        axes.append( fig.add_subplot(rows, cols, i+1) )\n",
    "        axes[-1].set_title(\"{}\".format(n_topics[i]))  \n",
    "        plt.imshow(b)\n",
    "        plt.axis('off')\n",
    "        plt.savefig('{}.png'.format(yvar), bbox_inches='tight')\n",
    "\n",
    "\n",
    "def wordcount_words(data, yvar, by = None):\n",
    "    plt.figure( figsize=(15,15) )\n",
    "    if by is None:\n",
    "        wordcloud = graph_wordcloud(data, yvar = yvar, by = by)\n",
    "        plt.imshow(wordcloud)\n",
    "        plt.axis('off')\n",
    "        plt.savefig('{}.png'.format(yvar), bbox_inches='tight')\n",
    "    else:\n",
    "        graph_wordcloud_by(data, by = by, yvar = yvar)\n",
    "\n",
    "wordcount_words(df_openfood, yvar = \"product_name\")\n",
    "wordcount_words(df_openfood, \"tokenized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebe3d5d",
   "metadata": {},
   "source": [
    "```r\n",
    "knitr::include_graphics(\"product_name.png\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d617775",
   "metadata": {},
   "source": [
    "```r\n",
    "knitr::include_graphics(\"tokenized.png\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb08ab66",
   "metadata": {},
   "source": [
    "5. Utiliser la librairie `fasttext` pour extraire les noms de produits\n",
    "français\n",
    "\n",
    "* Appliquer le modèle téléchargé précedemment pour déterminer le langage\n",
    "* Ne récupérer que les libellés français\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c77056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "\n",
    "PRETRAINED_MODEL_PATH = \"%s.model.bin\" % temp_dir\n",
    "model = fasttext.load_model(PRETRAINED_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c86465",
   "metadata": {},
   "source": [
    "```\n",
    "## Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8162e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "newcols = ['language','score_language']\n",
    "df_openfood[newcols] = pd.DataFrame(df_openfood['product_name'].astype(str).apply(lambda s: list(model.predict(s))).apply(lambda l: [l[0][0],l[1][0]]).tolist(), columns = newcols)\n",
    "df_openfood['language'] = df_openfood['language'].str.replace(\"__label__\",\"\")\n",
    "df_openfood_french = df_openfood[df_openfood['language'] == \"fr\"]\n",
    "df_openfood_french.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6bb9c9",
   "metadata": {},
   "source": [
    "```\n",
    "##                    product_name             tokenized language  score_language\n",
    "## 0                jeunes pousses        jeunes pousses       fr        0.971347\n",
    "## 7   moutarde au moût de raisin   moutarde moût raisin       fr        0.990018\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecae51d2",
   "metadata": {},
   "source": [
    "6. Visualiser avec `spacy.displacy` le résultat d'une reconnaissance\n",
    "d'entités nommées sur 50 données aléatoires. Cela vous semble-t-il satisfaisant ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab5d6d5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import fr_core_news_sm\n",
    "\n",
    "nlp = fr_core_news_sm.load()\n",
    "\n",
    "example = \" \\n \".join(df_openfood_french['product_name'].astype(\"str\").sample(50))\n",
    "\n",
    "from spacy import displacy\n",
    "html = displacy.render(nlp(example), style='ent', page=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709b57cb",
   "metadata": {},
   "source": [
    "```r\n",
    "cat(py$html)\n",
    "```\n",
    "\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"fr\">\n",
    "    <head>\n",
    "        <title>displaCy</title>\n",
    "    </head>\n",
    "\n",
    "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
    "<figure style=\"margin-bottom: 6rem\">\n",
    "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
    "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
    "    Mousse\n",
    "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
    "</mark>\n",
    " de canard </br> \n",
    "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
    "    Escalope\n",
    "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
    "</mark>\n",
    " milanaise de poulet pané aux poivres </br> Filet mignon de porc \n",
    "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
    "    Label rouge Bleu blanc\n",
    "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
    "</mark>\n",
    " coeur </br> \n",
    "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
    "    Amandes\n",
    "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
    "</mark>\n",
    " décortiquées </br> \n",
    "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
    "    Touche de Thé Saveur\n",
    "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
    "</mark>\n",
    " citron </br> Concassé de baobab </br> \n",
    "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
    "    Boisson\n",
    "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
    "</mark>\n",
    " instantanée </br> Sorbet plein fruit citron vert </br> Saucisse de Francfort </br> Sirop de \n",
    "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
    "    grenadine \n",
    " \n",
    "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
    "</mark>\n",
    "Saucisson sec de l'île de beauté </br> Poitrine de poulet fumé </br> 6 merguez de porc </br> \n",
    "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
    "    Terrine de canard\n",
    "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
    "</mark>\n",
    " </br> \n",
    "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
    "    Mini\n",
    "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
    "</mark>\n",
    " poulet cordon bleu </br> Melange sportif </br> Thé vert à la fraise </br> Crème d'artichaut et truffe d'été </br> Coulis de \n",
    "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
    "    Framboise \n",
    " Steak\n",
    "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
    "</mark>\n",
    " de cuisse de poulet </br> COURONNE \n",
    "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
    "    BRETZEL 250G \n",
    " Soupe\n",
    "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
    "</mark>\n",
    " de poissons aux étrilles </br> \n",
    "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
    "    Petites\n",
    "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
    "</mark>\n",
    " gambas compotée de tomates \n",
    "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
    "    Tagliatelles\n",
    "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
    "</mark>\n",
    " au pesto </br> Figues au foie gras mi-cuit </br> \n",
    "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
    "    Bruge cubes \n",
    " Jambon\n",
    "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
    "</mark>\n",
    " périgourdin </br> Saucisse sèche au piment d'espelette </br> \n",
    "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
    "    Cabillaud Panés Qualité\n",
    "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
    "</mark>\n",
    " 100% \n",
    "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
    "    Filet MSC \n",
    " 2 Bavettes\n",
    "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
    "</mark>\n",
    " d'\n",
    "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
    "    Aloyau \n",
    " Poulet\n",
    "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
    "</mark>\n",
    " aux noix de cajou </br> Croissant </br> Compote pomme mangue </br> Pâte à tartiner aux noisettes du \n",
    "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
    "    Piémont\n",
    "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
    "</mark>\n",
    " 42% </br> Sirop d'agave </br> Glace framboise fleur de sureau </br> 1 faux filet </br> \n",
    "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
    "    Cèpenade\n",
    "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
    "</mark>\n",
    " nature </br> \n",
    "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
    "    Fromage Blanc\n",
    "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
    "</mark>\n",
    " 1/2 écrémé \n",
    "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
    "    BBC\n",
    "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
    "</mark>\n",
    " 500g </br> Aguardiente de orujo de liebana </br> Poulet fermier </br> Pain au chocolat au beurre </br> \n",
    "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
    "    Comté \n",
    " \n",
    "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
    "</mark>\n",
    "Melande deboulette </br> Pâtes alimentaires de blé dur biologique </br> Confit de canard </br> \n",
    "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
    "    Escalope\n",
    "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
    "</mark>\n",
    " cordon bleu poulet </br> \n",
    "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
    "    Croquettes \n",
    " Cassoulet\n",
    "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
    "</mark>\n",
    " au confit de canard </br> Goût \n",
    "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
    "    Myrtille \n",
    " \n",
    "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
    "</mark>\n",
    "Mélange mexicain</div>\n",
    "</figure>\n",
    "</body>\n",
    "</html>\n",
    "\n",
    "7. Récupérer dans un vecteur les entités nommées reconnues par `spaCy`.\n",
    "Regarder les entités reconnues dans les 20 premiers libellés de produits \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54221ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "for doc in nlp.pipe(df_openfood_french.head(20)['product_name'].astype(\"unicode\"), disable=[\"tok2vec\", \"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\"]):\n",
    "    # Do something with the doc here\n",
    "    x.append([(ent.text, ent.label_) for ent in doc.ents])\n",
    "    \n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625dddc0",
   "metadata": {},
   "source": [
    "```\n",
    "## [[], [], [('Pistou', 'PER')], [], [], [('Sachet calisson', 'PER')], [], [], [], [], [('Vainilla', 'PER')], [], [('Solène', 'PER')], [], [('Caramel', 'ORG')], [], [('Chouquettes x', 'MISC')], [('maïs bio', 'PER')], [], [('Bouillie', 'MISC')]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ebf26c",
   "metadata": {},
   "source": [
    "<!----\n",
    "# State of the union address"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc7bf24",
   "metadata": {},
   "source": [
    "Un exercice à venir sur l'analyse des discours des présidents américains \n",
    "inspiré de https://github.com/BuzzFeedNews/2018-01-trump-state-of-the-union\n",
    "---->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
