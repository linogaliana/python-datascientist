---
title: "Construire des graphiques avec Python"
title-en: "Building graphics with Python"
author: Lino Galiana
categories:
    - Visualisation
    - Exercice
description: |
    Une partie essentielle du travail du  _data scientist_ est d'être en mesure de synthétiser une information dans des représentations graphiques percutantes. Ce chapitre permet de découvrir les enjeux de la représentation de données avec `Python`, l'écosystème pour faire ceci. Il ouvre également à la représentation interactive de données avec `Plotly`.
description-en: |
    An essential part of the _data scientist's_ job is to be able to synthesize information into powerful graphical representations. This chapter looks at the challenges of data representation with `Python`, the ecosystem for doing this. It also opens the door to interactive data representation with `Plotly`.
image: https://minio.lab.sspcloud.fr/lgaliana/generative-art/pythonds/drawing.png
echo: false
bibliography: ../../reference.bib
---

{{< badges
    printMessage="true"
>}}

:::: {.content-visible when-profile="fr"}

::: {.callout-tip}
## Compétences à l'issue de ce chapitre

* Découvrir l'écosystème [`matplotlib`](https://matplotlib.org/) et
[`seaborn`](https://seaborn.pydata.org/) pour la construction de graphiques par enrichissement successif de couches.
* Découvrir le récent écosystème [`plotnine`](https://plotnine.readthedocs.io/en/stable/index.html),
qui est une implémentation en `Python` du _package_ `R` [`ggplot2`](https://ggplot2.tidyverse.org/)
pour ce type de représentation et qui, grâce à sa grammaire des graphiques, offre une syntaxe puissante pour construire des visualisations de données.
* Découvrir le principe des représentations interactives HTML (format _web_) grâce aux packages [`plotly`](https://plotly.com/python/) et [`altair`](https://altair-viz.github.io/).
* Apprendre les enjeux de la représentation graphique, les compromis nécessaires pour construire un message clair et les limites de certaines représentations classiques.

:::

# Introduction

::: {.callout-important}

Être capable de construire des visualisations de données intéressantes est une compétence nécessaire à tout _data scientist_ ou chercheur. Pour améliorer la qualité de ces visualisations, il est recommandé de suivre certains conseils donnés par des spécialistes de la _dataviz_ sur la sémiologie graphique.

Les bonnes visualisations de données, comme celles du _New York Times_, reposent certes sur des outils adaptés (des librairies `JavaScript`) mais aussi sur certaines règles de représentation qui permettent de comprendre en quelques secondes le message d'une visualisation. 

Transmettre une information synthétique de manière limpide à un public ne s'inventant pas, il est recommandé de réfléchir à la réception d'une visualisation et aux messages principaux que celle-ci est censée transmettre. Cette [présentation d'Eric Mauvière](https://ssphub.netlify.app/talk/2024-02-29-mauviere/) illustre, avec de nombreux exemples, la manière dont des choix de visualisation affectent la pertinence du message délivré. 

Parmi les autres ressources que j'ai trouvées utiles par le passé, ce post de blog de `datawrapper`](https://blog.datawrapper.de/text-in-data-visualizations/) (une référence dans le domaine de la visualisation) est très intéressant. Ce [post de blog d'Albert Rapp](https://albert-rapp.de/posts/ggplot2-tips/10_recreating_swd_look/10_recreating_swd_look) est montre également comment construire graduellement une bonne visualisation de données et mérite d'être relu de temps en temps.


:::


::::

:::: {.content-visible when-profile="en"}

::: {.callout-tip}
## Skills at the End of This Chapter

* Discover the [`matplotlib`](https://matplotlib.org/) and [`seaborn`](https://seaborn.pydata.org/) ecosystems for constructing charts through the successive enrichment of layers.
* Explore the modern [`plotnine`](https://plotnine.readthedocs.io/en/stable/index.html) ecosystem,
a `Python` implementation of the `R` package [`ggplot2`](https://ggplot2.tidyverse.org/)
for this type of representation, which offers a powerful syntax for building data visualizations through its grammar of graphics.
* Understand the concept of interactive HTML (web format) visualizations through the [`plotly`](https://plotly.com/python/) and [`altair`](https://altair-viz.github.io/) packages.
* Learn the challenges of graphical representation, the trade-offs needed to convey a clear message, and the limitations of certain traditional representations.


:::

# Introduction


::: {.callout-important}

Being able to create interesting data visualizations is a necessary skill for any _data scientist_ or researcher. To improve the quality of these visualizations, it is recommended to follow certain advice from _dataviz_ specialists on graphical semiology.

Good data visualizations, like those from the _New York Times_, rely not only on appropriate tools (such as `JavaScript` libraries) but also on certain design principles that allow the message of a visualization to be understood in just a few seconds.

As we can't invent ways of conveying synthetic information to an audience, it's a good idea to think about the reception of a visualization and the main messages it's designed to convey. This [presentation by Eric Mauvière](https://ssphub.netlify.app/talk/2024-02-29-mauviere/) illustrates, with numerous examples, how visualization choices affect the relevance of the message delivered.

Among other resources I've found useful in the past, this blog post by `datawrapper`](https://blog.datawrapper.de/text-in-data-visualizations/) (a reference in the field of visualization) is very interesting. This [blog post by Albert Rapp](https://albert-rapp.de/posts/ggplot2-tips/10_recreating_swd_look/10_recreating_swd_look) also shows how to gradually build up a good data visualization and is worth re-reading from time to time.


:::

::::


::: {.content-visible when-profile="fr"}
La pratique de la _data visualisation_ se fera, dans ce cours, en répliquant des graphiques qu'on peut trouver sur
la page de l'*open data* de la ville de Paris
[ici](https://opendata.paris.fr/explore/dataset/comptage-velo-donnees-compteurs/dataviz/?disjunctive.id_compteur&disjunctive.nom_compteur&disjunctive.id&disjunctive.name) ou en proposant des alternatives à ceux-ci sur les mêmes données.

L'objectif de ce chapitre n'est pas de faire un inventaire complet des graphiques pouvant être fait avec `Python`, ce serait long, assez insipide et peu pertinent car des sites le font déjà très bien à partir d'une grande variété d'exemple, notamment le site [python-graph-gallery.com/](https://python-graph-gallery.com/). L'objectif est plutôt d'illustrer, par la pratique, quelques enjeux liés à l'utilisation des principales librairies graphiques de `Python`.

On peut distinguer quelques grandes familles de représentations graphiques: les représentations de distributions propres à une variable, les représentations de relations entre plusieurs variables, les cartes qui permettent de représenter dans l'espace une ou plusieurs variables...

Ces familles se ramifient elles-mêmes en de multiples types de figures. Par exemple, selon la nature du phénomène, les représentations de relations peuvent prendre la forme d'une série temporelle (évolution d'une variable dans le temps), d'un nuage de point (corrélation entre deux variables), d'un diagramme en barre (pour souligner le rapport relatif entre les valeurs d'une variable en fonction d'une autre), etc.

Plutôt qu'un inventaire à la Prévert des types de visualisations possibles, ce chapitre et le suivant vont plutôt proposer quelques visualisations qui pourraient donner envie d'aller plus loin dans l'analyse avant la mise en oeuvre d'une forme de modélisation. Ce chapitre est consacré aux visualisations traditionnelles, le [suivant](/content/visualisation/maps.qmd) est dédié à la cartographie. Ces deux chapitres font partie d'un tout visant à offrir les premiers éléments pour synthétiser l'information présente dans un jeu de données.

Le pas suivant est d'approfondir le travail de communication et de synthèse par le biais de productions pouvant prendre des formes aussi diverses que des rapports, des publications scientifiques ou articles, des présentations, une application interactive, un site web ou des _notebooks_ comme ceux proposés par ce cours. Le principe général est identique quel que soit le _medium_ utilisé et intéresse particulièrement les _data scientists_ lorsqu'ils font appel à de l'exploitation intensive de données et désirent obtenir un _output_ rerproductible. Un jour peut-être j'ajouterai un chapitre à ce propos dans ce cours[^quarto].

[^quarto]: Ce chapitre sera construit autour de l'écosystème [`Quarto`](https://quarto.org/). En attendant ce chapitre, vous pouvez consulter la documentation exemplaire de cet écosystème et pratiquer, ce sera le meilleur moyen de découvrir.
:::

::: {.content-visible when-profile="en"}
The practice of _data visualization_ in this course will involve replicating charts found on the *open data* page of the City of Paris [here](https://opendata.paris.fr/explore/dataset/comptage-velo-donnees-compteurs/dataviz/?disjunctive.id_compteur&disjunctive.nom_compteur&disjunctive.id&disjunctive.name) or proposing alternatives using the same data.

The goal of this chapter is not to provide a comprehensive inventory of charts that can be created with `Python`. That would be long, somewhat tedious, and unnecessary, as websites like [python-graph-gallery.com/](https://python-graph-gallery.com/) already excel at showcasing a wide variety of examples. Instead, the objective is to illustrate, through practice, some key challenges and opportunities related to using the main graphical libraries in `Python`.

We can distinguish several major families of visualizations: representations of distributions specific to a single variable, representations of relationships between multiple variables, and maps that allow spatial representation of one or more variables.

These families themselves branch into various types of figures. For instance, depending on the nature of the phenomenon, relationship representations may take the form of a time series (evolution of a variable over time), a scatter plot (correlation between two variables), or a bar chart (highlighting the relative values of one variable in relation to another), among others.

Rather than an exhaustive inventory of possible visualizations, this chapter and the next will present some visualizations that may inspire further analysis before implementing a form of modeling. This chapter focuses on traditional visualizations, while the [next chapter](/content/visualisation/maps.qmd) is dedicated to cartography. Together, these two chapters aim to provide the initial tools for synthesizing the information present in a dataset.

The next step is to deepen communication and synthesis work through productions that can take forms as diverse as reports, scientific publications or articles, presentations, an interactive application, a website or _notebooks_ like those proposed by this course. The general principle is the same whatever the _medium_ used, and is of particular interest to _data scientists_ when they involve intensive exploitation of data and wish to obtain a rerproducible _output_. Perhaps one day I'll add a chapter on this subject to this course[^quarto-en].

[^quarto-en]: This chapter will be built around the [`Quarto`](https://quarto.org/) ecosystem. In the meantime, you can consult the excellent documentation of this ecosystem and practice, which is the best way to learn.
:::


:::: {.content-visible when-profile="fr"}


::: {.callout-note}

Si vous êtes intéressés par `R` {{< fa brands python >}}, une version très proche de ce TP est disponible dans [ce cours d'introduction à `R` pour l'ENS Ulm](https://rgeo.linogaliana.fr/exercises/ggplot.html).

:::

::::

:::: {.content-visible when-profile="en"}



::: {.callout-note}

If you are interested in `R` {{< fa brands python >}}, a very similar version of this practical work is available in [this introductory `R` course for ENS Ulm](https://rgeo.linogaliana.fr/exercises/ggplot.html).

:::

::::


:::: {.content-visible when-profile="fr"}

::: {.callout-important}
## Utiliser une interface interactive pour visualiser les graphiques

Pour les chapitres de visualisation, il est vivement recommandé d’utiliser `Python` par le biais d'une interface interactive comme un _notebook Jupyter_ (via `VSCode` ou `Jupyter` par exemple, cf. [le chapitre de présentation des notebooks](/content/getting-started/01_environment.qmd)). 

Cela permet de visualiser les graphiques immédiatement sous chaque cellule de code, de les ajuster facilement, et de tester des modifications en temps réel.

À l’inverse, si l'on exécute des scripts depuis une console classique (par exemple en écrivant dans un fichier `.py` et en exécutant ligne à ligne avec <kbd>MAJ</kbd>+,<kbd>ENTREE</kbd> dans `VSCode`) les graphiques ne vont pas s'afficher dans une fenêtre popup_ ce qui nécessite de faire des commandes supplémentaires pour les enregistrer, avant d'ouvrir les exports manuellement et pouvoir corriger le cas échéant le code. L’expérience d’apprentissage en devient plus laborieuse.
:::

::::


:::: {.content-visible when-profile="en"}

::: {.callout-important}

## Use an interactive interface to visualize graphics

For visualization chapters, it is highly recommended to use `Python` via an interactive interface such as a _notebook Jupyter_ (via `VSCode` or `Jupyter` for example, see [the notebook presentation chapter](/content/getting-started/01_environment.qmd)). 

This makes it possible to view the graphics immediately below each code cell, to adjust them easily, and to test modifications in real time.
Conversely, if scripts are run from a conventional console (e.g., by writing to a `.py` file and executing line by line with <kbd>MAJ</kbd>+,<kbd>ENTREE</kbd> in `VSCode`), the graphics will not be displayed in a popup window_ requiring additional commands to save them, before opening the exports manually and being able to correct the code if necessary. This makes for a more laborious learning experience.
:::

::::



::: {.content-visible when-profile="fr"}
## Données {-}

Ce chapitre s'appuie sur les données de comptage des passages de vélo dans les points de mesure parisiens diffusés sur le site de l'_open data_ de la ville de Paris.

L'exploitation de l'historique récent a été grandement facilité par la diffusion des données au format `Parquet`, un format moderne plus pratique que le CSV. Pour en savoir plus sur ce format, vous pouvez consulter les ressources évoquées dans le paragraphe consacré à ce format dans le [chapitre d'approfondissement](/content/manipulation/02_pandas_suite.qmd).
:::

::: {.content-visible when-profile="en"}
## Data {-}

This chapter is based on the bicycle passage count data from Parisian measurement points, published on the open data website of the City of Paris.

The use of recent historical data has been greatly facilitated by the availability of data in the `Parquet` format, a modern format more practical than CSV. For more information about this format, you can refer to the resources mentioned in the section dedicated to it in the [advanced chapter](/content/manipulation/02_pandas_suite.qmd).
:::


{{< include "_prepare_data_bike.qmd" >}}


::: {.content-visible when-profile="fr"}
# Premières productions graphiques avec l'API `Matplotlib` de `Pandas`

Chercher à produire une visualisation parfaite du premier coup est illusoire. Il est beaucoup plus réaliste d'améliorer graduellement une représentation graphique afin, petit à petit, de mettre en avant les effets de structure dans un jeu de données.

Nous allons donc commencer par nous représenter la distribution des passages aux principales stations de mesure. Pour cela nous allons produire rapidement un _barplot_ puis l'améliorer graduellement.

Dans cette partie, nous allons ainsi reproduire les deux premiers graphiques de la [page d'analyse des données](https://opendata.paris.fr/explore/dataset/comptage-velo-donnees-compteurs/dataviz/?disjunctive.id_compteur&disjunctive.nom_compteur&disjunctive.id&disjunctive.name) : *Les 10 compteurs avec la moyenne horaire la plus élevée* et *Les 10 compteurs ayant comptabilisé le plus de vélos*. Les valeurs chiffrées des graphiques peuvent être différentes de celles de la page en ligne, c'est normal, car nous ne travaillons pas systématiquement sur les données ayant la même fraîcheur que celles en ligne.

Pour importer les librairies graphiques que nous utiliserons dans ce chapitre, il faut faire

```{python}
#| echo: true
import matplotlib.pyplot as plt
import seaborn as sns
from plotnine import * #<1>
```
1. Importer des librairies sous la forme `from package import *` n'est pas une très bonne pratique. Néanmoins, pour un _package_ comme `plotnine`, dont nous allons utiliser de nombreuses fonctions, ce serait un peu fastidieux d'importer les fonctions au cas par cas. De plus, cela permet de réutiliser presque tels quels les exemples de code de la librairie `R` `ggplot`, nombreux sur internet avec démonstrations visuelles. `from package import *` est l'équivalent `Python` de la pratique `library(package)` en `R`.

:::

::: {.content-visible when-profile="en"}
# Initial Graphical Productions with `Pandas`' `Matplotlib` API

Trying to produce a perfect visualization on the first attempt is unrealistic. It is much more practical to gradually improve a graphical representation to progressively highlight structural effects in a dataset.

We will begin by visualizing the distribution of bicycle counts at the main measurement stations. To do this, we will quickly create a _barplot_ and then improve it step by step.

In this section, we will reproduce the first two charts from the [data analysis page](https://opendata.paris.fr/explore/dataset/comptage-velo-donnees-compteurs/dataviz/?disjunctive.id_compteur&disjunctive.nom_compteur&disjunctive.id&disjunctive.name): *The 10 counters with the highest hourly average* and *The 10 counters that recorded the most bicycles*. The numerical values of the charts may differ from those on the webpage, which is expected, as we are not necessarily working with data as up-to-date as that online.

To import the graphical libraries we will use in this chapter, execute

```{python}
#| echo: true
import matplotlib.pyplot as plt
import seaborn as sns
from plotnine import * #<1>
```
1. Importing libraries in the form `from package import *` is not a very good practice. However, for a _package_ like `plotnine`, many of whose functions we'll be using, it would be a bit tedious to import functions on a case-by-case basis. What's more, it allows us to reuse the `ggplot` `R` library code examples, which are plentiful on the Internet with visual demonstrations, almost as they are. `from package import *` is the `Python` equivalent of the `library(package)` practice in `R`.

:::



::: {.content-visible when-profile="fr"}
## Comprendre, en quelques mots, le principe de `matplotlib`

`matplotlib` date du début des années 2000 et a émergé pour proposer une alternative en `Python` à la création de graphiques sous `Matlab`, un logiciel propriétaire de calcul numérique. `matplotlib` est donc une librairie assez ancienne, antérieure à l'émergence de `Python` dans l'écosystème du traitement de données. Cela s'en ressent sur la logique de construction de `matplotlib` qui n'est pas toujours intuitive lorsqu'on est familier de l'écosystème moderne de la _data science_. Heureusement, il existe de nombreuses librairies qui s'appuient sur `matplotlib` mais qui visent à fournir une syntaxe plus familière aux _data scientists_.

`matplotlib` propose principalement deux niveaux d'abstraction: la figure et les axes. La figure est, en quelque sorte, la "toile" globale qui contient un ou plusieurs axes dans lesquels s'inséreront des graphiques. Selon les cas, il faudra jouer avec les paramètres de figure ou d'axe, ce qui rend très flexible la construction d'un graphique mais peut également être déroutant car on ne sait jamais trop quel niveau d'abstraction il faut modifier pour mettre à jour sa figure[^chatGPT]. Comme le montre la @fig-matplotlib, tous les éléments d'une figure sont paramétrables.

[^chatGPT]: Heureusement, comme il existe un énorme corpus de code en ligne utilisant `matplotlib`, les assistants de code comme `ChatGPT` ou `Github Copilot` sont précieux pour construire un graphique à partir d'instructions.

![Comprendre l'architecture d'une figure `matplotlib` (Source: [documentation officielle](https://matplotlib.org/stable/users/explain/quick_start.html))](https://matplotlib.org/stable/_images/anatomy.png){#fig-matplotlib}

En pratique, il existe deux manières de créer et mettre à jour sa figure selon qu'on préfère passer par:

- l'approche explicite, héritière d'une logique de programmation orientée objet, où on crée des objets `Figure` et `Axes` et met à jour ceux-ci.
- l'approche implicite, basée sur l'interface `pyplot` qui utilise une succession de fonctions pour mettre à jour les objets créés implicitement.
:::

::: {.content-visible when-profile="en"}
## Understanding the Basics of `matplotlib`

`matplotlib` dates back to the early 2000s and emerged as a `Python` alternative for creating charts, similar to `Matlab`, a proprietary numerical computation software. Thus, `matplotlib` is quite an old library, predating the rise of `Python` in the data processing ecosystem. This is reflected in its design, which may not always feel intuitive to those familiar with the modern _data science_ ecosystem. Fortunately, many libraries build upon `matplotlib` to provide syntax more familiar to _data scientists_.

`matplotlib` primarily offers two levels of abstraction: the figure and the axes. The figure is essentially the "canvas" that contains one or more axes, where the charts are placed. Depending on the situation, you might need to modify figure or axis parameters, which makes chart creation highly flexible but also potentially confusing, as it’s not always clear which abstraction level to modify[^chatGPT-en]. As shown in @fig-matplotlib, every element of a figure is customizable.

[^chatGPT-en]: Thankfully, with a vast amount of online code using `matplotlib`, code assistants like `ChatGPT` or `Github Copilot` are invaluable for creating charts based on instructions.

![Understanding the Anatomy of a `matplotlib` Figure (Source: [Official Documentation](https://matplotlib.org/stable/users/explain/quick_start.html))](https://matplotlib.org/stable/_images/anatomy.png){#fig-matplotlib}

In practice, there are two ways to create and update your figure, depending on your preference:

- The explicit approach, inheriting an object-oriented programming logic, where `Figure` and `Axes` objects are created and updated directly.
- The implicit approach, based on the `pyplot` interface, which uses a series of functions to update implicitly created objects.
:::

:::: {.content-visible when-profile="fr"}

::: {.panel-tabset group="matplotlib-abstraction"}
## Approche explicite (approche orientée POO)

{{< include "01_matplotlib/_matplotlib_poo.qmd" >}}

Source: [Documentation officielle de `matplotlib`](https://matplotlib.org/stable/users/explain/quick_start.html)

## Approche implicite

{{< include "01_matplotlib/_matplotlib_pyplot.qmd" >}}

Source: [Documentation officielle de `matplotlib`](https://matplotlib.org/stable/users/explain/quick_start.html)

::::

Ces éléments constituent le minimum pour comprendre la logique de `matplotlib`. Pour être plus à l'aise avec ces concepts, la pratique répétée est indispensable.

:::

:::: {.content-visible when-profile="en"}

::: {.panel-tabset group="matplotlib-abstraction"}
## Explicit Approach (Object-Oriented Approach)

{{< include "01_matplotlib/_matplotlib_poo.qmd" >}}

Source: [Official `matplotlib` Documentation](https://matplotlib.org/stable/users/explain/quick_start.html)

## Implicit Approach

{{< include "01_matplotlib/_matplotlib_pyplot.qmd" >}}

Source: [Official `matplotlib` Documentation](https://matplotlib.org/stable/users/explain/quick_start.html)

:::

These elements are the minimum required to understand the logic of `matplotlib`. To become more comfortable with these concepts, repeated practice is essential.

::::



::: {.content-visible when-profile="fr"}
## Découvrir `matplotlib` par l'intermédiaire de `Pandas`
:::

::: {.content-visible when-profile="en"}
## Discovering `matplotlib` through `Pandas`
:::



{{< include "01_matplotlib/_exo1.qmd" >}}

{{< include "01_matplotlib/_exo1_solution.qmd" >}}


::: {.content-visible when-profile="fr"}
On commence à avoir quelque chose qui commence à transmettre un message synthétique sur la nature des données. On peut néanmoins remarquer plusieurs éléments problématiques (par exemple les labels) mais aussi des éléments ne correspondant pas (les titres des axes, etc.) ou manquants (le nom du graphique...).

Comme les graphiques produits par `Pandas` suivent la logique très flexible de `matplotlib`, il est possible de les customiser. Cependant, cela demande généralement beaucoup de travail et la grammaire `matplotlib` n'est pas aussi normalisée que celle de `ggplot` en `R`. Si on désire rester dans l'écosystème `matplotlib`, il est préférable de directement utiliser `seaborn`, qui offre quelques arguments prêts à l'emploi. Sinon on peut basculer sur l'écosystème `plotnine` qui offrira une syntaxe normalisée pour modifier les différents

# Utiliser directement `seaborn`

## Comprendre `seaborn` en quelques lignes

`seaborn` est une interface haut niveau au dessus de `matplotlib`. Ce package offre un ensemble de fonctionnalités pour créer des figures ou des axes `matplotlib` directement depuis une fonction admettant de nombreux arguments et, si besoin d'aller plus loin dans la customisation, d'utiliser les fonctionnalités de `matplotlib` pour mettre à jour la figure, que ce soit par le biais de l'approche implicite ou explicite décrites précédemment.

Comme pour `matplotlib`, `seaborn` permet de faire la même figure de multiples manières. `seaborn` hérite de la dualité axes-figures de `matplotlib` et il faudra souvent jouer avec un niveau ou l'autre. La principale caractéristique de `seaborn` est d'offrir quelques points d'entrée standardisés, par exemple `seaborn.relplot` ou `seaborn.catplot`, et une logique d'_inputs_ basée sur le `DataFrame` là où `matplotlib` est structurée autour du _array_ `Numpy`.

La figure comporte maintenant un message mais il est encore peu lisible. Il y a plusieurs manières de faire un *barplot* en `seaborn`. Les deux principales sont :

- `sns.catplot` ;
- `sns.barplot`.

On propose d'utiliser `sns.catplot` pour cet exercice. Il s'agit d'un point d'entrée assez fréquent pour faire des graphiques d'une variable discrétisée.

## Le diagramme en barre (_barplot_)
:::

::: {.content-visible when-profile="en"}
We are starting to create something that conveys a synthetic message about the nature of the data. However, several issues remain (e.g., labels), as well as elements that are either incorrect (axis titles, etc.) or missing (graph title...).

Since the charts produced by `Pandas` follow the highly flexible logic of `matplotlib`, they can be customized. However, this often requires significant effort, and the `matplotlib` grammar is not as standardized as `ggplot` in `R`. If you wish to remain in the `matplotlib` ecosystem, it is better to use `seaborn` directly, which provides ready-to-use arguments. Alternatively, you can switch to the `plotnine` ecosystem, which offers a standardized syntax for modifying elements.

# Using `seaborn` Directly

## Understanding `seaborn` in a Few Lines

`seaborn` is a high-level interface built on top of `matplotlib`. This package provides a set of features to create `matplotlib` figures or axes directly from a function with numerous arguments. If further customization is needed, `matplotlib` functionalities can be used to update the figure, whether through the implicit or explicit approaches described earlier.

As with `matplotlib`, the same figure can be created in multiple ways in `seaborn`. `seaborn` inherits the figure-axes duality from `matplotlib`, requiring frequent adjustments at either level. The main characteristic of `seaborn` is its standardized entry points, such as `seaborn.relplot` or `seaborn.catplot`, and its _input_ logic based on `DataFrame`, whereas `matplotlib` is structured around `Numpy` arrays.

The figure now conveys a message, but it is still not very readable. There are several ways to create a *barplot* in `seaborn`. The two main ones are:

- `sns.catplot`
- `sns.barplot`

For this exercise, we suggest using `sns.catplot`. It is a common entry point for plotting graphs of a discretized variable.

## The bar chart (_barplot_)
:::



{{< include "01_matplotlib/_exo2.qmd" >}}
{{< include "01_matplotlib/_exo2_solution.qmd" >}}



::: {.content-visible when-profile="fr"}
On comprend ainsi que le boulevard de Sébastopol est le plus emprunté, ce qui ne vous surprendra pas si vous faites du vélo à Paris. Néanmoins, si vous n'êtes pas familiers avec la géographie parisienne, cela sera peu informatif pour vous, vous allez avoir besoin d'une représentation graphique supplémentaire : une carte ! Nous verrons ceci lors d'un prochain chapitre.
:::

::: {.content-visible when-profile="en"}
This shows that Boulevard de Sébastopol is the most traveled, which won't surprise you if you cycle in Paris. However, if you're not familiar with Parisian geography, this will provide little information for you. You'll need an additional graphical representation: a map! We will cover this in a future chapter.
:::


:::: {.content-visible when-profile="fr"}

::: {.callout-tip}
## Exercice 2bis : reproduire la figure _"Les 10 compteurs ayant comptabilisé le plus de vélos"_

En suivant l'approche graduelle de l'exercice 2, refaire le graphique *Les 10 compteurs ayant comptabilisé le plus de vélos* avec `seaborn`.

:::

::::

:::: {.content-visible when-profile="en"}

::: {.callout-tip}
## Exercise 2b: Reproducing the Figure _"The 10 Counters That Recorded the Most Bicycles"_

Following the gradual approach of Exercise 2, recreate the chart *The 10 Counters That Recorded the Most Bicycles* using `seaborn`.

:::

::::


::: {.content-visible when-profile="fr"}
## Un exemple d'alternative au _barplot_, le _lollipop chart_

Les diagrammes en bâtons (_barplot_) sont extrêmement communs, sans doute à cause de l'héritage d'Excel où ces graphiques sont faisables en deux clics. Néanmoins, en ce qui concerne le message à transmettre, ils sont loin d'être parfaits. Par exemple, les barres prennent beaucoup d'espace visuel, ce qui peut brouiller le message à transmettre sur le rapport entre les observations.

Sur le plan sémiologique, c'est-à-dire sur le plan de l'efficacité du message à transmettre, les _lollipop charts_ sont préférables : ils transmettent la même information mais avec moins de signes visuels pouvant brouiller sa compréhension.

Les _lollipop charts_ ne sont pas parfaits non plus mais sont un peu plus efficaces pour transmettre le message. Pour en savoir plus sur les alternatives au _barplot_, la conférence d'Eric Mauvière pour le réseau des _data scientists_ de la statistique publique, dont le message principal est _"Désempilez vos figures"_, mérite le détour ([disponible sur le site ssphub.netlify.app/](https://ssphub.netlify.app/talk/2024-02-29-mauviere/)).
:::

::: {.content-visible when-profile="en"}
## An Alternative to the _Barplot_: the _Lollipop Chart_

Bar charts (_barplot_) are extremely common, likely due to the legacy of Excel, where these charts can be created with just a couple of clicks. However, in terms of conveying a message, they are far from perfect. For example, the bars take up a lot of visual space, which can obscure the intended message about relationships between observations.

From a semiological perspective, that is, in terms of the effectiveness of conveying a message, _lollipop charts_ are preferable: they convey the same information but with fewer visual elements that might clutter understanding.

_Lollipop charts_ are not perfect either but are slightly more effective at conveying the message. To learn more about alternatives to bar charts, Eric Mauvière's talk for the public statistics data scientists network, whose main message is _"Unstack your figures"_, is worth exploring ([available on ssphub.netlify.app/](https://ssphub.netlify.app/talk/2024-02-29-mauviere/)).
:::


{{< include "01_matplotlib/_exo3.qmd" >}}

::: {.content-visible when-profile="fr"}
La figure obtenue dans cet exercice est la suivante:
:::
```{python}
my_range=range(1,len(df2.index)+1)

sns.set_style("ticks", {"xtick.color": "forestgreen"})

plt.hlines(y=my_range, xmin=0, xmax=df2['sum_counts'], color='black', alpha = 0.4)
plt.plot(df2['sum_counts'], my_range, "o", color = "forestgreen")

plt.yticks(my_range, df2['nom_compteur'])
plt.title("Les 10 compteurs ayant comptabilisés le plus de vélos", loc='left')
plt.xlabel('sum_counts')
plt.ylabel('La somme des vélos comptabilisés sur la période sélectionnée')
```

::: {.content-visible when-profile="fr"}
# La même figure avec `Plotnine`

`plotnine` est le nouveau venu dans l'écosystème de la visualisation en `Python`. Cette librairie est développée par `Posit`, l'entreprise à l'origine de l'éditeur `RStudio` et de l'écosystème du _tidyverse_ si central dans le langage `R`. Cette librairie vise à importer la logique de `ggplot` en `Python`, c'est-à-dire une grammaire des graphiques normalisée, lisible et flexible héritée de @wilkinson2012grammar.

![L'état d'esprit des habitués de `ggplot2` quand ils découvrent `plotnine`](https://minio.lab.sspcloud.fr/lgaliana/generative-art/pythonds/elmo.jpg)

Dans cette approche, un graphique est vu comme une succession de couches qui, une fois superposées, donneront la figure suivante. En soi, ce principe n'est pas différent de celui de `matplotlib`. Néanmoins, la grammaire utilisée par `plotnine` est beaucoup plus intuitive et normalisée, ce qui offrira beaucoup plus d'autonomie pour modifier sa figure.

![La logique de `ggplot` (et `plotnine`) par @Lisa_psyTeachR_Book_Template_2021, image elle-même empruntée à @field2012discovering](https://psyteachr.github.io/data-skills-v2/images/corsi/layers.png)

Avec `plotnine`, il n'y a plus de point d'entrée dual figure-axe. Comme l'illustrent les slides ci-dessous :

1. On initialise une figure
2. On met à jour les couches (_layers_), un niveau d'abstraction très général concernant aussi bien les données représentées que les échelles des axes ou la couleur
3. À la fin, on peut jouer sur l'esthétique en modifiant les labels des axes, de la légende, les titres, etc.
:::

::: {.content-visible when-profile="en"}
# The Same Figure with `Plotnine`

`plotnine` is the newcomer to the `Python` visualization ecosystem. This library is developed by `Posit`, the company behind the `RStudio` editor and the _tidyverse_ ecosystem, which is central to the `R` language. This library aims to bring the logic of `ggplot` to `Python`, meaning a standardized, readable, and flexible grammar of graphics inspired by @wilkinson2012grammar.

![The mindset of `ggplot2` users when they discover `plotnine`](https://minio.lab.sspcloud.fr/lgaliana/generative-art/pythonds/elmo.jpg)

In this approach, a chart is viewed as a succession of layers that, when combined, create the final figure. This principle is not inherently different from that of `matplotlib`. However, the grammar used by `plotnine` is far more intuitive and standardized, offering much more autonomy for modifying a chart.

![The logic of `ggplot` (and `plotnine`) by @Lisa_psyTeachR_Book_Template_2021, image itself borrowed from @field2012discovering](https://psyteachr.github.io/data-skills-v2/images/corsi/layers.png)

With `plotnine`, there is no longer a dual figure-axis entry point. As illustrated in the slides below:

1. A figure is initialized
2. Layers are updated, a very general abstraction level that applies to the data represented, axis scales, colors, etc.
3. Finally, aesthetics can be adjusted by modifying axis labels, legend labels, titles, etc.
:::


:::: {.content-visible when-profile="en"}

:::{.cell .markdown}
Dérouler les _slides_ ci-dessous ou [cliquer ici](/slides/ggplot.qmd)
pour afficher les slides en plein écran.

```{=html}
<div class="sourceCode" id="cb1"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><iframe class="sourceCode yaml code-with-copy" src="https://rgeo.linogaliana.fr/slides/ggplot.html#/ggplot2"></iframe></div>
```

:::

::::


:::: {.content-visible when-profile="en"}

:::{.cell .markdown}
Scroll _slides_ below or [click here](/slides/ggplot.qmd)
to display slides full screen.

```{=html}
<div class="sourceCode" id="cb1"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><iframe class="sourceCode yaml code-with-copy" src="https://rgeo.linogaliana.fr/slides/ggplot.html#/ggplot2"></iframe></div>
```

:::

::::

{{< include "01_matplotlib/_exo4.qmd" >}}
{{< include "01_matplotlib/_exo4_solution.qmd" >}}


::: {.content-visible when-profile="fr"}
# Premières agrégations temporelles

On va maintenant se concentrer sur la dimension temporelle de notre jeu de données à travers deux approches :

- Un diagramme en barre synthétisant l'information de notre jeu de données de manière mensuelle ;
- Des séries instructives sur la dynamique temporelle. Cela sera l'objet de la prochaine partie.

Avant cela, nous allons enrichir ces données pour bénéficier d'un historique plus long, permettant notamment d'avoir la période Covid dans nos données, ce qui présente un intérêt du fait de la dynamique particulière du trafic dans cette période (arrêt brutal, reprise très forte...).
:::

::: {.content-visible when-profile="en"}
# Initial Temporal Aggregations

We will now focus on the temporal dimension of our dataset using two approaches:

- A bar chart summarizing the information in our dataset on a monthly basis;
- Informative series on temporal dynamics, which will be the subject of the next section.

Before that, we will enhance this data to include a longer history, particularly encompassing the Covid period in our dataset. This is interesting due to the unique traffic dynamics during this time (sudden halt, strong recovery, etc.).
:::

{{< include "_historical_data_bike.qmd" >}}


::: {.content-visible when-profile="fr"}
Pour commencer, reproduisons la troisième figure qui est, encore une fois, un _barplot_. Ici, sur le plan sémiologique, ce n'est pas justifié d'utiliser un _barplot_, une simple série suffirait à fournir une information similaire.

La première question du prochain exercice implique une première rencontre avec une donnée temporelle à travers une opération assez classique en séries temporelles : changer le format d'une date pour pouvoir faire une agrégation à un pas de temps plus large.
:::

::: {.content-visible when-profile="en"}
To begin, let us reproduce the third figure, which is, once again, a _barplot_. Here, from a semiological perspective, it is not justified to use a _barplot_; a simple time series would suffice to provide similar information.

The first question in the next exercise involves an initial encounter with temporal data through a fairly common time series operation: changing the format of a date to allow aggregation at a broader time step.
:::


{{< include "01_matplotlib/_exo5.qmd" >}}
{{< include "01_matplotlib/_exo5_solution.qmd" >}}


::: {.content-visible when-profile="fr"}

# Première série temporelle

Il est plus commun de représenter les données ayant une dimension temporelle sous la forme de série que de barres empilées.

:::: {.callout-tip}
## Exercice 5: barplot des comptages mensuels

1. Créer une variable `day` qui transforme l'horodatage en format journalier du type `2021-05-01` avec `dt.day`.
2. Reproduire la figure de la page d'_open data_.

:::

::::

:::: {.content-visible when-profile="en"}

# First Time Series

It is more common to represent data with a temporal dimension as a series rather than stacked bars.

::: {.callout-tip}
## Exercise 5: Barplot of Monthly Counts

1. Create a `day` variable that converts the timestamp into a daily format like `2021-05-01` using `dt.day`.
2. Reproduce the figure from the _open data_ page.

:::

::::


```{python}
df['day'] = df['date'].dt.date
moyenne_quotidienne = df.groupby('day', as_index=False).agg({'sum_counts':'mean'})
moyenne_quotidienne['day'] = pd.to_datetime(moyenne_quotidienne['day'])
```

```{python}
# Version plotnine
figure4 = (
    ggplot(moyenne_quotidienne, aes(x = "day", y = 'sum_counts')) +
    geom_line(color = "magenta") +
    geom_area(fill="magenta", alpha = 0.6) +
    labs(
        x = "Date et heure de comptage (Jour)",
        y = "Moyenne journalière du comptage par heure\nsur la période sélectionnée",
       title = "Moyenne journalière des comptages vélos"
    ) +
    theme_minimal() +
    theme(
        axis_text_x = element_text(angle = 45, hjust = 1),
        plot_title = element_text(hjust = 0.5)
    )
)
figure4
```


```{python}
#| output: false

# Version matplotlib
plt.clf()
ax = sns.lineplot(x='day', y='sum_counts', data=moyenne_quotidienne, color = "magenta")
l1 = ax.lines[0]
x1 = l1.get_xydata()[:, 0]
y1 = l1.get_xydata()[:, 1]
ax.fill_between(x1, y1, color="magenta", alpha=0.3)
```


::: {.content-visible when-profile="fr"}
# Des graphiques réactifs grâce aux librairies `Javascript`

## L'écosystème disponible depuis `Python`

Les figures figées construites avec `matplotlib` ou `plotnine` sont figées et présentent ainsi l'inconvénient de ne pas permettre d'interaction avec le lecteur. Toute l'information doit donc être contenue dans la figure, ce qui peut la rendre difficile à lire. Si la figure est bien faite, avec différents niveaux d'information, cela peut bien fonctionner.

Il est néanmoins plus simple, grâce aux technologies _web_, de proposer des visualisations à plusieurs niveaux. Un premier niveau d'information, celui du coup d'œil, peut suffire à assimiler les principaux messages de la visualisation. Ensuite, un comportement plus volontaire de recherche d'information secondaire peut permettre d'en savoir plus. Les visualisations réactives, qui sont maintenant la norme dans le monde de la _dataviz_, permettent ce type d'approche : le lecteur d'une visualisation peut passer sa souris à la recherche d'informations complémentaires (par exemple, les valeurs exactes) ou cliquer pour faire apparaître des informations complémentaires sur la visualisation ou autour.

Ces visualisations reposent sur le même triptyque que l'ensemble de l'écosystème _web_ : `HTML`, `CSS` et `JavaScript`. Les utilisateurs de `Python` ne vont jamais manipuler directement ces langages, qui demandent une certaine expertise, mais vont utiliser des librairies au niveau de `R` qui génèreront automatiquement tout le code `HTML`, `CSS` et `JavaScript` permettant de créer la figure.

Il existe plusieurs écosystèmes `Javascript` mis à disposition des développeurs.euses par le biais de `Python`. Les deux principales librairies sont [`Plotly`](https://plotly.com/python/), associée à l'écosystème `Javascript` du même nom, et [`Altair`](https://altair-viz.github.io/), associée à l'écosystème `Vega` et `Altair` en `Javascript`[^star]. Pour permettre aux pythonistes de découvrir la librairie `Javascript` émergente [`Observable Plot`](https://observablehq.com/plot/), l'ingénieur de recherche français Julien Barnier a développé [`pyobsplot`](https://juba.github.io/pyobsplot/) une librairie `Python` permettant d'utiliser cet écosystème depuis `Python`.

[^star]: Le nom de ces librairies est inspiré de la constellation du triangle d'été dont Véga et Altair sont deux membres.

L'interactivité ne doit pas juste être un gadget n'apportant pas de lisibilité supplémentaire, voire la détériorant. Il est rare de pouvoir se contenter de la figure produite sans avoir à fournir un travail supplémentaire pour la rendre efficace.
:::

::: {.content-visible when-profile="en"}
# Reactive Charts with `Javascript` Libraries

## The Ecosystem Available from `Python`

Static figures created with `matplotlib` or `plotnine` are fixed and thus have the disadvantage of not allowing interaction with the viewer. All the information must be contained in the figure, which can make it difficult to read. If the figure is well-made with multiple levels of information, it can still work well.

However, thanks to _web_ technologies, it is simpler to offer visualizations with multiple levels. A first level of information, the quick glance, may be enough to grasp the main messages of the visualization. Then, a more deliberate behavior of seeking secondary information can provide further insights. Reactive visualizations, now the standard in the _dataviz_ world, allow for this approach: the viewer can hover over the visualization to find additional information (e.g., exact values) or click to display complementary details.

These visualizations rely on the same triptych as the entire _web_ ecosystem: `HTML`, `CSS`, and `JavaScript`. `Python` users will not directly manipulate these languages, which require a certain level of expertise. Instead, they use libraries that automatically generate all the necessary `HTML`, `CSS`, and `JavaScript` code to create the figure.

Several `Javascript` ecosystems are made available to developers through `Python`. The two main libraries are [`Plotly`](https://plotly.com/python/), associated with the `Javascript` ecosystem of the same name, and [`Altair`](https://altair-viz.github.io/), associated with the `Vega` and `Altair` ecosystems in `Javascript`[^star]. To allow Python users to explore the emerging `Javascript` library [`Observable Plot`](https://observablehq.com/plot/), French research engineer Julien Barnier developed [`pyobsplot`](https://juba.github.io/pyobsplot/), a `Python` library enabling the use of this ecosystem from `Python`.

[^star]: The names of these libraries are inspired by the Summer Triangle constellation, of which Vega and Altair are two members.

Interactivity should not just be a gimmick that adds no readability or even worsens it. It is rare to rely solely on the figure as produced without further work to make it effective.
:::

::: {.content-visible when-profile="fr"}
### La librairie `Plotly`

Le package `Plotly` est une surcouche à la librairie `Javascript` `Plotly.js` qui permet de créer et manipuler des objets graphiques de manière très flexible afin de produire des objets réactifs sans avoir à recourir à Javascript.

Le point d'entrée recommandé est le module `plotly.express` ([documentation ici](https://plotly.com/python/plotly-express/)) qui offre une approche intuitive pour construire des graphiques pouvant être modifiés *a posteriori* si besoin (par exemple pour *customiser* les axes).

::: {.callout-note}
## Visualiser les figures produites par `Plotly`

Dans un _notebook_ `Jupyter` classique, les lignes suivantes de code permettent d'afficher le résultat d'une commande `Plotly` sous un bloc de code :

```{python}
#| eval: false
from plotly.offline import init_notebook_mode
init_notebook_mode(connected = True)
```

Pour `JupyterLab`, l'extension `jupyterlab-plotly` s'avère nécessaire:

```python
!jupyter labextension install jupyterlab-plotly
```

:::

## Réplication de l'exemple précédent avec `Plotly`

Les modules suivants seront nécessaires pour construire des graphiques avec `plotly`:

```{python}
#| echo: true
import plotly
import plotly.express as px
```
:::

::: {.content-visible when-profile="en"}
### The `Plotly` Library

The `Plotly` package is a wrapper for the `Javascript` library `Plotly.js`, allowing for the creation and manipulation of graphical objects very flexibly to produce interactive objects without the need for Javascript.

The recommended entry point is the `plotly.express` module ([documentation here](https://plotly.com/python/plotly-express/)), which provides an intuitive approach for creating charts that can be modified *post hoc* if needed (e.g., to customize axes).

::: {.callout-note}
## Displaying Figures Created with `Plotly`

In a standard `Jupyter` notebook, the following lines of code allow the output of a `Plotly` command to be displayed under a code block:

```{python}
#| eval: false
from plotly.offline import init_notebook_mode
init_notebook_mode(connected = True)
```

For `JupyterLab`, the `jupyterlab-plotly` extension is required:

```python
!jupyter labextension install jupyterlab-plotly
```

:::

## Replicating the Previous Example with `Plotly`

The following modules will be required to create charts with `plotly`:

```{python}
#| echo: true
import plotly
import plotly.express as px
```
:::


:::: {.content-visible when-profile="fr"}

::: {.callout-tip}
## Exercice 7: un barplot avec `Plotly`

L'objectif est de reconstruire le premier diagramme en barre rouge avec `Plotly`.

1. Réalisez le graphique en utilisant la fonction adéquate avec `plotly.express` et...
    * Ne pas prendre le thème par défaut mais un à fond blanc, pour avoir un résultat ressemblant à celui proposé sur le site de l'*open-data*.
    * Pour la couleur rouge, vous pouvez utiliser l'argument `color_discrete_sequence`.
    * Ne pas oublier de nommer les axes.
    * Pensez à la couleur du texte de l'axe inférieur.

2. Tester un autre thème, à fond sombre. Pour les couleurs, faire un groupe stockant les trois plus fortes valeurs puis les autres.

:::

::::

:::: {.content-visible when-profile="en"}

::: {.callout-tip}
## Exercise 7: A Barplot with `Plotly`

The goal is to recreate the first red bar chart using `Plotly`.

1. Create the chart using the appropriate function from `plotly.express` and...
    * Do not use the default theme but one with a white background to achieve a result similar to that on the *open-data* site.
    * Use the `color_discrete_sequence` argument for the red color.
    * Remember to label the axes.
    * Consider the text color for the lower axis.

2. Try another theme with a dark background. For colors, group the three highest values together and separate the others.

:::

::::

::: {.content-visible when-profile="fr"}
```{python}
#| output: false
# 1. Graphique avec fond blanc
fig = px.bar(
    df1.sort_values('sum_counts', ascending=True),
    orientation='h', x='sum_counts',
    y='nom_compteur', color_discrete_sequence=["red"], template="plotly_white"
)

fig.update_layout(
    title='Les 10 compteurs avec la moyenne horaire la plus élevée',
    xaxis_title='Moyenne du comptage par heure sur la période sélectionnée')
fig.update_xaxes(title_font=dict(color='red'))
```

```{python}
#| output: false

# 2. Graphique avec thème sombre
df1['top'] = df1['sum_counts'] > df1.sort_values('sum_counts', ascending=False)['sum_counts'][3]
fig2 = px.bar(
    df1.sort_values('sum_counts', ascending=True), orientation='h', x='sum_counts',
    y='nom_compteur', color='top', # attention, l'argument color ne semble pas toujours fonctionner
    template="plotly_dark",
    color_discrete_sequence=['red','green']
)
fig2.update_layout(
    title='Les 10 compteurs avec la moyenne horaire la plus élevée',
    xaxis_title='Moyenne du comptage par heure sur la période sélectionnée'
)
```
:::

::: {.content-visible when-profile="en"}
```{python}
#| output: false
# 1. Chart with white background
fig = px.bar(
    df1.sort_values('sum_counts', ascending=True),
    orientation='h', x='sum_counts',
    y='nom_compteur', color_discrete_sequence=["red"], template="plotly_white"
)

fig.update_layout(
    title='The 10 counters with the highest hourly average',
    xaxis_title='Average count per hour over the selected period')
fig.update_xaxes(title_font=dict(color='red'))
```

```{python}
#| output: false

# 2. Chart with dark theme
df1['top'] = df1['sum_counts'] > df1.sort_values('sum_counts', ascending=False)['sum_counts'][3]
fig2 = px.bar(
    df1.sort_values('sum_counts', ascending=True), orientation='h', x='sum_counts',
    y='nom_compteur', color='top', # note: the color argument might not always work
    template="plotly_dark",
    color_discrete_sequence=['red','green']
)
fig2.update_layout(
    title='The 10 counters with the highest hourly average',
    xaxis_title='Average count per hour over the selected period'
)
```
:::


::: {.content-visible when-format="html"}

::: {.content-visible when-profile="fr"}
La première question permet de construire le graphique suivant :
:::

::: {.content-visible when-profile="en"}
The first question allows the creation of the following chart:
:::

```{python}
fig.show()
```

::: {.content-visible when-profile="fr"}
Alors qu’avec le thème sombre (question 2), on obtient :
:::

::: {.content-visible when-profile="en"}
Whereas with the dark theme (question 2), we get:
:::

```{python}
fig2.show()
```

:::


::: {.content-visible when-profile="fr"}
## La librairie `altair`

Pour cet exemple, nous allons reconstruire notre figure précédente.
:::

::: {.content-visible when-profile="en"}
## The `altair` Library

For this example, we will recreate our previous figure.
:::

```{python}
df1 = (
    df
    .groupby('nom_compteur')
    .agg({'sum_counts': "mean"})
    .sort_values('sum_counts', ascending = False)
    .head(10)
    .sort_values('sum_counts')
)
```

::: {.content-visible when-profile="fr"}
Comme `ggplot`/`plotnine`, `Vega` est un écosystème graphique visant à proposer une implémentation de la grammaire des graphiques de @wilkinson2012grammar. La syntaxe de `Vega` est donc basée sur un principe déclaratif : on déclare une construction par couches et transformations de données progressives.

À l'origine, `Vega` est basée sur une syntaxe JSON, d'où son lien fort avec `Javascript`. Néanmoins, il existe une API Python qui permet de faire ce type de figures interactives nativement en Python. Pour comprendre la logique de construction d'un code `altair`, voici comment répliquer la figure précédente avec :
:::

::: {.content-visible when-profile="en"}
Like `ggplot`/`plotnine`, `Vega` is a graphics ecosystem designed to implement the grammar of graphics from @wilkinson2012grammar. The syntax of `Vega` is therefore based on a declarative principle: a construction is declared through layers and progressive data transformations.

Originally, `Vega` was based on a JSON syntax, hence its strong connection to `Javascript`. However, there is a Python API that allows for creating these types of interactive figures natively in Python. To understand the logic of constructing an `altair` code, here is how to replicate the previous figure:
:::


::: {.content-visible when-profile="fr"}

```{python}
#| code-fold: true
#| code-summary: "Voir l'architecture d'une figure altair"
#| echo: true
import altair as alt

color_scale = alt.Scale(domain=[True, False], range=['green', 'red'])

fig2 = (
    alt.Chart(df1)
    .mark_bar() #<1>
    .encode( #<2>
        x=alt.X('average(sum_counts):Q', title='Moyenne du comptage par heure sur la période sélectionnée'), #<3>
        y=alt.Y('nom_compteur:N', sort='-x', title=''),
        color=alt.Color('top:N', scale=color_scale, legend=alt.Legend(title="Top")),
        tooltip=[
            alt.Tooltip('nom_compteur:N', title='Nom du compteur'),
            alt.Tooltip('sum_counts:Q', title='Moyenne horaire')
            ] #<4>
    ).properties( #<5>
        title='Les 10 compteurs avec la moyenne horaire la plus élevée'
    ).configure_view(
        strokeOpacity=0
    )
)

fig2.interactive()
```

1. On déclare d'abord le _dataframe_ qui sera utilisé, comme nous le faisions avec `ggplot(df)` avec `plotnine`. Puis le type de figure désirée (ici un diagramme en barre, `mark_bar` dans la grammaire d'`altair`).
2. On définit notre couche principale avec `encode`. Celle-ci peut accepter simplement des noms de colonnes ou des constructeurs plus complexes, comme ici.
3. On définit un constructeur pour notre axe des _x_, à la fois pour gérer l'échelle des valeurs mais aussi les paramètres de celle-ci (labels, etc.). Ici, on définit l'axe des _x_ comme une valeur continue (`:Q`), moyenne de `sum_counts` pour chaque valeur de $y$. Cette moyenne n'est pas indispensable, on aurait pu se contenter d'écrire `sum_counts:Q` voire même `sum_counts` mais c'est pour illustrer la gestion des transformations de données dans `altair`.
4. Le _tooltip_ nous permet de gérer l'interactivité de notre figure.
5. Les propriétés viennent à la fin de notre déclaration pour finaliser la figure.

:::

::: {.content-visible when-profile="en"}

```{python}
#| code-fold: true
#| code-summary: "View the architecture of an Altair figure"
#| echo: true
import altair as alt

color_scale = alt.Scale(domain=[True, False], range=['green', 'red'])

fig2 = (
    alt.Chart(df1)
    .mark_bar() #<1>
    .encode( #<2>
        x=alt.X('average(sum_counts):Q', title='Average count per hour over the selected period'), #<3>
        y=alt.Y('nom_compteur:N', sort='-x', title=''),
        color=alt.Color('top:N', scale=color_scale, legend=alt.Legend(title="Top")),
        tooltip=[
            alt.Tooltip('nom_compteur:N', title='Counter Name'),
            alt.Tooltip('sum_counts:Q', title='Hourly Average')
            ] #<4>
    ).properties( #<5>
        title='The 10 counters with the highest hourly average'
    ).configure_view(
        strokeOpacity=0
    )
)

fig2.interactive()
```

1. First, the _dataframe_ to be used is declared, similar to `ggplot(df)` in `plotnine`. Then, the desired chart type is specified (in this case, a bar chart, `mark_bar` in Altair's grammar).
2. The main layer is defined using `encode`. This can accept either simple column names or more complex constructors, as shown here.
3. A constructor is defined for the x-axis, both to manage value scaling and its parameters (e.g., labels). Here, the x-axis is defined as a continuous value (`:Q`), the average of `sum_counts` for each $y$ value. This average is not strictly necessary; we could have used `sum_counts:Q` or even `sum_counts`, but this illustrates data transformations in `altair`.
4. The _tooltip_ adds interactivity to the chart.
5. Properties are specified at the end of the declaration to finalize the chart.

:::
