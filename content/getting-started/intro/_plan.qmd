::: {.content-visible when-profile="fr"}
# Plan du cours

Ce cours est une introduction aux enjeux de la _data science_ à
travers l'apprentissage du langage `Python`. Comme le terme _"data science"_
l'indique, une partie importante de ce cours est consacrée au travail sur les
données: récupération, structuration, exploration, mise en relation.

C'est l'objet de la première partie du cours ["Manipuler des données"](/content/manipulation/index.qmd) qui sert de fondement au reste du cours. Malheureusement, de nombreuses formations en _data science_, statistiques appliquées ou sciences économiques et sociales, font l'impasse sur cette part du travail des _data scientists_ - qu'on appelle parfois ["data wrangling"](https://en.wikipedia.org/wiki/Data_wrangling) ou [_"feature engineering"_](https://en.wikipedia.org/wiki/Feature_engineering) - qui, en plus de représenter une part importante du temps de travail des _data scientists_, est indispensable pour construire un modèle pertinent.

L'objectif de cette partie est d'illustrer les enjeux liés à la récupération de plusieurs types de sources de données et à leur exploitation par le biais de `Python`. Les exemples seront diversifiés, pour illustrer la richesse des données qui peuvent être analysées avec `Python`: statistiques d'émissions communales de $CO_2$ en France, données de transactions immobilières, diagnostics énergétiques des logements, données de fréquentation des stations vélib...

La deuxième partie est consacrée à la production de visualisations avec `Python`. Après avoir récupéré et nettoyé des données, on désire généralement synthétiser celles-ci par le biais de tableaux, de productions graphiques ou de cartes. Cette partie est une introduction rapide à ce sujet (["Communiquer avec `Python`"](/content/visualisation/index.qmd)). Assez introductive, l'objectif de cette partie est surtout de donner quelques notions qui sont consolidées par la suite.

La troisième partie est consacrée à la modélisation à travers l'exemple fil rouge de la science électorale (["Modéliser avec `Python`"](/content/modelisation/index.qmd)). L'objectif de cette partie est d'illustrer la démarche scientifique du _machine learning_, les choix méthodologiques et techniques afférents et ouvrir vers les enjeux suivants qui seront évoqués dans la suite du cursus universitaire.

La quatrième partie du cours fait un pas de côté pour se consacrer aux enjeux spécifiques liés à l'exploitation des données textuelles. Il s'agit du chapitre d'["Introduction au _Natural Language Processing (NLP)"_ avec `Python`"](/content/NLP/index.qmd). Ce champ de recherche étant particulièrement actif, il ne s'agit que d'une introduction au sujet. Pour aller plus loin, se référer à @RN2020, chapitre 24.

Ce chapitre propose aussi une partie consacrée au contrôle de version avec le logiciel `Git` {{< fa brands git-alt >}} ([Découvrir `Git`](/content/git/index.qmd)). Pourquoi proposer ce contenu dans le cadre d'un cours de `Python` {{< fa brands python >}} ? Car apprendre `Git` permettra de produire de meilleurs codes `Python`, de les échanger, voire même de les tester dans des environnements reproductibles ou de mettre à disposition les résultats en ligne (c'est une utilisation plus avancée, objet du cours de [mise en production](https://ensae-reproductibilite.github.io/)). Ce pas de côté dans l'apprentissage de `Python` est très utile, _a fortiori_ dans un monde où [`Github`](https://github.com/) sert de vitrine et où les entreprises et administrations exigent, à juste titre, que leurs _data scientists_ sachent faire du `Git`.

:::


::: {.content-visible when-profile="en"}
# Course Outline

This course serves as an introduction to the core challenges of _data science_ through learning the `Python` programming language. As the term _“data science”_ implies, a significant portion of the course is dedicated to working directly with data: retrieving it, structuring it, exploring it, and combining it.

These topics are covered in the first part of the course, [“Manipulating Data”](/content/manipulation/index.qmd), which lays the foundation for everything that follows. Unfortunately, many training programs in _data science_, applied statistics, or the economic and social sciences tend to overlook this crucial aspect of a data scientist’s work—often referred to as [“data wrangling”](https://en.wikipedia.org/wiki/Data_wrangling) or [_“feature engineering”_](https://en.wikipedia.org/wiki/Feature_engineering). And yet, not only does it represent a large share of the day-to-day work in data science, it’s also essential for building relevant and accurate models.

The goal of this first section is to highlight the challenges involved in accessing and leveraging different types of data sources using `Python`. The examples are diverse, reflecting the variety of data that can be analyzed with `Python`: municipal $CO_2$ emissions in France, real estate transaction records, housing energy performance diagnostics, bike-sharing data from the Velib system, and more.

The second part of the course focuses on creating visualizations with `Python`. Once your data has been cleaned and processed, you'll typically want to summarize it—through tables, graphs, or maps. This part, [“Communicating with Python”](/content/visualization/index.qmd), offers a concise introduction to the topic. While somewhat introductory, it provides essential concepts that will be reinforced later in the course.

The third part centers on modeling, using electoral science as the main example ([“Modeling with Python”](/content/modelisation/index.qmd)). This section introduces the scientific reasoning behind _machine learning_, explores both methodological and technical choices, and sets the stage for deeper topics addressed later in the program.

The fourth part takes a step back to focus on the specific challenges of working with text data. This is the [“Introduction to Natural Language Processing (NLP) with Python”](/content/NLP/index.qmd) chapter. Given that NLP is a rapidly evolving field, this section serves only as an introduction. For more advanced coverage, see @RN2020, chapter 24.

This chapter also includes a section on version control with `Git` {{< fa brands git-alt >}} ([Discover `Git`](/content/git/index.qmd)). Why include this in a course about `Python` {{< fa brands python >}}? Because learning `Git` helps you write better code, collaborate effectively, and test or share your work in reproducible environments. This is especially valuable in a world where platforms like [`GitHub`](https://github.com/) act as professional showcases—and where companies and public institutions increasingly expect their _data scientists_ to be proficient with `Git`.

For more advanced applications, including deployment and reproducibility, refer to the companion course on [putting data science projects into production](https://ensae-reproductibilite.github.io/).

:::
