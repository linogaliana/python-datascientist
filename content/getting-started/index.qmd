---
title: Introduction
title-en: Introduction
description: "Cette introduction présente l'objectif du cours,les partis-pris
  pédagogiques, le fil conducteur de cet enseignement ainsi que les modalités
  pratiques de celui-ci."
description-en: "This introduction presents the course objective, pedagogical approach,
  the main theme of this of the course, as well as the practical practical details."
image: https://ensae-reproductibilite.github.io/website/egg.jpg
bibliography: ../../reference.bib
---


# Introduction

::: {.important}

:::: {.content-visible when-profile="fr"}
Ce cours rassemble l'ensemble du contenu du cours 
__*Python {{< fa brands python >}} pour la data science*__ que je donne 
à l'[ENSAE](https://www.ensae.fr/courses/python-pour-le-data-scientist-pour-leconomiste/) depuis 2018.
Ce cours était auparavant donné par [Xavier Dupré](http://www.xavierdupre.fr/app/ensae_teaching_cs/helpsphinx3/td_2a.html). 
Environ 170 élèves qui suivent ce cours chaque année. L'année 2024 a permis l'arrivée progressive d'une version anglophone équivalente à
la version française visant à servir de cours d'introduction à la _data science_ pour les instituts statistiques européens
grâce à un [appel à projets européen](https://cros.ec.europa.eu/dashboard/aiml4os). 

Ce site ([pythonds.linogaliana.fr/](https://pythonds.linogaliana.fr)) est le point d'entrée principal du cours. Il centralise
l'ensemble des contenus faits en cours dans le cadre de travaux pratiques ou proposés en complément à des fins de formation en continue. 
Ce cours est _open source_
et j'accueille avec plaisir les suggestions d'amélioration sur [`Github` {{< fa brands github >}}](https://github.com/linogaliana/python-datascientist) ou par le biais des commentaires en bas de chaque page. `Python` étant un langage vivant et très dynamique, les pratiques évoluent et ce cours s'adapte en continu pour tenir compte de l'écosystème mouvant de la _data science_, en essayant néanmoins de distinguer les évolutions pérennes des pratiques des effets de mode.  

Quelques éléments supplémentaires sont disponibles dans
les [slides introductives](https://slidespython.linogaliana.fr/).
Des éléments plus avancés sont présents dans un autre cours consacré 
à la mise en production de projets _data science_
que je donne avec Romain Avouac
en dernière année de l'ENSAE ([ensae-reproductibilite.github.io/website](https://ensae-reproductibilite.github.io/website)).
::::


:::: {.content-visible when-profile="en"}
This course gathers all the content of the course 
__*Python {{< fa brands python >}} for Data Science*__ that I have been teaching 
at [ENSAE](https://www.ensae.fr/courses/python-pour-le-data-scientist-pour-leconomiste/) since 2018.
This course was previously taught by [Xavier Dupré](http://www.xavierdupre.fr/app/ensae_teaching_cs/helpsphinx3/td_2a.html). 
About 170 students take this course each year. In 2024, a gradual introduction of an English version equivalent to the French version began, aimed at serving as an introductory course in _data science_ for European statistical institutes
thanks to a [European call for projects](https://cros.ec.europa.eu/dashboard/aiml4os).

This site ([pythonds.linogaliana.fr/](https://pythonds.linogaliana.fr)) is the main entry point for the course. It centralizes
all the content created during the course for practical work or provided additionally for continuing education purposes. 
This course is _open source_
and I welcome suggestions for improvement on [`Github` {{< fa brands github >}}](https://github.com/linogaliana/python-datascientist) or through the comments at the bottom of each page. As `Python` is a living and dynamic language, practices evolve and this course continuously adapts to the changing ecosystem of _data science_, while trying to distinguish lasting practice evolutions from passing trends.

Additional elements are available in
the [introductory slides](https://slidespython.linogaliana.fr/).
More advanced elements are present in another course dedicated 
to deploying _data science_ projects
that I teach with Romain Avouac
in the final year of ENSAE ([ensae-reproductibilite.github.io/website](https://ensae-reproductibilite.github.io/website)).
::::

:::


::: {.content-visible when-profile="fr"}
:::: {.note collapse="true"}
## Architecture du site web

Ce cours présente
des tutoriels et des exercices complets.
Chaque page est structurée sous la forme
d'un problème concret et présente la
démarche générique pour résoudre ce problème général. 

Vous pouvez naviguer dans l'architecture du site via la table des matières
ou par les liens vers le contenu antérieur ou postérieur à la fin de chaque
page. Certaines parties, notamment celle consacrée à la modélisation,
proposent des exemples fil-rouge pour illustrer la démarche de manière
plus extensive.
::::
:::

:::: {.content-visible when-profile="en"}
::::: {.note collapse="true"}
## Website Architecture

This course features
tutorials and complete exercises.
Each page is structured around
a concrete problem and presents the
generic approach to solving this general problem.

You can navigate the site architecture via the table of contents
or through the links to previous or subsequent content at the end of each
page. Some sections, notably the one dedicated to modeling,
offer extended examples to illustrate the approach in more detail.
::::
:::


::: {.content-visible when-profile="fr"}
`Python`, dont le logo assez reconnaissable prend la forme de {{< fa brands python >}},
est un langage qui a déjà plus de trente ans
mais qui a connu, au cours de la décennie 2010, une
nouvelle jeunesse  du fait de l'engouement autour de
la _data science_.

`Python`, plus que tout autre
langage informatique, réunit des communautés aussi
diverses que des statisticiens, des développeurs, 
des gestionnaires
d'applications ou d'infrastructures informatiques,
des lycéens - `Python` est au programme du bac français 
depuis quelques années - ou des chercheurs 
dans des champs à la fois théoriques et appliqués.

Contrairement
à beaucoup de langages informatiques qui fédèrent
une communauté assez homogène, `Python` est parvenu à réunir
largement grâce à quelques principes centraux : la lisibilité 
du langage, la simplicité à utiliser des modules,
la simplicité à l'associer à des langages plus performants
pour certaines tâches données, l'énorme volume de documentation
disponible en ligne...
Être le deuxième meilleur langage pour réaliser telle ou telle
tâche
peut ainsi être une source de succès lorsque la concurrence ne dispose
pas d'un éventail aussi large d'avantages.

Le succès de `Python`, de par sa nature de 
langage couteau-suisse, est indissociable 
de l'émergence du profil du _data scientist_, profil
capable de s'intégrer à différents niveaux dans la valorisation
de données. 
@davenport2012data, dans la _Harvard Business Review_, 
ont ainsi pu parler du _"boulot le plus sexy du 21e siècle"_
et ont pu, dix ans plus tard, faire un panorama complet de l'évolution
des compétences attendues d'un _data scientist_ dans
la même revue [@davenport2022data]. Ce ne sont d'ailleurs pas que les
_data scientists_ qui ont vocation à pratiquer `Python` ; dans le halo 
des emplois autour de la donnée (_data scientist_, _data engineer_, _ML engineer_...),
`Python` fait office de tour de Babel permettant la communication entre ces
différents profils interdépendants. 

La richesse de `Python` permet de l'utiliser dans toutes les phases du traitement de la donnée, de sa récupération et structuration à partir de 
sources diverses à sa valorisation. 
Par le prisme de la _data science_, nous verrons que `Python` est
un très bon candidat pour assister les _data scientists_ dans tous 
les aspects du travail de données. 

Ce cours introduit différents outils qui permettent de mettre en relation
des données et des théories grâce à `Python`. Néanmoins, ce cours
va au-delà d'une simple introduction au langage et propose
des éléments plus approfondis, notamment sur les dernières 
innovations permises par la _data science_ dans les méthodes de travail.
:::

::: {.content-visible when-profile="en"}
`Python`, with its recognizable logo in the form of {{< fa brands python >}},
is a language that has been around for over thirty years
but has experienced a renaissance during the 2010s
due to the surge in interest around
_data science_.

`Python`, more than any other
programming language, brings together diverse communities such as statisticians, developers,
application or IT infrastructure managers,
high school students - `Python` has been part of the French baccalaureate program 
for several years - and researchers 
in both theoretical and applied fields.

Unlike many programming languages that have a fairly homogeneous community,
`Python` has managed to bring together a wide range of users thanks to a few central principles: the readability 
of the language, the ease of using modules,
the simplicity of integrating it with more performant languages
for specific tasks, the vast amount of documentation
available online...
Being the second best language for performing a given
task
can thus be a source of success when competitors do not have
a similarly broad range of advantages.

The success of `Python`, due to its nature as a 
Swiss Army knife language, is inseparable 
from the emergence of the _data scientist_ profile, a role
capable of integrating at different levels in data valuation.
@davenport2012data, in the _Harvard Business Review_, 
talked about the _"sexiest job of the 21st century"_
and, ten years later, provided a comprehensive overview of the evolving
skills expected of a _data scientist_ in the same review [@davenport2022data]. It's not only _data scientists_
who are expected to use `Python`; within the ecosystem
of data-related jobs (_data scientist_, _data engineer_, _ML engineer_...),
`Python` serves as a Babel tower enabling communication between these
interdependent profiles.

The richness of `Python` allows it to be used in all phases of data processing, from retrieval and structuring from
various sources to its valuation. 
Through the lens of _data science_, we will see that `Python` is
an excellent candidate to assist _data scientists_ in all
aspects of data work.

This course introduces various tools that allow for the connection
of data and theories using `Python`. However, this course
goes beyond a simple introduction to the language and provides
more advanced elements, especially on the latest 
innovations enabled by _data science_ in work methods.
:::


::: {.content-visible when-profile="fr"}
# Pourquoi faire du `Python` {{< fa brands python >}} pour l'analyse de données ?

`Python` est d'abord connu, dans le monde de la _data science_, pour avoir
fourni très tôt les outils utiles à l'entraînement d'algorithmes
de _machine learning_ sur plusieurs types de données. Certes, 
le succès de [`Scikit Learn`](https://scikit-learn.org/stable/)[^scikit],
de [`Tensorflow`](https://www.tensorflow.org/)[^tf] ou plus
récemment de [`PyTorch`](https://pytorch.org/)[^pytorch] dans la communauté
de la *data science* ont beaucoup contribué à l'adoption de `Python`. Cependant,
réduire `Python` à quelques librairies de _machine learning_
serait réducteur tant il s'agit
d'un véritable couteau-suisse pour les *data scientists*,
les *social scientists* ou les économistes. La _success story_ de `Python` 
n'est pas seulement le fait d'avoir proposé des librairies de _machine learning_ à un moment adéquat: ce 
langage dispose de réels atouts pour de nouveaux praticiens de la donnée.  

[^scikit]: Librairie développée par les laboratoires de recherche publique français de l'INRIA depuis 2007.
[^tf]: Librairie initialement utilisée par Google pour leurs besoins internes, celle-ci a été rendue publique en 2015. Bien que moins de moins en moins utilisée, cette librairie a eu une influence importante dans les années 2010 en favorisant l'usage des réseaux de neurone dans la recherche ou pour l'exploitation à des fins opérationnelles. 
[^pytorch]: Librairie développée par Meta depuis 2018 et rattachée depuis 2022 à la [_PyTorch foundation_](https://pytorch.org/foundation).

L'intérêt de `Python` est son rôle central dans un
écosystème plus large autour d'outils puissants, flexibles et *open-source*.
Il appartient, comme le langage {{< fa brands r-project >}}, à cette classe
de langages pouvant servir au quotidien pour des tâches très diversifiées. 
Dans de nombreux domaines explorés dans ce cours, `Python` est, de loin,
le langage informatique proposant l'écosystème le plus complet et le plus simple
d'accès.

Outre le _machine learning_ dont nous avons déjà parlé, `Python` est
incontournable dès lors qu'on désire récupérer des données par le biais 
d'API ou de _web scraping_[^js-webscraping], deux approches que nous explorerons
dans la première partie du cours. Dans les domaines de l'analyse de données tabulaires[^nlp-cv], 
de la publication de contenu web ou de la production de graphiques, `Python` présente un écosystème
de plus en plus similaire à {{< fa brands r-project >}} du fait de l'investissement croissant de [`Posit`](https://posit.co/),
l'entreprise à l'origine des principales librairies {{< fa brands r-project >}} pour la _data science_, dans la
communauté `Python`.

[^js-webscraping]: Dans ces deux domaines, le concurrent le plus sérieux pour `Python`
est `Javascript`. Néanmoins, la communauté autour de ce dernier langage est plus orientée
autour des problématiques de développement web que de _data science_.  

[^nlp-cv]: Les données tabulaires sont des données structurées, organisées,
comme leur nom l'indique, sous forme de tableau permettant de mettre en correspondance
des observations avec des variables. Cette structuration se distingue d'autres types
de données plus complexes: textes libres, images, sons, vidéos... Dans le domaine des données
non structurées, `Python` est le langage d'analyse hégémonique. Dans le domaine des données
tabulaires, l'avantage compétitif de `Python` est moindre, notamment par rapport à {{< fa brands r-project >}}, 
mais ces deux langages proposent un noyau de fonctionnalités assez similaires. Nous aurons
l'occasion de régulièrement faire le parallèle entre ces deux langages
lors des chapitres consacrés à la librairie `Pandas`. 

Néanmoins, il ne s'agit pas, par ces éléments, de rentrer dans la
guéguerre stérile  {{< fa brands r-project >}} vs `Python`. 
Ces deux langages ayant beaucoup plus de points de convergence que de divergence, 
il est très simple de transposer les bonnes
pratiques d'un
langage à l'autre. Il s'agit d'un point qui est développé plus amplement
dans le cours plus avancé que je donne avec Romain Avouac en dernière année
d'ENSAE : [ensae-reproductibilite.github.io/website](https://ensae-reproductibilite.github.io/website). 

A terme, les data scientists et chercheurs en sciences sociales ou 
économie utiliseront de manière presque indifférente, et en alternance, {{< fa brands r-project >}} ou `Python`.
Ce cours
présentera ainsi régulièrement des analogies avec {{< fa brands r-project >}} pour aider les
personnes découvrant `Python`, mais connaissant déjà bien {{< fa brands r-project >}}, à 
mieux comprendre certains messages.
:::

::: {.content-visible when-profile="en"}
# Why Use `Python` {{< fa brands python >}} for Data Analysis?

`Python` is first known in the world of _data science_ for having
provided early on the tools useful for training _machine learning_ algorithms on various types of data. Indeed, 
the success of [`Scikit Learn`](https://scikit-learn.org/stable/)[^scikit],
[`Tensorflow`](https://www.tensorflow.org/)[^tf], or more
recently [`PyTorch`](https://pytorch.org/)[^pytorch] in the *data science* community has greatly contributed to the adoption of `Python`. However,
reducing `Python` to a few _machine learning_ libraries would be limiting, as it is
truly a Swiss Army knife for *data scientists*,
*social scientists*, or economists. The _success story_ of `Python` 
is not just about having provided _machine learning_ libraries at an opportune time: this 
language has real advantages for new data practitioners.  

[^scikit]: Library developed by the French public research laboratories of INRIA since 2007.
[^tf]: Library initially used by Google for their internal needs, it was made public in 2015. Although less used now, this library had a significant influence in the 2010s by promoting the use of neural networks in research and operational applications. 
[^pytorch]: Library developed by Meta since 2018 and affiliated since 2022 with the [_PyTorch foundation_](https://pytorch.org/foundation).

The appeal of `Python` is its central role in a
larger ecosystem of powerful, flexible, and *open-source* tools.
Like {{< fa brands r-project >}}, it belongs to the class
of languages that can be used daily for a wide variety of tasks. 
In many areas explored in this course, `Python` is, by far,
the programming language offering the most complete and accessible ecosystem.

Beyond _machine learning_, which we have already discussed, `Python` is
indispensable when it comes to retrieving data via 
APIs or _web scraping_[^js-webscraping], two approaches that we will explore
in the first part of the course. In the fields of tabular data analysis[^nlp-cv], 
web content publishing, or graphic production, `Python` presents an ecosystem
increasingly similar to {{< fa brands r-project >}} due to the growing investment of [`Posit`](https://posit.co/),
the company behind the major {{< fa brands r-project >}} libraries for _data science_, in the
`Python` community.

[^js-webscraping]: In these two areas, the most serious competitor to `Python`
is `Javascript`. However, the community around this language is more focused
on web development issues than on _data science_.  

[^nlp-cv]: Tabular data are structured data, organized,
as their name indicates, in a table format that allows matching
observations with variables. This structuring differs from other types
of more complex data: free texts, images, sounds, videos... In the domain of unstructured data,
`Python` is the hegemonic language for analysis. In the domain of tabular data, `Python`'s competitive advantage is less pronounced, particularly compared to {{< fa brands r-project >}}, 
but these two languages offer a core set of fairly similar functionalities. We will
regularly draw parallels between these two languages
in the chapters dedicated to the `Pandas` library. 

Nevertheless, these elements are not meant to engage in the
sterile debate of {{< fa brands r-project >}} vs `Python`. 
These two languages have many more points of convergence than divergence, 
making it very simple to transpose good practices from one
language to the other. This is a point that is discussed more extensively
in the advanced course I teach with Romain Avouac in the final year
at ENSAE: [ensae-reproductibilite.github.io/website](https://ensae-reproductibilite.github.io/website). 

Ultimately, data scientists and researchers in social sciences or 
economics will use {{< fa brands r-project >}} or `Python` almost interchangeably and alternately.
This course
will regularly present analogies with {{< fa brands r-project >}} to help
those discovering `Python`, but who are already familiar with {{< fa brands r-project >}}, to 
better understand certain points.
:::


::: {.content-visible when-profile="fr"}
# Objectifs du cours

## Initier à la démarche de la _data science_

Ce cours s’adresse aux praticiens de la _data science_,
discipline entendue ici au sens large comme la __combinaison de techniques issues des mathématiques, de la statistique et de l’informatique pour produire de la connaissance utile à partir de données__.
Comme la _data science_ n’est pas uniquement une discipline scientique mais vise également à fournir un ensemble d’outils pour répondre à des objectifs opérationnels, l'apprentissage du principal outil nécessaire à l'acquisition de connaissances en _data science_, à savoir le langage `Python` est également
l'occasion d'évoquer la démarche scientifique rigoureuse à adopter face à des données. Ce cours a pour objectif de présenter la démarche face à un jeu de données, les problèmes rencontrés, les solutions pour les surmonter et les implications que ces dernières peuvent avoir. Il ne s'agit donc pas que d'un cours sur un outil technique, désincarné de problématiques scientifiques. 
:::

::: {.content-visible when-profile="en"}
# Course Objectives

## Introducing the Approach to _Data Science_

This course is aimed at practitioners of _data science_,
understood here in a broad sense as the __combination of techniques from mathematics, statistics, and computer science to produce useful knowledge from data__.
As _data science_ is not only a scientific discipline but also aims to provide a set of tools to meet operational objectives, learning the main tool necessary for acquiring knowledge in _data science_, namely the `Python` language, is also an opportunity to discuss the rigorous scientific approach to be adopted when working with data. This course aims to present the approach to handling a dataset, the problems encountered, the solutions to overcome them, and the implications of these solutions. It is therefore not just a course on a technical tool, detached from scientific issues.
:::


::: {.content-visible when-profile="fr"}
:::: {.tip}
## Faut-il avoir un _background_ en mathématiques pour ce cours ?

Ce cours présuppose qu'on désire faire un usage de `Python` intense
en données dans un cadre statistique rigoureux. Il ne 
revient que de manière secondaire
sur les fondements statistiques ou algorithmiques
derrière certaines des techniques évoquées, souvent l'objet d'enseignements dédiés, notamment
à l'ENSAE. 

Ne pas connaître ces notions n'empêche ainsi pas de comprendre
le contenu de ce site *web* car les concepts plus avancés sont généralement présentés à part,
dans des encadrés dédiés. 
La facilité d'usage de `Python`
évite de devoir programmer soi-même un modèle, ce qui rend
possible l'application
de modèles dont on n'est pas expert. La connaissance des modèles sera 
plutôt nécessaire dans l'interprétation des résultats.

Pour autant, même s'il est relativement facile d'utiliser des 
modèles complexes
avec `Python`, il est fort utile d'avoir du recul sur ceux-ci avant
de se lancer dans une démarche de modélisation. Il s'agit de l'une des
raisons pour lesquelles la modélisation arrive si tardivement dans ce cours: en
plus de faire appel à des concepts statistiques avancés, il est nécessaire, 
pour produire une modélisation pertinente, d'avoir appréhendé les 
faits stylisés dans nos données. Bien comprendre la structure des données et leur adéquation
avec les hypothèses d'un modèle est indispensable pour construire une modélisation
de qualité.
::::
:::

::: {.content-visible when-profile="en"}
:::: {.tip}
## Is a Mathematical Background Required for This Course?

This course assumes a desire to use `Python` intensively for data analysis within a rigorous statistical framework. It only briefly touches on the statistical or algorithmic foundations behind some of the techniques discussed, which are often the subject of dedicated teachings, particularly at ENSAE.

Not knowing these concepts does not prevent understanding the content of this website, as more advanced concepts are generally presented separately in dedicated boxes. The ease of using `Python` avoids the need to program a model oneself, which makes it possible to apply models without being an expert. Knowledge of models will be more necessary for interpreting results.

However, even though it is relatively easy to use complex models with `Python`, it is very useful to have some background on them before embarking on a modeling approach. This is one of the reasons why modeling comes later in this course: in addition to involving advanced statistical concepts, it is necessary to have understood the stylized facts in our data to produce relevant modeling. A thorough understanding of data structure and its alignment with model assumptions is essential for building high-quality models.
::::

:::

## Reproductibilité

::: {.content-visible when-profile="fr"}
Ce cours donne une place centrale à 
la notion de reproductibilité. Cette exigence se traduit de diverses
manières dans cet enseignement, 
en premier lieu en permettant que tous
les exemples et exercices de ce cours soient testés par le biais 
de _notebooks_ `Jupyter`[^nb]. 

L'ensemble du contenu du site *web* est reproductible dans des environnements
informatiques divers. Il est bien sûr possible de copier-coller les morceaux
de code présents dans ce site, grâce au bouton {{< fa solid clipboard >}} présent au dessus
des exemples de code:

```{python}
x = "Essayez de me copier-coller" #<1>
```
1. Cliquez sur le bouton {{< fa solid clipboard >}} pour copier ce contenu et le coller ailleurs.


[^nb]: Un _notebook_ est un environnement interactif qui permet d'écrire et d'exécuter du code en direct. Il combine, dans un seul document, du texte, du code qui peut être exécuté et dont les sorties s'affichent après calculs. C'est extrêmement pratique pour l'apprentissage du langage `Python`. Pour plus de détails, consultez la [documentation officielle de Jupyter](https://jupyter.org/documentation).

Néanmoins, comme ce site présente de nombreux exemples, les allers et retours 
entre un environnement de test de `Python` et celui-ci pourraient être
pénibles. Chaque chapitre est donc facilement récupérable sous forme de
_notebook_ `Jupyter` grâce à des boutons au début de chaque page. 
Voici, par exemple, ces boutons pour le tutoriel `Numpy` :
:::

::: {.content-visible when-profile="en"}

This course places a central emphasis on the concept of reproducibility. This requirement is reflected in various ways throughout this teaching, primarily by ensuring that all examples and exercises in this course can be tested using `Jupyter` notebooks[^nb]. 

The entire content of the website is reproducible in various computing environments. It is, of course, possible to copy and paste the code snippets present on this site, using the {{< fa solid clipboard >}} button above the code examples:

```{python}
x = "Try to copy-paste me" #<1>
```
1. Click on the {{< fa solid clipboard >}} button to copy this content and paste it elsewhere.


However, since this site presents many examples, the back-and-forth between a Python testing environment and this site could be cumbersome. Each chapter is therefore easily retrievable as a `Jupyter` notebook via buttons at the beginning of each page. For example, here are those buttons for the `Numpy` tutorial:

:::

{{< badges
    fpath="/content/manipulation/01_numpy.qmd"
    printMessage="false"
>}}

::: {.content-visible when-profile="fr"}
Les recommandations concernant 
les environnements à privilégier pour utiliser
ces notebooks sont reportées au prochain chapitre. 

L'exigence de reproductibilité se manifeste également 
dans le choix des exemples pris pour ce cours. 
L'ensemble du contenu de ce site s'appuie sur des données
ouvertes, qu'il s'agisse de données françaises (principalement
issues de la plateforme
centralisatrice [`data.gouv`](https://www.data.gouv.fr) ou du site
_web_ de l'[Insee](https://www.insee.fr)) ou de données
américaines. Les résultats sont donc reproductibles pour quelqu'un
disposant d'un environnement identique[^environnement-identique]. 

[^environnement-identique]: Le fait d'ouvrir les chapitres sous la forme de _notebooks_ dans des environnements standardisés, ce qui sera proposé à partir du prochain chapitre, permet d'assurer que vous disposiez d'un environnement contrôlé. Les installations personnelles de `Python` ont toutes les chances d'avoir subies des bidouillages modifiant votre environnement et pouvant provoquer des erreurs inattendues et difficiles à comprendre: ce n'est donc pas un usage recommandé pour ce cours. Comme vous pourrez le découvrir dans le prochain chapitre, les environnements _cloud_ offrent un confort en ce qui concerne la standardisation des environnements. 

:::: {.note}
Des chercheurs américains ont pu parler de crise de la reproductibilité dans le domaine
du _machine learning_ [@Reproducibilitycrisis]. Les dérives de l'écosystème de 
la publication scientifique et les enjeux économiques derrière les publications 
académiques dans le domaine du _machine learning_ ont une place privilégiée parmi
les facteurs pouvant l'expliquer.

Néanmoins, l'enseignement universitaire porte également une responsabilité
dans ce domaine. Les étudiants et chercheurs ne sont pas formés à ces sujets et s'ils
n'adoptent pas cette exigence tôt dans leur parcours, ils n'y seront plus forcément incités 
ultérieurement. Pour cette raison, en plus de former à `Python` {{< fa brands python >}} et à la _data science_, ce cours
introduit à l'usage du
logiciel de contrôle de version `Git` {{< fa brands git-alt >}} dans une partie dédiée.
Tous les projets des élèves doivent être _open source_, ce qui est l'une des meilleures manières,
pour un enseignant, de trouver une consigne pour que les élèves produisent un code de qualité.  
::::
:::

::: {.content-visible when-profile="en"}

Recommendations regarding 
the preferred environments for using
these notebooks are deferred to the next chapter.

The requirement for reproducibility is also evident 
in the choice of examples used in this course. 
All content on this site relies on open data, whether it is French data (mainly
from the centralizing platform [`data.gouv`](https://www.data.gouv.fr) or the
website of [Insee](https://www.insee.fr)) or American data. Results are therefore reproducible for someone
with an identical environment[^identical-environment].

[^identical-environment]: Opening chapters as _notebooks_ in standardized environments, as will be proposed starting from the next chapter, ensures that you have a controlled environment. Personal installations of `Python` are likely to have undergone modifications that can alter your environment and cause unexpected and hard-to-understand errors: this is not a recommended use for this course. As you will discover in the next chapter, _cloud_ environments offer comfort regarding environment standardization.

:::: {.note}
American researchers have discussed a reproducibility crisis in the field
of _machine learning_ [@Reproducibilitycrisis]. Issues with the scientific 
publishing ecosystem and the economic stakes behind academic publications 
in the field of _machine learning_ are prominent factors that may explain this.

However, academic teaching also bears a responsibility
in this area. Students and researchers are not trained in these topics, and if they
do not adopt this requirement early in their careers, they may not be encouraged to do so later. For this reason, in addition to training in `Python` {{< fa brands python >}} and _data science_, this course
introduces the use of
the version control software `Git` {{< fa brands git-alt >}} in a dedicated section.
All student projects must be _open source_, which is one of the best ways
for a teacher to ensure that students produce quality code.
::::

:::


::: {.content-visible when-profile="fr"}
## Évaluation

Les élèves de l'ENSAE valident le cours grâce à
un projet approfondi. 
Les éléments relatifs à l'évaluation du cours, ainsi qu'une
liste des projets déjà effectués, sont disponibles dans la
Section [Évaluation](/content/annexes/evaluation).
:::

::: {.content-visible when-profile="en"}
## Assessment

ENSAE students validate the course through
an in-depth project. 
Details about the course assessment, as well as a
list of previously completed projects, are available in the
[Assessment](annexes/evaluation) section.
:::


::: {.content-visible when-profile="fr"}
# Plan du cours

Ce cours est une introduction aux enjeux de la _data science_ à 
travers l'apprentissage du langage `Python`. Comme le terme _"data science"_
l'indique, une partie importante de ce cours est consacrée au travail sur les 
données: récupération, structuration, exploration, mise en relation. C'est l'objet de la première
partie du cours
["Manipuler des données"](/content/manipulation/index.qmd) qui sert de fondement au reste du cours.
Malheureusement, de nombreuses formations en _data science_, statistiques appliquées ou sciences économiques et sociales,
font l'impasse sur
cette part du travail des _data scientists_ qu'on appelle parfois ["data wrangling"](https://en.wikipedia.org/wiki/Data_wrangling)
ou [_"feature engineering"_](https://en.wikipedia.org/wiki/Feature_engineering). 
qui, en plus de représenter une part importante du temps de travail des _data scientists_, est indispensable 
pour construire un modèle pertinent.

L'objectif de cette partie est d'illustrer les enjeux liés à la récupération
de plusieurs types de sources de données et à leur exploitation par le biais de `Python`. Les exemples seront diversifiés, pour illustrer la richesse des données qui peuvent être analysées avec `Python`: statistiques d'émissions communales de $CO_2$, données de transactions immobilières, diagnostics énergétiques des logements, données de fréquentation des stations vélib...

La deuxième partie est consacrée à la production de visualisations avec `Python`. Après avoir récupéré et nettoyé des données, 
on désire généralement synthétiser celles-ci par le biais de tableaux, de productions graphiques ou de cartes. Cette partie est une introduction rapide à ce sujet (["Communiquer avec `Python`"](/content/visualisation/index.qmd)). Assez introductive, l'objectif de cette partie est surtout de donner quelques notions qui sont consolidées par la suite. 

La troisième partie est consacrée à la modélisation à travers l'exemple fil rouge de la science électorale (["Modéliser avec `Python`"](/content/modelisation/index.qmd)). L'objectif de cette partie est d'illustrer la démarche scientifique du _machine learning_, les choix méthodologiques et techniques afférents et ouvrir vers les enjeux suivants qui seront évoqués dans la suite du cursus universitaire. 

La quatrième partie du cours fait un pas de côté pour se consacrer aux enjeux spécifiques liés à l'exploitation des données textuelles. Il s'agit du chapitre d'["Introduction au _Natural Language Processing (NLP)"_ avec `Python`"](/content/NLP/index.qmd). Ce champ de recherche étant particulièrement actif, il ne s'agit que d'une introduction au sujet. Pour aller plus loin, se référer à @RN2020, chapitre 24.
:::

::: {.content-visible when-profile="en"}
# Course Outline

This course is an introduction to the issues of _data science_ through the learning of the `Python` language. As the term _"data science"_ suggests, a significant part of this course is dedicated to working with data: retrieval, structuring, exploration, and linking. This is the subject of the first part of the course
["Manipulating Data"](/content/manipulation/index.qmd), which serves as the foundation for the rest of the course. Unfortunately, many programs in _data science_, applied statistics, or social and economic sciences, overlook this part of the data scientist's work sometimes referred to as ["data wrangling"](https://en.wikipedia.org/wiki/Data_wrangling)
or [_"feature engineering"_](https://en.wikipedia.org/wiki/Feature_engineering), which, in addition to being a significant portion of the data scientist's work, is essential for building a relevant model.

The goal of this part is to illustrate the challenges related to retrieving various types of data sources and their exploitation using `Python`. The examples will be varied to illustrate the richness of the data that can be analyzed with `Python`: municipal $CO_2$ emission statistics, real estate transaction data, energy diagnostics of housing, Vélib station attendance data...

The second part is dedicated to producing visualizations with `Python`. After retrieving and cleaning data, one generally wants to synthesize it through tables, graphics, or maps. This part is a brief introduction to this topic (["Communicating with `Python`"](/content/visualisation/index.qmd)). Being quite introductory, the goal of this part is mainly to provide some concepts that will be consolidated later.

The third part is dedicated to modeling through the example of electoral science (["Modeling with `Python`"](/content/modelisation/index.qmd)). The goal of this part is to illustrate the scientific approach of _machine learning_, the related methodological and technical choices, and to open up to the following issues that will be discussed in the rest of the university curriculum.

The fourth part of the course takes a step aside to focus on specific issues related to the exploitation of textual data. This is the chapter on ["Introduction to _Natural Language Processing (NLP)_ with `Python`"](/content/nlp/index.qmd). This research field being particularly active, it is only an introduction to the subject. For further reading, refer to @RN2020, chapter 24.
:::

::: {.content-visible when-profile="fr"}
# Références {-}
:::

::: {.content-visible when-profile="en"}
# References {-}
:::

::: {#refs}
:::

