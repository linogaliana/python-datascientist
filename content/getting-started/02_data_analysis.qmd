---
title: "D√©marche √† adopter face √† un jeu de donn√©es"
title-en: "How to deal with a data set"
bibliography: ../../reference.bib
description: |
  Quelques √©l√©ments pour adopter une d√©marche
  scientifique et √©thique face √† un 
  jeu de donn√©es. 
description-en: |
  A few guidelines for adopting a scientific
  and ethical approach to 
  data sets. 
image: https://minio.lab.sspcloud.fr/lgaliana/generative-art/mise-en-prod/babypython.png
categories:
  - Tutoriel
  - Rappels
---

::: {.content-visible when-profile="fr"}
:::: {.tip}
## Objet de ce chapitre

- D√©marche scientifique et technique √† adopter face √† un nouveau jeu de donn√©es ;
- D√©couvrir les principaux fournisseurs de donn√©es en France et les moyens d'acc√©der √† celles-ci ;
- Discuter des enjeux √©thiques derri√®re le travail des _data scientists_ et des chercheurs en science quantitative
::::
:::

::: {.content-visible when-profile="en"}
:::: {.tip}
## Purpose of this chapter

- Scientific and technical approach to adopt when faced with a new dataset;
- Discover the main data providers in France and how to access their data;
- Discuss the ethical issues behind the work of data scientists and researchers in quantitative science
::::
:::


::: {.content-visible when-profile="fr"}
Pour bien d√©buter des travaux sur une base de donn√©es,
il est n√©cessaire de se poser quelques questions de bon sens
et de suivre une d√©marche scientifique dont un certain
nombre de gestes prennent une forme assez simple.

Dans un projet sur des jeux de donn√©es, on peut sch√©matiquement
s√©parer les √©tapes en quatre grandes parties :

1. La r√©cup√©ration et structuration des donn√©es ;
2. L'analyse de celle-ci, notamment la production de statistiques descriptives indispensables pour orienter les exploitations ult√©rieures ;
3. La mod√©lisation ;
4. La valorisation finale des √©tapes pr√©c√©dentes et la communication de r√©sultats ou la mise en ≈ìuvre d'une cha√Æne de production.

Ce cours explore ces diff√©rentes √©tapes de mani√®re progressive gr√¢ce √†
l'√©cosyst√®me `Python` qui est tr√®s complet. Chaque chapitre du cours
peut √™tre vu comme une mani√®re de progresser dans ce fil conducteur. 
Dans ce chapitre, nous allons plut√¥t mettre en avant quelques r√©flexions
√† avoir avant de se lancer dans chaque √©tape.
:::

::: {.content-visible when-profile="en"}
To begin working with a database effectively,
it's essential to ask some common-sense questions
and follow a scientific approach, where some steps are quite straightforward.

In a data project, the steps can be schematically divided into four main parts:

1. Data retrieval and structuring;
2. Analysis of the data, including the production of descriptive statistics essential for guiding further explorations;
3. Modeling;
4. Finalizing and communicating results from the previous steps or implementing a production pipeline.

This course explores these different stages progressively using the comprehensive `Python` ecosystem. Each chapter of the course can be seen as a way to advance through this process. 
In this chapter, we will focus on some considerations to make before starting each stage.
:::


::: {.content-visible when-profile="fr"}

# Lors de la r√©cup√©ration des donn√©es

## R√©flexions √† mener en amont

La phase de constitution de son jeu de donn√©es sous-tend tout le projet qui suit.

La premi√®re question √† se poser est
_"de quelles donn√©es ai-je besoin pour r√©pondre √† ma probl√©matique ?"_.
Cette probl√©matique pourra √©ventuellement 
√™tre affin√©e en fonction des besoins mais les travaux sont g√©n√©ralement
de meilleure qualit√© lorsque la probl√©matique am√®ne √† la r√©flexion sur les donn√©es
disponibles plut√¥t que l'inverse. 

Ensuite, _"qui produit et met √† disposition ces donn√©es" ?_
_Les sources disponibles sur internet sont-elles fiables ?_
Les sites d'_open data_ gouvernementaux sont par exemple assez fiables mais autorisent parfois l'archivage de donn√©es restructur√©es par des tiers et non des producteurs officiels. A l'inverse, sur `Kaggle` ou sur `Github` la source de certains jeux de donn√©es n'est pas trac√©e ce qui rend compliqu√©e la confiance sur la qualit√© de la donn√©e

Une fois identifi√© une ou plusieurs sources de donn√©es,
_est-ce que je peux les compl√©ter avec d'autres donn√©es ?_
(dans ce cas, faire attention √† avoir des niveaux de granularit√© ad√©quats).
:::

::: {.content-visible when-profile="en"}

# When retrieving data

## Considerations to make in advance

The phase of constructing your dataset underpins the entire subsequent project.

The first question to ask is, _"What data do I need to address my problem?"_
This problem might be refined depending on needs, but work is generally of higher quality when the problem prompts reflection on the available data rather than the other way around.

Next, _"Who produces and provides this data?"_
_Are the sources available on the internet reliable?_
Government open data sites are generally quite reliable but sometimes allow the archiving of data restructured by third parties rather than official producers. Conversely, on `Kaggle` or `Github`, the source of some datasets is not tracked, making it difficult to trust the quality of the data.

Once one or more data sources are identified, _"Can I supplement them with additional data?"_
(In this case, be careful to ensure appropriate levels of granularity).
:::

::: {.content-visible when-profile="fr"}

## Qui produit et diffuse des donn√©es en France ?

Lors de la phase de recherche de jeux de donn√©es, il est essentiel de conna√Ætre les principaux acteurs qui produisent et diffusent des donn√©es. Voici un panorama de l'√©cosyst√®me fran√ßais de la diffusion de donn√©es. 

### L'Insee et la statistique publique

En premier lieu, les __instituts statistiques__ comme l'Insee (Institut National de la Statistique et des √âtudes √âconomiques) en France ainsi que les __services statistiques minist√©riels (SSM)__[^ssp] produisent des donn√©es fiables sur de nombreuses probl√©matiques socio√©conomiques. Celles-ci sont des statistiques agr√©g√©es pouvant, pour certaines sources de donn√©es locales, √™tre tr√®s fines. Ces statistiques sont produites par le biais d'enqu√™tes, de donn√©es individuelles issues de fichiers administratifs dont l'acc√®s est permis par une [loi de 1951](https://www.insee.fr/fr/information/1300616) (voir la partie sur la r√©glementation des donn√©es üëáÔ∏è) ou par l'exploitation de sources de donn√©es alternatives, issues par exemple de producteurs priv√©s.

L'Insee produit √©galement des √©tudes approfondies exploitant les donn√©es qu'elle produit et qu'il est pertinent de lire lorsqu'on d√©couvre une probl√©matique socio√©conomique.

Parmi les _best-sellers_ des sources de donn√©es disponibles sur le site [insee.fr](https://www.insee.fr/fr/accueil), on retrouve les donn√©es du recensement, les chiffres du ch√¥mage, le taux d'inflation, le PIB, le fichier des pr√©noms. Toutes ces sources mesur√©es par l'Insee, qui sont si utilis√©es dans le d√©bat public, ont g√©n√©ralement des d√©finitions internationales pour permettre des comparaisons dans le temps et l'espace.  


[^ssp]: Le service statistique public fran√ßais est constitu√© de l‚ÄôInsee et des 16 services statistiques minist√©riels (SSM). Ces derniers sont les directions des minist√®res ayant des missions de production et de diffusion de service public. Contrairement aux autres directions des minist√®res auxquels les SSM sont rattach√©s, ils n'ont pas vocation exclusivement √† appuyer l'action publique de mani√®re op√©rationnelle mais surtout √† donner des √©l√©ments quantitatifs utiles au d√©bat public et √† l'action publique. 

Dans ce cours, nous utiliserons quelques fois des sources diffus√©es par l'Insee pour avoir des donn√©es contextuelles √† un niveau agr√©g√©.
:::

::: {.content-visible when-profile="en"}

## Who produces and disseminates data in France?

During the phase of searching for datasets, it is essential to know the key players who produce and disseminate data. Here is an overview of the French data dissemination ecosystem.

### Insee and public statistics administrations

Firstly, __statistical institutes__ like Insee (Institut National de la Statistique et des √âtudes √âconomiques) in France, as well as __ministerial statistical services (SSM)__[^ssp], produce reliable data on various socioeconomic issues. These are aggregated statistics that, for some local data sources, can be very detailed. These statistics are produced through surveys, individual data from administrative files accessible under a [1951 law](https://www.insee.fr/fr/information/1300616) (see the section on data regulation üëáÔ∏è), or through the exploitation of alternative data sources, such as those from private producers.

Insee also produces in-depth studies utilizing the data it generates, which are relevant to read when exploring a socioeconomic issue.

Among the _best-sellers_ of the data sources available on [insee.fr](https://www.insee.fr/fr/accueil) are census data, unemployment figures, inflation rate, GDP, and the names database. All these sources measured by Insee, which are so widely used in public debate, generally have international definitions to allow comparisons over time and space.

[^ssp]: The French public statistical service consists of Insee and the 16 ministerial statistical services (SSM). These are the departments of ministries responsible for the production and dissemination of public service data. Unlike other departments to which the SSMs are attached, they are not solely focused on supporting public action operationally but primarily on providing quantitative elements useful for public debate and public action.

In this course, we will occasionally use data sources disseminated by Insee to provide contextual data at an aggregated level.
:::

::: {.content-visible when-profile="fr"}

### L'IGN 

L'IGN (Institut National de l'Information G√©ographique et Foresti√®re) est un autre acteur important qui produit et diffuse des donn√©es g√©ographiques et cartographiques de haute qualit√© en France. Ces donn√©es couvrent divers aspects du territoire national, allant des cartes topographiques aux informations sur l'occupation des sols, et sont essentielles pour des projets ayant une dimension g√©ographique.

Nous utiliserons fr√©quemment certains fonds de carte produit par l'IGN lors de nos chapitres d'analyse spatial.
:::

::: {.content-visible when-profile="en"}

### IGN for geographical datasets

IGN (Institut National de l'Information G√©ographique et Foresti√®re) is another major player that produces and disseminates high-quality geographic and cartographic data in France. This data covers various aspects of the national territory, from topographic maps to land use information, and is essential for projects with a geographic dimension.

We will frequently use some of the map backgrounds produced by IGN in our spatial analysis chapters.
:::


::: {.content-visible when-profile="fr"}

### Les autres administrations et collectivit√©s locales

Contrairement aux administrations de la statistique publique, le reste de l'administration fran√ßaise n'a pas comme mission principale de diffuser du savoir statistique. N√©anmoins, les donn√©es peuvent occuper une place importante dans les processus internes de ces administrations. 

Par exemple, la DGFiP (Direction G√©n√©rale des Finances Publiques) dispose d'√©norm√©ment de donn√©es issues des d√©clarations fiscales des Fran√ßais. Contrairement √† l'Insee qui va s'int√©resser √† ces donn√©es pour, par exemple, avoir une vision exhaustive des in√©galit√©s √©conomiques ou de la situation des entreprises fran√ßaises, la DGFiP s'y int√©resse √† des fins de gestion r√©galienne de l'administration et se posera des questions telles que _"les ressources correspondent-elles aux attentes et permettront-elles de financer le budget de l'Etat ?"_. 

Les collectivit√©s locales mettent √† disposition un large √©ventail de donn√©es locales. Ces donn√©es couvrent divers domaines dans leur champ de comp√©tence : am√©nagement, infrastructures, budget... Elles sont tr√®s pratiques pour des √©tudes sp√©cifiques √† une r√©gion ou une ville, en compl√©ment de donn√©es locales fournies par d'autres acteurs, notamment l'Insee. Par exemple, dans le cadre de ce cours, nous utiliserons √† plusieurs reprises le [portail Open Data de la Ville de Paris](https://opendata.paris.fr/pages/home/).
:::

::: {.content-visible when-profile="en"}

### Other central administrations and local authorities

Unlike public statistical administrations, the rest of the French administration does not primarily aim to disseminate statistical knowledge. However, data can play an important role in the internal processes of these administrations.

For example, the DGFiP (Direction G√©n√©rale des Finances Publiques) holds a vast amount of data from French taxpayers' tax declarations. Unlike INSEE, which uses this data to gain an exhaustive view of economic inequalities or the situation of French businesses, DGFiP focuses on the administrative management aspect and asks questions such as, _"Do the resources align with expectations and will they finance the state's budget?"_

Local authorities provide a wide range of local data. This data covers various areas within their scope: urban planning, infrastructure, budget... They are very useful for studies specific to a region or city, complementing local data provided by other actors, including INSEE. For instance, in this course, we will frequently use the [Open Data portal of the City of Paris](https://opendata.paris.fr/pages/home/).
:::

::: {.content-visible when-profile="fr"}

:::: {.note}
## La DINUM et le portail [data.gouv](https://www.data.gouv.fr/fr/)

La DINUM (Direction Interminist√©rielle du Num√©rique) est une administration centrale en France charg√©e de coordonner les initiatives num√©riques au sein de l'√âtat. Elle joue un r√¥le crucial dans la diffusion des donn√©es publiques √† travers la plateforme [data.gouv](https://www.data.gouv.fr/fr/) qui centralise et met √† disposition des milliers de jeux de donn√©es produits par les administrations publiques, facilitant ainsi leur r√©utilisation pour des projets de recherche, d'innovation, ou d'int√©r√™t public.
::::

:::

::: {.content-visible when-profile="en"}

:::: {.note}
## The [data.gouv](https://www.data.gouv.fr/fr/) portal: a central piece of French open data ecosystem

DINUM (Interministerial Digital Department) is a central administration in France responsible for coordinating digital initiatives within the state. It plays a crucial role in disseminating public data through the [data.gouv](https://www.data.gouv.fr/fr/) platform, which centralizes and provides access to thousands of datasets produced by public administrations, thus facilitating their reuse for research, innovation, or public interest projects.
::::

:::

::: {.content-visible when-profile="fr"}

### Les projets contributifs et _crowd-sourc√©s_

Des initiatives comme OpenStreetMap, Wikidata, ou OpenFoodFacts reposent sur la contribution volontaire de nombreux utilisateurs pour produire et maintenir des jeux de donn√©es. Ces projets sont particuli√®rement utiles pour obtenir des donn√©es g√©ospatiales, encyclop√©diques ou sur les produits de consommation, respectivement.

### Les donn√©es issues d'acteurs priv√©s

Du fait de la num√©risation de l'√©conomie, de nombreuses entreprises collectent des donn√©es sur leurs utilisateurs ou clients dans le cadre de leurs activit√©s. Ces donn√©es, souvent volumineuses et vari√©es, peuvent √™tre exploit√©es √† de multiples fins, notamment pour des analyses de march√© ou des √©tudes comportementales. L'exploitation de la donn√©e est certes le coeur de m√©tier d'une partie des entreprises du num√©rique (notamment les r√©seaux sociaux) mais de nombreux acteurs exploitent en interne leurs donn√©es clients. En Europe, le cadre r√©glementaire est, depuis 2018, le [RGPD (R√®glement g√©n√©ral sur la protection des donn√©es)](https://www.cnil.fr/fr/comprendre-le-rgpd) qui d√©finit les conditions de collecte, stockage et exploitation de donn√©es personnelles.

Certaines entreprises peuvent √©galement mettre √† disposition ces donn√©es, ou une version agr√©g√©e, par le biais de projets de recherche ou d'acc√®s via des API. Celles-ci peuvent √™tre int√©ressantes pour r√©pondre √† des questions cibl√©es, √† condition de ne pas oublier qu'elles sont produites √† partir d'une certaine client√®le et que l'extrapolation √† la population g√©n√©rale n'est pas toujours possible.
:::

::: {.content-visible when-profile="en"}

### Contributory and crowd-sourced datasets

Initiatives such as OpenStreetMap, Wikidata, and OpenFoodFacts rely on the voluntary contributions of many users to produce and maintain datasets. These projects are particularly useful for obtaining geospatial data, encyclopedic information, or data on consumer products, respectively.

### Data from private sector

Due to the digitization of the economy, many companies collect data on their users or customers as part of their activities. This data, often large and varied, can be used for various purposes, including market analysis or behavioral studies. While data exploitation is indeed central to some digital companies (particularly social networks), many actors internally exploit their customer data. In Europe, the regulatory framework since 2018 is the [GDPR (General Data Protection Regulation)](https://www.cnil.fr/fr/comprendre-le-rgpd), which defines the conditions for collecting, storing, and using personal data.

Some companies may also make this data, or an aggregated version of it, available through research projects or access via APIs. These can be useful for answering specific questions, provided one remembers that they are produced from a particular customer base and that extrapolation to the general population is not always possible.
:::


::: {.content-visible when-profile="fr"}

## Structuration des donn√©es

Vient ensuite la phase de mise en forme et nettoyage des jeux de donn√©es r√©cup√©r√©s. Cette √©tape est primordiale et est g√©n√©ralement celle qui mobilise le plus de temps. Pendant quelques ann√©es, on parlait de _data cleaning_. Cependant, cela a pu, implicitement, laisser penser qu'il s'agissait d'une t√¢che subalterne. On commence √† lui pr√©f√©rer le concept de _data wrangling_ ou _feature engineering_ qui souligne bien qu'il s'agit d'une comp√©tence qui n√©cessite beaucoup de comp√©tences.

Un jeu de donn√©es propre est un jeu de donn√©es dont la structure est ad√©quate et n'entra√Ænera pas d'erreur, visible ou non, lors de la phase d'analyse. Comme nous aurons l'occasion de le d√©finir dans les premiers chapitres de la [partie Manipulation](/content/manipulation/index.qmd), l'horizon id√©al de structuration est une donn√©e _tidy_, c'est-√†-dire organis√©e sous forme de tableau bien structur√©.

Voici quelques caract√©ristiques d'un jeu de donn√©es propre :

- les __informations manquantes__ sont bien comprises et trait√©es. `Numpy` et `Pandas` proposent un certain formalisme sur le sujet qu'il est utile d'adopter en rempla√ßant par `NaN` les observations manquantes. Cela implique de faire attention √† la mani√®re dont certains producteurs codent les valeurs manquantes : certains ont la facheuse tendance √† √™tre imaginatifs sur les codes pour valeurs manquantes : _"-999"_, _"XXX"_, _"NA"_
- les __variables servant d'identifiants__ sont bien les m√™mes d'une table √† l'autre (notamment dans le cas de jointures) : m√™me format, m√™me modalit√©s...
- pour des __variables textuelles__, qui peuvent √™tre mal renseign√©es, avoir corrig√© les √©ventuelles fautes (ex "Rolland Garros" -> "Roland Garros")
- cr√©er des variables qui synth√©tisent l'information dont vous avez besoin
- supprimer les √©l√©ments inutiles (colonne ou ligne vide)
- renommer les colonnes avec des noms compr√©hensibles
:::

::: {.content-visible when-profile="en"}

## Data structuring

Next comes the phase of formatting and cleaning the retrieved datasets. This step is crucial and is generally the one that requires the most time. For several years, the term _data cleaning_ was used. However, this may have implicitly suggested that it was a subordinate task. The concept of _data wrangling_ or _feature engineering_ is now preferred, highlighting that it is a skill that requires significant expertise.

A clean dataset is one where the structure is appropriate and will not cause errors, visible or not, during the analysis phase. As we will define in the early chapters of the [Manipulation section](/content/manipulation/index.qmd), the ideal structuring horizon is _tidy_ data, i.e., organized in a well-structured table.

Here are some characteristics of a clean dataset:

- __missing information__ is well understood and addressed. `Numpy` and `Pandas` offer formalism on this topic that it is useful to adopt by replacing missing observations with `NaN`. This involves paying attention to how some producers code missing values: some have a tendency to be imaginative with codes for missing values: _"-999"_, _"XXX"_, _"NA"_
- __identifier variables__ are the same across tables (especially in the case of joins): same format, same categories...
- for __textual variables__, which can be poorly recorded, correct any possible errors (e.g., "Rolland Garros" -> "Roland Garros")
- create variables that synthesize the information you need
- remove unnecessary elements (empty columns or rows)
- rename columns with understandable names
:::


::: {.content-visible when-profile="fr"}

# Lors de l'analyse descriptive

Une fois les jeux de donn√©es nettoy√©s, vous pouvez plus sereinement √©tudier l'information pr√©sente dans les donn√©es. Cette phase et celle du nettoyage ne sont pas s√©quentielles, en r√©alit√© vous devrez r√©guli√®rement passer de votre nettoyage √† quelques statistiques descriptives qui vous montreront un probl√®me, retourner au nettoyage etc.

Les questions √† se poser pour _"challenger"_ le jeu de donn√©es :

- Est-ce que mon √©chantillon est bien __repr√©sentatif__ de ce qui m'int√©resse ? N'avoir que 2000 communes sur les 35000 n'est pas n√©cessairement un probl√®me mais il est bon de s'√™tre pos√© la question.
- Est-ce que les __ordres de grandeur__ sont bons ? Pour cela, confronter vos premi√®res statistiques descriptives √† vos recherches internet. Par exemple trouver que les maisons vendues en France en 2020 font en moyenne 400 m¬≤ n'est pas un ordre de grandeur r√©aliste.
- Est-ce que je __comprends toutes les variables__ de mon jeu de donn√©es ? Est-ce qu'elles se "comportent" de la bonne fa√ßon ? √Ä ce stade, il est parfois utile de se faire un dictionnaire de variables (qui explique comment elles sont construites ou calcul√©es). On peut √©galement mener des √©tudes de __corr√©lation__ entre nos variables.
- Est-ce que j'ai des __outliers__, i.e. des valeurs aberrantes pour certains individus ? Dans ce cas, il faut d√©cider quel traitement on leur apporte (les supprimer, appliquer une transformation logarithmique, les laisser tel quel) et surtout bien le justifier.
- Est-ce que j'ai des __premiers grands messages__ sortis de mon jeu de donn√©es ? Est-ce que j'ai des r√©sultats surprenants ? Si oui, les ai-je creus√©s suffisamment pour voir si les r√©sultats tiennent toujours ou si c'est √† cause d'un souci dans la construction du jeu de donn√©es (mal nettoy√©es, mauvaise variable...)
:::

::: {.content-visible when-profile="en"}

# During descriptive analysis

Once the datasets are cleaned, you can more confidently study the information present in the data. This phase and the cleaning phase are not sequential; in reality, you will regularly move from cleaning to some descriptive statistics that reveal issues, and then back to cleaning, etc.

Questions to ask to _"challenge"_ the dataset:

- Is my sample __representative__ of what I am interested in? Having only 2000 municipalities out of 35000 is not necessarily a problem, but it's good to have considered the question.
- Are the __orders of magnitude__ correct? To assess this, compare your initial descriptive statistics with your internet research. For example, finding that houses sold in France in 2020 average 400 m¬≤ is not a realistic order of magnitude.
- Do I __understand all the variables__ in my dataset? Do they "behave" as expected? At this stage, it can be useful to create a variable dictionary (explaining how they are constructed or calculated). Correlation studies between variables can also be conducted.
- Do I have any __outliers__, i.e., aberrant values for certain individuals? In this case, decide on the treatment (remove them, apply a logarithmic transformation, leave them as is) and justify it well.
- Do I have any __key insights__ from my dataset? Do I have surprising results? If so, have I investigated them thoroughly to see if the results still hold or if it's due to issues in the dataset construction (poorly cleaned, incorrect variable...)
:::

::: {.content-visible when-profile="fr"}

# Lors de la mod√©lisation

√Ä cette √©tape, l'analyse descriptive doit avoir donn√© quelques premi√®res pistes pour savoir dans quelle direction vous voulez mener votre mod√®le. Une erreur de d√©butant est de se lancer directement dans la mod√©lisation parce qu'il s'agirait d'une comp√©tence plus pouss√©e. Cela am√®ne g√©n√©ralement √† des analyses de pauvre qualit√© : la mod√©lisation tend g√©n√©ralement √† confirmer les intuitions issues de l'analyse descriptive. Si cette derni√®re n'a pas √©t√© s√©rieusement entreprise, l'interpr√©tation des r√©sultats d'un mod√®le peut s'av√©rer inutilement complexe.

Un bagage statistique et √©conom√©trique aide √† avoir de meilleures intuitions sur les r√©sultats issus d'un mod√®le. Il n'est pas inutile de voir que les autres cours de votre cursus statistique (√âconom√©trie 1, S√©ries Temporelles, Sondages, Analyse des donn√©es, etc.) peuvent vous aider √† trouver le mod√®le le plus adapt√© √† votre question.

Un point important √† avoir en t√™te est que la m√©thode sera guid√©e par l'objectif et non l'inverse. Parmi les questions √† consid√©rer :

- Est-ce que vous voulez expliquer ou pr√©dire ? Selon votre r√©ponse √† cette question, vous n'allez pas adopter la m√™me approche scientifique ni les m√™mes algorithmes.
- Est-ce que vous voulez classer un √©l√©ment dans une cat√©gorie (de mani√®re supervis√©e via de la classification ou non supervis√©e avec du _clustering_) ou pr√©dire une valeur num√©rique (r√©gression) ?

En fonction des mod√®les que vous aurez d√©j√† vus en cours et des questions que vous souhaiterez r√©soudre sur votre jeu de donn√©es, le choix du mod√®le sera souvent assez direct.
:::

::: {.content-visible when-profile="en"}

# During modeling

At this stage, descriptive analysis should have provided some initial clues on which direction to take your model. A beginner's mistake is to dive straight into modeling because it seems like a more advanced skill. This often leads to poor quality analyses: modeling tends to confirm intuitions derived from descriptive analysis. If the latter has not been thoroughly conducted, interpreting model results can become unnecessarily complex.

A background in statistics and econometrics helps in developing better intuitions about the results from a model. It is useful to note that other courses in your statistical curriculum (Econometrics 1, Time Series, Surveys, Data Analysis, etc.) can help you find the most appropriate model for your question.

An important point to keep in mind is that the method will be guided by the objective and not the other way around. Among the questions to consider:

- Do you want to explain or predict? Depending on your answer to this question, you will not adopt the same scientific approach or algorithms.
- Do you want to classify an item into a category (supervised classification or unsupervised clustering) or predict a numerical value (regression)?

Depending on the models you have already encountered in your courses and the questions you wish to address with your dataset, the choice of model will often be quite straightforward.
:::


::: {.content-visible when-profile="fr"}

## Lors de la phase de valorisation des travaux

La mise √† disposition de code sur `Github` ou `Gitlab` est une incitation tr√®s forte pour produire du code de qualit√©. Il est ainsi recommand√© de syst√©matiquement utiliser ces plateformes pour la mise √† disposition de code. C'est d'ailleurs une consigne obligatoire pour la validation de ce cours.

Cependant, les gains de qualit√© ne sont pas la seule raison d'adopter l'utilisation de `Github` ou `Gitlab` au quotidien. Le cours que je donne avec Romain Avouac en troisi√®me ann√©e d'ENSAE ([ensae-reproductibilite.github.io/website/](https://ensae-reproductibilite.github.io/website/)) √©voque l'un des principaux gains √† utiliser ces plateformes, √† savoir la possibilit√© de mettre √† disposition automatiquement diff√©rents livrables pour valoriser son travail aupr√®s de diff√©rents publics.

Selon le public vis√©, la communication ne sera pas identique. Le code peut int√©resser les personnes d√©sirant avoir des d√©tails sur la m√©thodologie mise en ≈ìuvre en pratique mais il peut s'agir d'un format rebutant pour d'autres publics. Une visualisation de donn√©es dynamiques parlera √† des publics moins experts de la donn√©e mais est plus dure √† mettre en ≈ìuvre qu'un graphique standard.
:::

::: {.content-visible when-profile="en"}

# During the results presentation phase

Sharing code on `Github` or `Gitlab` is a strong incentive to produce high-quality code. It is therefore recommended to systematically use these platforms for code sharing. This is actually a mandatory requirement for validating this course.

However, quality gains are not the only reason to adopt the use of `Github` or `Gitlab` on a daily basis. The course I teach with Romain Avouac in the third year of ENSAE ([ensae-reproductibilite.github.io/website/](https://ensae-reproductibilite.github.io/website/)) discusses one of the main benefits of using these platforms, namely the ability to automatically provide various deliverables to showcase your work to different audiences.

Depending on the target audience, communication will differ. The code may interest those wanting details on the methodology implemented in practice, but it may be a format that is off-putting to other audiences. Dynamic data visualizations will appeal to less data-savvy audiences but are harder to implement than standard charts.
:::

::: {.content-visible when-profile="fr"}

:::: {.caution}

Les _notebooks_ `Jupyter` ont eu beaucoup de succ√®s dans le monde de la _data science_ pour partager des travaux. Pourtant il ne s'agit pas forc√©ment toujours du meilleur format. En effet, beaucoup de _notebooks_ tentent √† empiler des pav√©s de code et du texte, ce qui les rend difficilement lisibles[^note-projet].

Sur un projet cons√©quent, il vaut mieux reporter le plus de code possible dans des scripts bien structur√©s et avoir un _notebook_ qui appelle ces scripts pour produire des outputs. Ou alors ne pas utiliser un notebook et privil√©gier un autre format (un tableau de bord, un site web, une appli r√©active...).

Dans le cours de derni√®re ann√©e de l'ENSAE, [Mise en production de projets data science](https://ensae-reproductibilite.github.io/website/), Romain Avouac et moi revenons sur les moyens de communication et de partage de code alternatifs au _notebook_.

Si ce cours propose des _notebooks_, c'est parce qu'ils sont particuli√®rement ad√©quats pour l'apprentissage de `Python`. Les possibilit√©s d'intercaler du texte entre deux blocs de code et l'interactivit√© sont des fonctionnalit√©s id√©ales pour la p√©dagogie. Quand vous serez plus √† l'aise avec `Python`, vous pourrez sortir du _notebook_ pour aller vers l'ex√©cution de scripts.

::::

[^note-projet]: D'ailleurs, dans les consignes de rendu du projet ([partie Evaluation](content/annexes/evaluation.qmd)), on vous recommande d'√©viter les _notebooks_ monolithiques en vous proposant quelques solutions pour cela.

:::

::: {.content-visible when-profile="en"}

:::: {.caution}

_Jupyter_ notebooks have been very popular in the data science world for sharing work. However, they are not always the best format. Indeed, many notebooks tend to stack blocks of code and text, which makes them hard to read[^note-projet].

For a substantial project, it is better to move as much code as possible into well-structured scripts and have a notebook that calls these scripts to produce outputs. Alternatively, consider using a different format (a dashboard, a website, an interactive app...).

In the final-year course at ENSAE, [Data Science Project Deployment](https://ensae-reproductibilite.github.io/website/), Romain Avouac and I review alternative methods for code communication and sharing beyond notebooks.

This course uses notebooks because they are particularly well-suited for learning `Python`. The ability to insert text between code blocks and the interactivity are ideal for teaching purposes. Once you are more comfortable with `Python`, you can move beyond notebooks to executing scripts.

::::

[^note-projet]: In the project submission guidelines ([Evaluation section](content/annexes/evaluation.qmd)), we recommend avoiding monolithic notebooks and offer some solutions for this.

:::

::: {.content-visible when-profile="fr"}

# √âthique et responsabilit√© du _data scientist_

## La reproductibilit√© est importante

Les donn√©es sont une repr√©sentation synth√©tique de la r√©alit√©, et les conclusions de certaines analyses peuvent avoir un impact r√©el sur la vie des citoyens. Par exemple, les chiffres erron√©s pr√©sent√©s par @reinhart2010growth ont servi de justification th√©orique √† des politiques d'aust√©rit√© qui ont eu des cons√©quences graves pour certains citoyens dans des pays en crise[^4]. En Grande-Bretagne, le recensement des personnes contamin√©es par le Covid en 2020, ainsi que de leurs proches pour le suivi de l'√©pid√©mie, a √©t√© incomplet en raison de troncatures dues √† l'utilisation d'un format de stockage des donn√©es inappropri√© (tableur Excel)[^5].

Un autre exemple est celui du _credit scoring_ mis en ≈ìuvre aux √âtats-Unis. La citation ci-dessous, tir√©e de l'article de @hurley2016credit, illustre les cons√©quences et les aspects probl√©matiques d'un syst√®me de construction automatis√©e d'un score de cr√©dit :

:::

::: {.content-visible when-profile="en"}

# Ethics and responsibility

## Reproducibility is important

Data is a synthetic representation of reality, and the conclusions of certain analyses can have a real impact on people's lives. For instance, the erroneous figures presented by @reinhart2010growth were used as theoretical justification for austerity policies that had severe consequences for citizens in crisis-affected countries[^4]. In Great Britain, the Covid-19 case counts in 2020, and thus the monitoring of the epidemic, were incomplete due to truncations caused by the use of an inappropriate data storage format (Excel spreadsheet)[^5].

Another example is the _credit scoring_ system implemented in the United States. The following quote from @hurley2016credit's article illustrates the consequences and problematic aspects of an automated credit scoring system:

:::

> Consumers have limited ability to identify and contest unfair credit
decisions, and little chance to understand what steps they 
should take to improve their credit. Recent studies have also
questioned the accuracy of the data used by these tools, in some
cases identifying serious flaws that have a substantial bearing
on lending decisions. Big-data tools may also risk creating a
system of _"creditworthinessby association"_ in which consumers'
familial, religious, social, and other affiliations determine their
eligibility for an affordable loan.
>
> @hurley2016credit

::: {.content-visible when-profile="fr"}

[^4]: L'article de Reinhart et Rogoff, "_Growth in a Time of Debt_", s'appuyait
sur un Excel constitu√© √† la main. Un doctorant s'est aper√ßu d'erreurs 
dans celui-ci et a remarqu√© que lorsqu'on
substituait les chiffres officiels, les r√©sultats n'avaient plus le m√™me degr√© de validit√©. 

[^5]: Plus de d√©tails sont disponibles dans la presse du moment, notamment
[cet article](https://www.lemondeinformatique.fr/actualites/lire-un-mauvais-usage-d-excel-evince-16-000-cas-positifs-covid-19-en-uk-80607.html) ou [celui-l√†](https://www.bbc.com/news/technology-54423988).

Ces probl√®mes sont malheureusement assez structurels dans le domaine de la recherche. Une √©quipe de chercheurs de Princeton a pu parler de _"crise de la reproductibilit√©"_ dans le domaine du _machine learning_ suite √† de nombreux √©checs √† r√©pliquer certaines √©tudes [@Reproducibilitycrisis]. Comme l'√©voque @guinnane2023we, de nombreuses √©tudes d'histoire √©conomique s'appuient sur des chiffres de population sans fondement. 

Certains journaux acad√©miques ont d√©cid√© de mettre en oeuvre une approche plus transparente et reproductible. L'_American Economic Review_ (AER), l'une des revues du _"top 5"_ en √©conomie, a une politique assez proactive sur le sujet gr√¢ce √† son [_data editor_ Lars Vilhuber](https://aeadataeditor.github.io/).

:::

::: {.content-visible when-profile="en"}

[^4]: Reinhart and Rogoff's article, "_Growth in a Time of Debt_", relied on a manually constructed Excel file. A PhD student discovered errors in it and noted that when official figures were substituted, the results no longer had the same degree of validity.

[^5]: More details are available in the press of the time, notably [this article](https://www.lemondeinformatique.fr/actualites/lire-un-mauvais-usage-d-excel-evince-16-000-cas-positifs-covid-19-en-uk-80607.html) or [that one](https://www.bbc.com/news/technology-54423988).

These problems are unfortunately quite structural in research. A team of Princeton researchers has discussed the _"reproducibility crisis"_ in the field of _machine learning_ due to numerous failures to replicate certain studies [@Reproducibilitycrisis]. As @guinnane2023we mentions, many studies in economic history rely on unfounded population figures.

Some academic journals have decided to implement a more transparent and reproducible approach. The _American Economic Review_ (AER), one of the _top 5_ economics journals, has a rather proactive policy on the subject thanks to its [_data editor_ Lars Vilhuber](https://aeadataeditor.github.io/).
:::


::: {.content-visible when-profile="fr"}

## Lutter contre les biais cognitifs

La transparence sur les int√©r√™ts et limites d'une m√©thode mise en oeuvre
est donc importante.
Cette exigence de la recherche, parfois oubli√©e √† cause de la course
aux r√©sultats novateurs, m√©rite √©galement d'√™tre appliqu√©e
en entreprise ou administration. 
M√™me sans intention manifeste de la part de la personne qui analyse des donn√©es,
une mauvaise interpr√©tation est toujours possible. 

Tout en valorisant un
r√©sultat, il est possible d'alerter sur certaines limites. Il est important,
dans ses recherches comme dans les discussions avec d'autres interlocuteurs,
de faire attention au biais de confirmation qui consiste 
√† ne retenir que l'information qui correspond √† nos conceptions _a priori_ et
√† ne pas consid√©rer celles qui pourraient aller √† l'encontre de celles-ci :

![](https://s3.amazonaws.com/revue/items/images/005/107/849/original/59df6bbf7a4b2da55d4eebbd37457f47.png?1571180763)

Certaines repr√©sentations de donn√©es sont √† exclure car des biais cognitifs
peuvent amener √† des interpr√©tations erron√©es[^5]. Dans le domaine de la 
visualisation de donn√©es, les camemberts (_pie chart_) ou les diagrammes
radar sont par exemple 
√† exclure car l'oeil humain per√ßoit mal ces formes circulaires. Pour une raison
similaire, les cartes avec aplat de couleur (cartes
choropl√®thes) sont trompeuses. 
Les _posts_ de blog pour [_datawrapper_](https://blog.datawrapper.de/)
de Lisa Charlotte Muth ou ceux d'Eric Mauvi√®re sont d'excellentes ressources
pour apprendre les bonnes et mauvaises pratiques de
visualisation (voir la [partie visualisation](../visualisation/index.qmd) de ce cours
pour plus de d√©tails). 

[^5]: On suppose ici que le message erron√© est transmis sans volont√© de 
manipulation. La manipulation manifeste est un probl√®me encore plus grave. 

:::

::: {.content-visible when-profile="en"}

## Fighting cognitive biases

Transparency about the interests and limitations of a method used is therefore important.
This research requirement, sometimes forgotten due to the race for innovative results, also deserves to be applied in business or administration.
Even without a manifest intention from the person analyzing the data, misinterpretation is always possible.

While highlighting a result, it is possible to point out certain limitations. It is important, in research as well as in discussions with others, to be aware of confirmation bias, which consists of only considering information that aligns with our _a priori_ beliefs and ignoring information that might contradict them:

![](https://s3.amazonaws.com/revue/items/images/005/107/849/original/59df6bbf7a4b2da55d4eebbd37457f47.png?1571180763)

Certain data representations should be excluded as cognitive biases can lead to erroneous interpretations[^5]. In the field of data visualization, pie charts or radar charts should be excluded because the human eye poorly perceives these circular shapes. For a similar reason, color-filled maps (choropleth maps) can be misleading.
Blog posts for [_datawrapper_](https://blog.datawrapper.de/) by Lisa Charlotte Muth or those by Eric Mauvi√®re are excellent resources for learning good and bad practices in visualization (see the [visualization section](../visualisation/index.qmd) of this course for more details).

[^5]: It is assumed here that the erroneous message is transmitted without intention to deceive. Manifest manipulation is an even more serious problem.

:::

::: {.content-visible when-profile="fr"}

## R√©glementation des donn√©es

Le cadre r√©glementaire de protection des donn√©es a √©volu√© ces derni√®res 
ann√©es avec le __RGPD__. Cette r√©glementation a permis de mieux faire 
saisir le fait que la collecte de donn√©es se justifie au nom 
de finalit√©s plus ou moins bien identifi√©es. Prendre conscience que
la confidentialit√© des donn√©es se justifie pour √©viter la diss√©mination
non contr√¥l√©e d'informations sur une personne est important. 
Des donn√©es particuli√®rement sensibles, notamment les donn√©es de sant√©,
peuvent √™tre plus contraignantes √† traiter que des donn√©es peu sensibles. 

En Europe, par exemple, les agents du service statistique public
(Insee ou services statistiques minist√©riels) sont tenus au secret professionnel
(article L121-6 du Code g√©n√©ral de la fonction publique),
qui leur interdit la communication des informations confidentielles
dont ils sont d√©positaires au titre de leurs missions ou fonctions,
sous peine des sanctions pr√©vues par l‚Äôarticle 226-13 du Code p√©nal
(jusqu‚Äô√† un an d‚Äôemprisonnement et 15 000 ‚Ç¨ d‚Äôamende). 
Le secret statistique, d√©fini dans une loi de 1951, 
renforce cette obligation dans le cas de donn√©es d√©tenues pour des usages statistiques.
Il interdit strictement la communication de donn√©es individuelles
ou susceptibles d'identifier les personnes,
issues de traitements √† finalit√©s statistiques,
que ces traitements proviennent d‚Äôenqu√™tes ou de bases de donn√©es. 
Le secret statistique exclut par principe de diffuser des donn√©es
qui permettraient l‚Äôidentification des personnes concern√©es,
personnes physiques comme personnes morales.
Cette obligation limite la finesse des informations disponibles en diffusion

Ce cadre contraignant s'explique par l'h√©ritage de la Seconde Guerre Mondiale
et le d√©sir de ne plus revivre une situation o√π la collecte d'information
sert une action publique bas√©e sur la discrimination entre cat√©gories
de la population.
:::

::: {.content-visible when-profile="en"}

## Data regulation

The regulatory framework for data protection has evolved in recent years with the __GDPR__. This regulation has helped to better understand that data collection is justified for more or less well-defined purposes. It is important to recognize that data confidentiality is justified to prevent the uncontrolled dissemination of information about individuals. Particularly sensitive data, such as health data, can be more challenging to handle than less sensitive data.

In Europe, for example, agents of public statistical services (e.g., Insee or ministerial statistical services) are bound by professional secrecy (Article L121-6 of the General Civil Service Code), which prohibits them from disclosing confidential information they hold as part of their duties, under penalty of sanctions provided for by Article 226-13 of the Penal Code (up to one year in prison and ‚Ç¨15,000 fine). Statistical secrecy, defined in a 1951 law, strengthens this obligation in the case of data held for statistical purposes. It strictly prohibits the communication of individual data or data that could identify individuals, derived from statistical processing, whether these processes come from surveys or databases. Statistical secrecy generally excludes the dissemination of data that could allow the identification of the concerned individuals, both natural and legal persons. This obligation limits the granularity of the information available for dissemination.

This strict framework is explained by the legacy of World War II and the desire to avoid a situation where information collection serves a public action based on discrimination between categories of the population.
:::


::: {.content-visible when-profile="fr"}

## Partager les moyens de reproduire une analyse

Un [article r√©cent de `Nature`](https://www.nature.com/articles/d41586-022-01692-1),
qui reprend les travaux d'une √©quipe d'√©pid√©miologistes [@gabelica2022many]
√©voque le probl√®me de l'acc√®s aux donn√©es pour des chercheurs d√©sirant reproduire
une √©tude. M√™me dans les articles scientifiques o√π il est mentionn√© que les
donn√©es peuvent √™tre mises √† disposition d'autres chercheurs, le partage
de celles-ci est rare :

![Graphique issu de l'article de _Nature_](https://media.nature.com/lw800/magazine-assets/d41586-022-01692-1/d41586-022-01692-1_23176470.png){}


Ce constat, quelque peu inqui√©tant, est confirm√© par une √©tude r√©cente
de @samuel2023computational qui a tent√© d'ex√©cuter un peu moins de 
30 000 _notebooks_ associ√©s √† des √©tudes scientifiques. Seuls 3%
des _notebooks_ reproduisent les r√©sultats esp√©r√©s. 

Afin de partager les moyens de reproduire des publications sans diffuser des
donn√©es potentiellement confidentielles, les jeux de donn√©es synth√©tiques
sont de plus en plus utilis√©s. Par le biais de mod√®les de _deep learning_, 
il est ainsi possible de g√©n√©rer des jeux de donn√©es synth√©tiques complexes
qui permettent de reproduire les principales caract√©ristiques d'un jeu de donn√©es
tout en √©vitant, si le mod√®le a √©t√© bien calibr√©, de diffuser une information
individuelle. 

Dans l'administration fran√ßaise, les codes sources sont 
consid√©r√©s comme des documents administratifs et peuvent
donc √™tre mis √† disposition de tout citoyen sur demande √† la 
Commission d'acc√®s aux documents administratifs (CADA):

> ¬´ Sont consid√©r√©s comme documents administratifs, au sens des titres Ier, III et IV du pr√©sent livre, quels que soient leur date, leur lieu de conservation, leur forme et leur support, les documents produits ou re√ßus, dans le cadre de leur mission de service public, par l'√âtat, les collectivit√©s territoriales ainsi que par les autres personnes de droit public ou les personnes de droit priv√© charg√©es d'une telle mission. Constituent de tels documents notamment les dossiers, rapports, √©tudes, comptes rendus, proc√®s-verbaux, statistiques, instructions, circulaires, notes et r√©ponses minist√©rielles, correspondances, avis, pr√©visions, __codes sources__ et d√©cisions. ¬ª 
>
> [Avis 20230314 - S√©ance du 30/03/2023 de la Commission d'acc√®s aux documents administratifs](https://www.cada.fr/20230314)

En revanche, les poids des mod√®les utilis√©s par l'administration, notamment ceux
des mod√®les de _machine learning_ ne sont pas r√©glement√©s de la m√™me 
mani√®re ([Avis 20230314 de la CADA](https://www.cada.fr/20230314)).
En effet, comme il existe toujours
un risque de r√©tro-ing√©nierie amenant √† une r√©v√©lation partielle
des donn√©es 
d'entra√Ænement lors d'un partage de mod√®le, les mod√®les
entra√Æn√©s sur des donn√©es
sensibles (comme les d√©cisions de justice √©tudi√©es
par ([l'avis 20230314 de la CADA](https://www.cada.fr/20230314)))
n'ont pas vocation √† √™tre partag√©s. 
:::

::: {.content-visible when-profile="en"}

## Sharing methods to reproduce an analysis

A [recent article in `Nature`](https://www.nature.com/articles/d41586-022-01692-1),
which discusses the work of an epidemiologists' team [@gabelica2022many],
raises the issue of data access for researchers wanting to reproduce
a study. Even in scientific articles where it is mentioned that
data can be made available to other researchers, such sharing is rare:

![Graph from the _Nature_ article](https://media.nature.com/lw800/magazine-assets/d41586-022-01692-1/d41586-022-01692-1_23176470.png){}


This somewhat concerning observation is confirmed by a recent study
by @samuel2023computational, which attempted to execute just under
30,000 _notebooks_ associated with scientific studies. Only 3%
of the _notebooks_ reproduce the expected results.

To share the means of reproducing publications without disseminating
potentially confidential data, synthetic datasets are increasingly used. Through
_Deep Learning_ models, it is possible to generate complex synthetic datasets
that reproduce the main characteristics of a dataset while avoiding, if the model
has been well-calibrated, the disclosure of individual information.

In French administration, source codes are
considered administrative documents and can
therefore be made available to any citizen upon request to the
Commission for Access to Administrative Documents (CADA):

> "Administrative documents, as defined in Titles I, III, and IV of this book, regardless of their date, place of storage, form, and medium, are documents produced or received in the course of their public service mission by the State, local authorities, as well as other public entities or private entities entrusted with such a mission. Such documents include, in particular, files, reports, studies, minutes, statistics, instructions, circulars, notes and ministerial responses, correspondence, opinions, forecasts, __source codes__ and decisions."
>
> [Opinion 20230314 - Session of 30/03/2023 of the Commission for Access to Administrative Documents](https://www.cada.fr/20230314)

However, the weights of models used by the administration, particularly those
of _machine learning_ models, are not regulated in the same way ([Opinion 20230314 from CADA](https://www.cada.fr/20230314)).
Indeed, as there is always
a risk of reverse engineering leading to partial disclosure
of training data when sharing a model, models
trained on sensitive data (such as the judicial decisions studied
in [Opinion 20230314 from CADA](https://www.cada.fr/20230314))
are not intended to be shared.
:::


::: {.content-visible when-profile="fr"}

## Adopter une approche √©cologique

Le num√©rique constitue une part croissante des
√©missions de gaz √† effet de serre.
Repr√©sentant aujourd'hui 4 % des √©missions mondiales
de CO2, cette part devrait encore cro√Ætre [@arcep2019]. 
Le monde de la _data science_ est √©galement
concern√©.

L'utilisation de donn√©es de plus en
plus massives, notamment la constitution
de corpus monumentaux de textes,
r√©cup√©r√©s par scraping, est une premi√®re source
de d√©pense d'√©nergie. De m√™me, la r√©cup√©ration
en continu de nouvelles traces num√©riques
n√©cessite d'avoir des serveurs fonctionnels 
en continu.  A cette premi√®re source de 
d√©pense d'√©nergie, s'ajoute l'entra√Ænement
des mod√®les qui peut prendre des jours,
y compris sur des architectures tr√®s 
puissantes. @strubell2019energy
estime que l'entra√Ænement d'un mod√®le √†
l'√©tat de l'art dans le domaine du 
NLP n√©cessite autant d'√©nergie que ce que
consommeraient cinq voitures, en moyenne,
au cours de l'ensemble de leur
cycle de vie. 

L'utilisation accrue de l'int√©gration
continue, qui permet de mettre en oeuvre de mani√®re
automatis√©e l'ex√©cution de certains scripts ou
la production de livrables en continu, 
am√®ne √©galement √† une d√©pense d'√©nergie importante. 
Il convient donc d'essayer de limiter l'int√©gration
continue √† la production d'_output_ vraiment nouveaux. 
:::

::: {.content-visible when-profile="en"}

## Adopting an ecological approach

Digital technology constitutes a growing share of
greenhouse gas emissions.
Currently representing 4% of global CO2 emissions,
this share is expected to grow further [@arcep2019]. 
The field of _data science_ is also
concerned.

The use of increasingly massive data, particularly the creation
of monumental text corpora,
gathered through scraping, is a primary source
of energy expenditure. Likewise, continuously collecting
new digital traces requires maintaining functional
servers continuously. In addition to this primary source
of energy expenditure, training models can take days,
even on very powerful architectures. @strubell2019energy
estimates that training a state-of-the-art model in the field of
NLP requires as much energy as five cars, on average,
over their entire life cycle.

The increased use of continuous integration, which allows for
automated execution of certain scripts or
continuous production of deliverables,
also leads to significant energy expenditure. 
Therefore, it is advisable to limit continuous integration
to the production of truly new _outputs_.
:::


::: {.content-visible when-profile="fr"}

:::: {.note}

Par exemple, cet ouvrage utilise de mani√®re intensive 
cette approche. N√©anmoins, pour essayer de limiter
les effets pervers de la production en continu d'un
ouvrage extensif, seuls les chapitres modifi√©s 
sont produits lors des pr√©visualisations mises en
oeuvre √† chaque `pull request` sur le d√©p√¥t
`Github`. 

::::
:::

::: {.content-visible when-profile="en"}

:::: {.note}

For example, this book makes intensive use of
this approach. Nevertheless, to try to limit
the negative effects of continuously producing an
extensive book, only the modified chapters
are generated during the previews implemented for each `pull request` on the `Github` repository.

::::
:::


::: {.content-visible when-profile="fr"}
Les _data scientists_ doivent √™tre conscients
des implications de leur usage intensif de 
ressources et essayer de minimiser leur
impact. Par exemple, plut√¥t que r√©-estimer
un mod√®le de NLP,
la m√©thode de l'apprentissage par transfert,
qui permet de transf√©rer les poids d'apprentissage
d'un mod√®le √† une nouvelle source, permet 
de r√©duire les besoins computationnels.
De m√™me, il peut √™tre utile, pour prendre 
conscience de l'effet d'un code trop long, 
de convertir le temps de calcul en 
√©missions de gaz √† effet de serre. 
Le package [`codecarbon`](https://codecarbon.io/)
propose cette solution en adaptant l'estimation
en fonction du _mix_ √©nerg√©tique du pays
en question. Mesurer √©tant le
pr√©requis pour prendre conscience puis comprendre,
ce type d'initiatives peut amener √† responsabiliser
les _data scientists_ et ainsi permettre un 
meilleur partage des ressources. 
:::

::: {.content-visible when-profile="en"}
Data scientists need to be aware
of the implications of their intensive use of 
resources and try to minimize their
impact. For example, rather than re-estimating
an NLP model, the transfer learning method,
which allows for transferring learning weights
from one model to a new source, helps 
reduce computational needs.
Similarly, it may be useful to understand
the impact of excessively long code by
converting computation time into
greenhouse gas emissions. 
The [`codecarbon`](https://codecarbon.io/)
package provides this solution by adapting the estimate
based on the energy mix of the relevant country.
Measuring being a prerequisite to awareness and understanding,
such initiatives can lead to increased accountability
among data scientists and thus allow for
better resource sharing. 
:::

::: {.content-visible when-profile="fr"}

# R√©f√©rences {.unnumbered}

:::

::: {.content-visible when-profile="en"}

# References {.unnumbered}

:::

::: {#refs}
:::
