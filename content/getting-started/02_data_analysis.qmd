---
title: "D√©marche √† adopter face √† un jeu de donn√©es"
bibliography: ../../reference.bib
description: |
  Quelques √©l√©ments pour adopter une d√©marche
  scientifique et √©thique face √† un 
  jeu de donn√©es. 
image: https://minio.lab.sspcloud.fr/lgaliana/generative-art/mise-en-prod/babypython.png
categories:
  - Tutoriel
  - Rappels
---

Pour bien d√©buter des travaux sur une base de donn√©es,
il est n√©cessaire de se poser quelques questions de bon sens
et de suivre une d√©marche scientifique dont un certain
nombre de gestes prennent une forme assez simple.

Dans un projet sur des jeux de donn√©es, on peut sch√©matiquement
s√©parer les √©tapes en quatre grandes parties :

1. La r√©cup√©ration et structuration des donn√©es ;
2. L'analyse de celle-ci, notamment la production de statistiques descriptives indispensables pour orienter les exploitations ult√©rieures ;
3. La mod√©lisation ;
4. La valorisation finale des √©tapes pr√©c√©dentes et la communication de r√©sultats ou la mise en oeuvre d'une chaine de production.

Ce cours explore ces diff√©rentes √©tapes de mani√®re progressive gr√¢ce √†
l'√©cosyst√®me `Python` qui est tr√®s complet. Chaque chapitre du cours
peut √™tre vu comme une mani√®re de progresser dans ce fil conducteur. 
Dans ce chapitre, nous allons plut√¥t mettre en avant quelques r√©flexions
√† avoir avant de se lancer dans chaque √©tape. 


# Lors de la r√©cup√©ration des donn√©es

## R√©flexions √† mener en amont

La phase de constitution de son jeu de donn√©es sous-tend tout le projet qui suit.

La premi√®re question √† se poser est
_"de quelles donn√©es ai-je besoin pour r√©pondre √† ma probl√©matique ?"_.
Cette probl√©matique pourra √©ventuellement 
√™tre affin√©e en fonction des besoins mais les travaux sont g√©n√©ralement
de meilleure qualit√© lorsque la probl√©matique am√®ne √† la r√©flexion sur les donn√©es
disponibles plut√¥t que l'inverse. 

Ensuite, _"qui produit et met √† disposition ces donn√©es" ?_
_Les sources disponibles sur internet sont-elles fiables ?_
Les sites d'_open data_ gouvernementaux sont par exemple assez fiables mais autorisent parfois l'archivage de donn√©es restructur√©es par des tiers et non des producteurs officiels. A l'inverse, sur `Kaggle` ou sur `Github` la source de certains jeux de donn√©es n'est pas trac√©e ce qui rend compliqu√©e la confiance sur la qualit√© de la donn√©e

Une fois identifi√© une ou plusieurs sources de donn√©es,
_est-ce que je peux les compl√©ter avec d'autres donn√©es ?_
(dans ce cas, faire attention √† avoir des niveaux de granularit√© ad√©quats).

## Qui produit et diffuse des donn√©es en France ?

Lors de la phase de recherche de jeux de donn√©es, il est essentiel de conna√Ætre les principaux acteurs qui produisent et diffusent des donn√©es. Voici un panorama de l'√©cosyst√®me fran√ßais de la diffusion de donn√©es. 

### L'Insee et la statistique publique

En premier lieu, les __instituts statistiques__ comme l'Insee (Institut National de la Statistique et des √âtudes √âconomiques) en France ainsi que les __services statistiques minist√©riels (SSM)__[^ssp] produisent des donn√©es fiables sur de nombreuses probl√©matiques socio√©conomiques. Celles-ci sont des statistiques agr√©g√©es pouvant, pour certaines sources de donn√©es locales, √™tre tr√®s fines. Ces statistiques sont produites par le biais d'enqu√™tes, de donn√©es individuelles issues de fichiers administratifs dont l'acc√®s est permis par une [loi de 1951](https://www.insee.fr/fr/information/1300616) (voir la partie sur la r√©glementation des donn√©es üëáÔ∏è) ou par l'exploitation de sources de donn√©es alternatives, issues par exemple de producteurs priv√©s.

L'Insee produit √©galement des √©tudes approfondies exploitant les donn√©es qu'elle produit et qu'il est pertinent de lire lorsqu'on d√©couvre une probl√©matique socio√©conomique.

Parmi les _best-sellers_ des sources de donn√©es disponibles sur le site [insee.fr](https://www.insee.fr/fr/accueil), on retrouve les donn√©es du recensement, les chiffres du ch√¥mage, le taux d'inflation, le PIB, le fichier des pr√©noms. Toutes ces sources mesur√©es par l'Insee, qui sont si utilis√©es dans le d√©bat public, ont g√©n√©ralement des d√©finitions internationales pour permettre des comparaisons dans le temps et l'espace.  


[^ssp]: Le service statistique public fran√ßais est constitu√© de l‚ÄôInsee et des 16 services statistiques minist√©riels (SSM). Ces derniers sont les directions des minist√®res ayant des missions de production et de diffusion de service public. Contrairement aux autres directions des minist√®res auxquels les SSM sont rattach√©s, ils n'ont pas vocation exclusivement √† appuyer l'action publique de mani√®re op√©rationnelle mais surtout √† donner des √©l√©ments quantitatifs utiles au d√©bat public et √† l'action publique. 

Dans ce cours, nous utiliserons quelques fois des sources diffus√©es par l'Insee pour avoir des donn√©es contextuelles √† un niveau agr√©g√©. 

### L'IGN 

L'IGN (Institut National de l'Information G√©ographique et Foresti√®re) est un autre acteur important qui produit et diffuse des donn√©es g√©ographiques et cartographiques de haute qualit√© en France. Ces donn√©es couvrent divers aspects du territoire national, allant des cartes topographiques aux informations sur l'occupation des sols, et sont essentielles pour des projets ayant une dimension g√©ographique.

Nous utiliserons fr√©quemment certains fonds de carte produit par l'IGN lors de nos chapitres d'analyse spatial. 


### Les autres administrations et collectivit√©s locales

Contrairement aux administrations de la statistique publique, le reste de l'administration fran√ßaise n'a pas comme mission principale de diffuser du savoir statistique. N√©anmoins, les donn√©es peuvent occuper une place importante dans les processus internes de ces administrations. 

Par exemple, la DGFiP (Direction G√©n√©rale des Finances Publiques) dispose d'√©norm√©ment de donn√©es issues des d√©clarations fiscales des Fran√ßais. Contrairement √† l'Insee qui va s'int√©resser √† ces donn√©es pour, par exemple, avoir une vision exhaustive des in√©galit√©s √©conomiques ou de la situation des entreprises fran√ßaises, la DGFiP s'y int√©resse √† des fins de gestion r√©galienne de l'administration et se posera des question telles que _"les ressources correspondent-elles aux attentes et permettront-elles de financer le budget de l'Etat ?"_. 

Les collectivit√©s locales mettent √† disposition un large √©ventail de donn√©es locales. Ces donn√©es couvrent divers domaines dans leur champ de comp√©tence: am√©nagement, infrastructures, budget... Elles sont tr√®s pratiques pour des √©tudes sp√©cifiques √† une r√©gion ou une ville, en compl√©ment de donn√©es locales fournies par d'autres acteurs, notamment l'Insee. Par exemple, dans le cadre de ce cours, nous utiliserons √† plusieurs reprises le [portail Open Data de la Ville de Paris](https://opendata.paris.fr/pages/home/). 

::: {.note}
## La DINUM et le portail [data.gouv](https://www.data.gouv.fr/fr/)

La DINUM (Direction Interminist√©rielle du Num√©rique) est une administration centrale en France charg√©e de coordonner les initiatives num√©riques au sein de l'√âtat. Elle joue un r√¥le crucial dans la diffusion des donn√©es publiques √† travers la plateforme [data.gouv](https://www.data.gouv.fr/fr/) qui centralise et met √† disposition des milliers de jeux de donn√©es produits par les administrations publiques, facilitant ainsi leur r√©utilisation pour des projets de recherche, d'innovation, ou d'int√©r√™t public.
:::

### Les projets contributifs et _crowd-sourc√©s_

Des initiatives comme OpenStreetMap, Wikidata, ou OpenFoodFacts reposent sur la contribution volontaire de nombreux utilisateurs pour produire et maintenir des jeux de donn√©es. Ces projets sont particuli√®rement utiles pour obtenir des donn√©es g√©ospatiales, encyclop√©diques ou sur les produits de consommation, respectivement.

### Les donn√©es issues d'acteurs priv√©s

Du fait de la num√©risation de l'√©conomie, de nombreuses entreprises collectent des donn√©es sur leurs utilisateurs ou clients dans le cadre de leurs activit√©s. Ces donn√©es, souvent volumineuses et vari√©es, peuvent √™tre exploit√©es √† de multiples fins, notamment pour des analyses de march√© ou des √©tudes comportementales. L'exploitation de la donn√©e est certes le coeur de m√©tier d'une partie des entreprises du num√©rique (notamment les r√©seaux sociaux) mais de nombreux acteurs exploitent en interne leurs donn√©es clients. En Europe, le cadre r√©glementaire est, depuis 2018, le [RGPD (R√®glement g√©n√©ral sur la protection des donn√©es)](https://www.cnil.fr/fr/comprendre-le-rgpd) qui d√©finit les conditions de collecte, stockage et exploitation de donn√©es personnelles. 

Certaines entreprises peuvent √©galement mettre √† disposition ces donn√©es, ou une version agr√©g√©e, par le biais de projets de recherche ou d'acc√®s via des API. Celles-ci peuvent √™tre int√©ressantes pour r√©pondre √† des questions cibl√©es, √† condition de ne pas oublier qu'elles sont produites √† partir d'une certaine client√®le et que l'extrapolation √† la population g√©n√©rale n'est pas toujours possible. 


## Structuration des donn√©es

Vient ensuite la phase de mise en forme et nettoyage des jeux de donn√©es r√©cup√©r√©s.
Cette √©tape est primordiale et est g√©n√©ralement celle qui mobilise le plus
de temps. Pendant quelques ann√©es, on parlait de _data cleaning_. Cependant,
cela a pu, implicitement, laisser penser qu'il s'agissait d'une t√¢che 
subalterne. On commence √† lui pr√©f√©rer le concept de _data wrangling_ ou _feature engineering_ 
qui souligne bien qu'il s'agit d'une comp√©tence qui n√©cessite beaucoup 
de comp√©tences.

Un jeu de donn√©es propre est un jeu de donn√©es dont la structure est 
ad√©quate et n'entra√Ænera pas d'erreur, visible ou non,
lors de la phase d'analyse. Comme nous aurons l'occasion de le d√©finir dans les premiers chapitres de la [partie Manipulation](/content/manipulation/index.qmd), l'horizon id√©al de structuration est une donn√©e _tidy_, c'est-√†-dire organis√©e sous forme de tableau bien structur√©. 

Voici quelques caract√©ristiques d'un jeu de donn√©es propre : 

- les __informations manquantes__ sont bien comprises et trait√©es. `Numpy` et
`Pandas` proposent un certain formalisme sur le sujet qu'il est utile 
d'adopter en rempla√ßant par `NaN` les observations manquantes. Cela
implique de faire attention √† la mani√®re dont certains producteurs
codent les valeurs manquantes : certains ont la facheuse tendance √† 
√™tre imaginatifs sur les codes pour valeurs manquantes : _"-999"_, _"XXX"_, _"NA"_ 
- les __variables servant d'identifiants__ sont bien les m√™mes d'une table √† l'autre (notamment dans le cas de jointures) : m√™me format, m√™me modalit√©s...
- pour des __variables textuelles__, qui peuvent √™tre mal renseign√©es, avoir corrig√© les √©ventuelles fautes (ex "Rolland Garros" -> "Roland Garros")
- cr√©er des variables qui synth√©tisent l'information dont vous avez besoin
- supprimer les √©l√©ments inutiles (colonne ou ligne vide)
- renommer les colonnes avec des noms compr√©hensibles


# Lors de l'analyse descriptive

Une fois les jeux de donn√©es nettoy√©s, vous pouvez plus sereinement
√©tudier l'information pr√©sente dans les donn√©es.
Cette phase et celle du nettoyage ne sont pas s√©quentielles,
en r√©alit√© vous devrez r√©guli√®rement passer de votre nettoyage √† quelques statistiques descriptives qui vous montreront un probl√®me, retourner au nettoyage etc.

Les questions √† se poser pour _"challenger"_ le jeu de donn√©es :

- Est-ce que mon √©chantillon est bien __repr√©sentatif__ de ce qui m'int√©resse ? N'avoir que 2000 communes sur les 35000 n'est pas n√©cessairement un probl√®me mais il est bon de s'√™tre pos√© la question.
- Est-ce que les __ordres de grandeur__ sont bons ? Pour cela, confronter vos premieres statistiques descriptives √† vos recherches internet. Par exemple trouver que les maisons vendues en France en 2020 font en moyenne 400 m¬≤ n'est pas un ordre de grandeur r√©aliste.
- Est-ce que je __comprends toutes les variables__ de mon jeu de donn√©es ? Est-ce qu'elles se "comportent" de la bonne fa√ßon ? A ce stade, il est parfois utile de se faire un dictionnaire de variables (qui explique comment elles sont construites ou calcul√©es). On peut √©galement mener des √©tudes de __corr√©lation__ entre nos variables.
- Est-ce que j'ai des __outliers__, i.e. des valeurs aberrantes pour certains individus ? Dans ce cas, il faut d√©cider quel traitement on leur apporte (les supprimer, appliquer une transformation logarithmique, les laisser tel quel) et surtout bien le justifier.
- Est-ce que j'ai des __premiers grands messages__ sortis de mon jeu de donn√©es ? Est-ce que j'ai des r√©sultats surprenants ? Si oui, les ai-je creus√© suffisamment pour voir si les r√©sultats tiennent toujours ou si c'est √† cause d'un souci dans la construction du jeu de donn√©es (mal nettoy√©es, mauvaise variable...)

# Lors de la mod√©lisation

A cette √©tape, l'analyse descriptive doit voir avoir donn√© quelques premi√®res pistes pour savoir dans quelle direction vous voulez mener votre mod√®le.
Une erreur de d√©butant est de se lancer directement dans la mod√©lisation parce
qu'il s'agirait d'une comp√©tence plus pouss√©e. Cela am√®ne g√©n√©ralement 
√† des analyses de pauvre qualit√© : la mod√©lisation tend g√©n√©ralement √† confirmer
les intuitions issues de l'analyse descriptive. Si cette derni√®re n'a pas √©t√© s√©rieusement entreprise, l'interpr√©tation des r√©sultats d'un mod√®le peu s'av√©rer inutilement complexe. 

Un bagage statistique et √©conom√©trique aide √† avoir de meilleures intuitions sur les r√©sultats issus d'un mod√®le. Il n'est pas inutile de voir que les autres cours de votre cursus statistique (Econom√©trie 1, Series Temporelles, Sondages, Analyse des donn√©es etc.) peuvent vous aider √† trouver le mod√®le le plus adapt√© √† votre question.

Un point important √† avoir en t√™te est que la m√©thode sera guid√©e par l'objectif et non l'inverse. Parmi les

- Est-ce que vous voulez expliquer ou pr√©dire ? Selon votre r√©ponse √† cette question, vous n'allez pas adopter la m√™me approche scientifique ni les m√™mes algorithmes. 
- Est-ce que vous voulez classer un √©l√©ment dans une cat√©gorie (de mani√®re supervis√©e via de la classification ou non supervis√©e avec du _clustering_) ou pr√©dire une valeur num√©rique (r√©gression) ?

En fonction des mod√®les que vous aurez d√©j√† vu en cours et des questions que vous souhaiterez r√©soudre sur votre jeu de donn√©es, le choix du mod√®le sera souvent assez direct.


## Lors de la phase de valorisation des travaux

La mise √† disposition de code sur `Github` ou `Gitlab` est une incitation tr√®s forte pour produire du code de qualit√©. Il est ainsi recommand√© de
syst√©matiquement utiliser ces plateformes pour la mise √† disposition de
code. C'est d'ailleurs une consigne obligatoire pour la validation de ce cours. 

Cependant, les gains de qualit√© ne sont pas la seule raison d'adopter l'utilisation de `Github` ou `Gitlab` au quotidien.
Le cours que je donne avec Romain Avouac en troisi√®me ann√©e d'ENSAE
([ensae-reproductibilite.github.io/website/](https://ensae-reproductibilite.github.io/website/)) √©voque
l'un des principaux gains √† utiliser ces plateformes, √† savoir
la possibilit√© de mettre √† disposition automatiquement diff√©rents livrables
pour valoriser son travail aupr√®s de diff√©rents publics. 

Selon le public vis√©, la communication ne sera pas identique. Le code peut
int√©resser les personnes d√©sirant avoir des d√©tails sur la m√©thodologie mise
en oeuvre en pratique mais il peut s'agir d'un format rebutant pour d'autres
publics. Une visualisation de donn√©es dynamiques parlera √† des publics
moins experts de la donn√©e mais est plus dure √† mettre en oeuvre
qu'un graphique standard. 


::: {.caution}

Les _notebooks_ `Jupyter` ont eu beaucoup de succ√®s dans le monde de 
la _data science_ pour partager des travaux. Pourtant il ne s'agit
pas forc√©ment toujours du meilleur format. En effet, beaucoup
de _notebooks_ tentent √† empiler des pav√©s de code et du texte, ce
qui les rend difficilement lisibles[^note-projet].

Sur un projet cons√©quent, il vaut mieux reporter le plus de code 
possible dans des scripts bien structur√©s et avoir un _notebook_
qui appelle ces scripts pour produire des outputs. Ou alors ne
pas utiliser un notebook et privil√©gier un autre format (un 
tableau de bord, un site web, une appli r√©active...). 

Dans le cours de derni√®re ann√©e de
l'ENSAE, [Mise en production de projets data science](https://ensae-reproductibilite.github.io/website/), Romain
Avouac et moi revenons sur les moyens de communication et de partage de code alternatifs au _notebook_. 

Si ce cours propose des _notebooks_, c'est parce qu'ils sont particuli√®rement ad√©quats pour l'apprentissage de `Python`. Les possibilit√©s d'intercaler du texte entre deux blocs de code et l'interactivit√© sont des fonctionnalit√©s id√©ales pour la p√©dagogie. Quand vous serez plus √† l'aise avec `Python`, vous pourrez sortir du _notebook_ pour aller vers l'ex√©cution de scripts. 


:::

[^note-projet]: D'ailleurs, dans les consignes de rendu du projet ([partie Evaluation](content/annexes/evaluation.qmd)), on vous recommande d'√©viter les _notebooks_ monolithiques en vous proposant quelques solutions pour cela.


# Ethique et responsabilit√© du _data scientist_

## La reproductibilit√© est importante

Les donn√©es sont une repr√©sentation synth√©tique de la r√©alit√© et les
conclusions de certaines analyses peuvent avoir un vrai impact sur 
la vie des citoyens. Les chiffres erron√©s de 
@reinhart2010growth ont ainsi pu servir de justification th√©orique √† des
politiques d'aust√©rit√© qui ont pu avoir des cons√©quences violentes
pour certains citoyens de
pays en crise[^4]. En Grande-Bretagne, le recensement des personnes
contamin√©es par le Covid en 2020, et donc de leurs proches pour le
suivi de l'√©pid√©mie,
a √©t√© incomplet √† cause de
troncatures dues √† l'utilisation d'un format non adapt√© de stockage
des donn√©es (tableur Excel)[^5].

Dernier exemple avec le _credit scoring_ mis en oeuvre aux Etats-Unis. 
La citation ci-dessous, issue de l'article de @hurley2016credit, 
illustre tr√®s bien les cons√©quences et les aspects probl√©matiques
d'un syst√®me de construction automatis√©e d'un score de cr√©dit :

> Consumers have limited ability to identify and contest unfair credit
decisions, and little chance to understand what steps they 
should take to improve their credit. Recent studies have also
questioned the accuracy of the data used by these tools, in some
cases identifying serious flaws that have a substantial bearing
on lending decisions. Big-data tools may also risk creating a
system of _"creditworthinessby association"_ in which consumers'
familial, religious, social, and other affiliations determine their
eligibility for an affordable loan.
>
> @hurley2016credit

[^4]: L'article de Reinhart et Rogoff, "_Growth in a Time of Debt_", s'appuyait
sur un Excel constitu√© √† la main. Un doctorant s'est aper√ßu d'erreurs 
dans celui-ci et a remarqu√© que lorsqu'on
substituait les chiffres officiels, les r√©sultats n'avaient plus le m√™me degr√© de validit√©. 

[^5]: Plus de d√©tails sont disponibles dans la presse du moment, notamment
[cet article](https://www.lemondeinformatique.fr/actualites/lire-un-mauvais-usage-d-excel-evince-16-000-cas-positifs-covid-19-en-uk-80607.html) ou [celui-l√†](https://www.bbc.com/news/technology-54423988).

Ces probl√®mes sont malheureusement assez structurels dans le domaine de la recherche. Une √©quipe de chercheurs de Princeton a pu parler de _"crise de la reproductibilit√©"_ dans le domaine du _machine learning_ suite √† de nombreux √©checs √† r√©pliquer certaines √©tudes [@Reproducibilitycrisis]. Comme l'√©voque @guinnane2023we, de nombreuses √©tudes d'histoire √©conomique s'appuient sur des chiffres de population sans fondement. 

Certains journaux acad√©miques ont d√©cid√© de mettre en oeuvre une approche plus transparente et reproductible. L'_American Economic Review_ (AER), l'une des revues du _"top 5"_ en √©conomie, a une politique assez proactive sur le sujet gr√¢ce √† son [_data editor_ Lars Vilhuber](https://aeadataeditor.github.io/).


## Lutter contre les biais cognitifs

La transparence sur les int√©r√™ts et limites d'une m√©thode mise en oeuvre
est donc importante.
Cette exigence de la recherche, parfois oubli√©e √† cause de la course
aux r√©sultats novateurs, m√©rite √©galement d'√™tre appliqu√©e
en entreprise ou administration. 
M√™me sans intention manifeste de la part de la personne qui analyse des donn√©es,
une mauvaise interpr√©tation est toujours possible. 

Tout en valorisant un
r√©sultat, il est possible d'alerter sur certaines limites. Il est important,
dans ses recherches comme dans les discussions avec d'autres interlocuteurs,
de faire attention au biais de confirmation qui consiste 
√† ne retenir que l'information qui correspond √† nos conceptions _a priori_ et
√† ne pas consid√©rer celles qui pourraient aller √† l'encontre de celles-ci :

![](https://s3.amazonaws.com/revue/items/images/005/107/849/original/59df6bbf7a4b2da55d4eebbd37457f47.png?1571180763)

Certaines repr√©sentations de donn√©es sont √† exclure car des biais cognitifs
peuvent amener √† des interpr√©tations erron√©es[^5]. Dans le domaine de la 
visualisation de donn√©es, les camemberts (_pie chart_) ou les diagrammes
radar sont par exemple 
√† exclure car l'oeil humain per√ßoit mal ces formes circulaires. Pour une raison
similaire, les cartes avec aplat de couleur (cartes
choropl√®thes) sont trompeuses. 
Les _posts_ de blog pour [_datawrapper_](https://blog.datawrapper.de/)
de Lisa Charlotte Muth ou ceux d'Eric Mauvi√®re sont d'excellentes ressources
pour apprendre les bonnes et mauvaises pratiques de
visualisation (voir la [partie visualisation](../visualisation/index.qmd) de ce cours
pour plus de d√©tails). 

[^5]: On suppose ici que le message erron√© est transmis sans volont√© de 
manipulation. La manipulation manifeste est un probl√®me encore plus grave. 

## R√©glementation des donn√©es

Le cadre r√©glementaire de protection des donn√©es a √©volu√© ces derni√®res 
ann√©es avec le __RGPD__. Cette r√©glementation a permis de mieux faire 
saisir le fait que la collecte de donn√©es se justifie au nom 
de finalit√©s plus ou moins bien identifi√©es. Prendre conscience que
la confidentialit√© des donn√©es se justifie pour √©viter la diss√©mination
non contr√¥l√©e d'informations sur une personne est important. 
Des donn√©es particuli√®rement sensibles, notamment les donn√©es de sant√©,
peuvent √™tre plus contraignantes √† traiter que des donn√©es peu sensibles. 

En Europe, par exemple, les agents du service statistique public
(Insee ou services statistiques minist√©riels) sont tenus au secret professionnel
(article L121-6 du Code g√©n√©ral de la fonction publique),
qui leur interdit la communication des informations confidentielles
dont ils sont d√©positaires au titre de leurs missions ou fonctions,
sous peine des sanctions pr√©vues par l‚Äôarticle 226-13 du Code p√©nal
(jusqu‚Äô√† un an d‚Äôemprisonnement et 15 000 ‚Ç¨ d‚Äôamende). 
Le secret statistique, d√©fini dans une loi de 1951, 
renforce cette obligation dans le cas de donn√©es d√©tenues pour des usages statistiques.
Il interdit strictement la communication de donn√©es individuelles
ou susceptibles d'identifier les personnes,
issues de traitements √† finalit√©s statistiques,
que ces traitements proviennent d‚Äôenqu√™tes ou de bases de donn√©es. 
Le secret statistique exclut par principe de diffuser des donn√©es
qui permettraient l‚Äôidentification des personnes concern√©es,
personnes physiques comme personnes morales.
Cette obligation limite la finesse des informations disponibles en diffusion

Ce cadre contraignant s'explique par l'h√©ritage de la Seconde Guerre Mondiale
et le d√©sir de ne plus revivre une situation o√π la collecte d'information
sert une action publique bas√©e sur la discrimination entre cat√©gories
de la population. 


## Partager les moyens de reproduire une analyse

Un [article r√©cent de `Nature`](https://www.nature.com/articles/d41586-022-01692-1),
qui reprend les travaux d'une √©quipe d'√©pid√©miologistes [@gabelica2022many]
√©voque le probl√®me de l'acc√®s aux donn√©es pour des chercheurs d√©sirant reproduire
une √©tude. M√™me dans les articles scientifiques o√π il est mentionn√© que les
donn√©es peuvent √™tre mises √† disposition d'autres chercheurs, le partage
de celles-ci est rare :

![Graphique issu de l'article de _Nature_](https://media.nature.com/lw800/magazine-assets/d41586-022-01692-1/d41586-022-01692-1_23176470.png){}


Ce constat, quelque peu inqui√©tant, est confirm√© par une √©tude r√©cente
de @samuel2023computational qui a tent√© d'ex√©cuter un peu moins de 
30 000 _notebooks_ associ√©s √† des √©tudes scientifiques. Seuls 3%
des _notebooks_ reproduisent les r√©sultats esp√©r√©s. 

Afin de partager les moyens de reproduire des publications sans diffuser des
donn√©es potentiellement confidentielles, les jeux de donn√©es synth√©tiques
sont de plus en plus utilis√©s. Par le biais de mod√®les de _deep learning_, 
il est ainsi possible de g√©n√©rer des jeux de donn√©es synth√©tiques complexes
qui permettent de reproduire les principales caract√©ristiques d'un jeu de donn√©es
tout en √©vitant, si le mod√®le a √©t√© bien calibr√©, de diffuser une information
individuelle. 

Dans l'administration fran√ßaise, les codes sources sont 
consid√©r√©s comme des documents administratifs et peuvent
donc √™tre mis √† disposition de tout citoyen sur demande √† la 
Commission d'acc√®s aux documents administratifs (CADA):

> ¬´ Sont consid√©r√©s comme documents administratifs, au sens des titres Ier, III et IV du pr√©sent livre, quels que soient leur date, leur lieu de conservation, leur forme et leur support, les documents produits ou re√ßus, dans le cadre de leur mission de service public, par l'√âtat, les collectivit√©s territoriales ainsi que par les autres personnes de droit public ou les personnes de droit priv√© charg√©es d'une telle mission. Constituent de tels documents notamment les dossiers, rapports, √©tudes, comptes rendus, proc√®s-verbaux, statistiques, instructions, circulaires, notes et r√©ponses minist√©rielles, correspondances, avis, pr√©visions, __codes sources__ et d√©cisions. ¬ª 
>
> [Avis 20230314 - S√©ance du 30/03/2023 de la Commission d'acc√®s aux documents administratifs](https://www.cada.fr/20230314)

En revanche, les poids des mod√®les utilis√©s par l'administration, notamment ceux
des mod√®les de _machine learning_ ne sont pas r√©glement√©s de la m√™me 
mani√®re ([Avis 20230314 de la CADA](https://www.cada.fr/20230314)).
En effet, comme il existe toujours
un risque de r√©tro-ing√©nierie amenant √† une r√©v√©lation partielle
des donn√©es 
d'entra√Ænement lors d'un partage de mod√®le, les mod√®les
entra√Æn√©s sur des donn√©es
sensibles (comme les d√©cisions de justice √©tudi√©es
par ([l'avis 20230314 de la CADA](https://www.cada.fr/20230314)))
n'ont pas vocation √† √™tre partag√©s. 


## Adopter une approche √©cologique

Le num√©rique constitue une part croissante des
√©missions de gaz √† effet de serre.
Repr√©sentant aujourd'hui 4 % des √©missions mondiales
de CO2, cette part devrait encore cro√Ætre [@arcep2019]. 
Le monde de la _data science_ est √©galement
concern√©.

L'utilisation de donn√©es de plus en
plus massives, notamment la constitution
de corpus monumentaux de textes,
r√©cup√©r√©s par scraping, est une premi√®re source
de d√©pense d'√©nergie. De m√™me, la r√©cup√©ration
en continu de nouvelles traces num√©riques
n√©cessite d'avoir des serveurs fonctionnels 
en continu.  A cette premi√®re source de 
d√©pense d'√©nergie, s'ajoute l'entra√Ænement
des mod√®les qui peut prendre des jours,
y compris sur des architectures tr√®s 
puissantes. @strubell2019energy
estime que l'entra√Ænement d'un mod√®le √†
l'√©tat de l'art dans le domaine du 
NLP n√©cessite autant d'√©nergie que ce que
consommeraient cinq voitures, en moyenne,
au cours de l'ensemble de leur
cycle de vie. 

L'utilisation accrue de l'int√©gration
continue, qui permet de mettre en oeuvre de mani√®re
automatis√©e l'ex√©cution de certains scripts ou
la production de livrables en continu, 
am√®ne √©galement √† une d√©pense d'√©nergie importante. 
Il convient donc d'essayer de limiter l'int√©gration
continue √† la production d'_output_ vraiment nouveaux. 

::: {.note}

Par exemple, cet ouvrage utilise de mani√®re intensive 
cette approche. N√©anmoins, pour essayer de limiter
les effets pervers de la production en continu d'un
ouvrage extensif, seuls les chapitres modifi√©s 
sont produits lors des pr√©visualisations mises en
oeuvre √† chaque `pull request` sur le d√©p√¥t
`Github`. 

:::

Les _data scientists_ doivent √™tre conscients
des implications de leur usage intensif de 
ressources et essayer de minimiser leur
impact. Par exemple, plut√¥t que r√©-estimer
un mod√®le de NLP,
la m√©thode de l'apprentissage par transfert,
qui permet de transf√©rer les poids d'apprentissage
d'un mod√®le √† une nouvelle source, permet 
de r√©duire les besoins computationnels.
De m√™me, il peut √™tre utile, pour prendre 
conscience de l'effet d'un code trop long, 
de convertir le temps de calcul en 
√©missions de gaz √† effet de serre. 
Le package [`codecarbon`](https://codecarbon.io/)
propose cette solution en adaptant l'estimation
en fonction du _mix_ √©nerg√©tique du pays
en question. Mesurer √©tant le
pr√©requis pour prendre conscience puis comprendre,
ce type d'initiatives peut amener √† responsabiliser
les _data scientists_ et ainsi permettre un 
meilleur partage des ressources. 


# R√©f√©rences {.unnumbered}

::: {#refs}
:::
