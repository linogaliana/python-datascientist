---
title: "Pratique de pandas: un exemple complet"
date: 2023-07-01T13:00:00Z
draft: false
weight: 30
tags:
  - pandas
  - pollution
  - Ademe
  - Exercice
  - Manipulation
categories:
  - Manipulation
  - Exercice
slug: pandasTP
type: book
description: |
  Apr√®s avoir pr√©sent√© la logique de `Pandas` dans le chapitre pr√©c√©dent, 
  ce chapitre vise √† illustrer les fonctionalit√©s du _package_ 
  √† partir de donn√©es d'√©missions de gaz √† effet de serre
  de l'[`Ademe`](https://data.ademe.fr/). 
echo: true
output: false
image: featured_tp_pandas.png
---

Les exemples de ce TP sont visualisables sous forme de `Jupyter Notebooks`:

::: {.cell .markdown}
```{python}
#| echo: false
#| output: 'asis'
#| include: true
#| eval: true

import sys
sys.path.insert(1, '../../') #insert the utils module
from utils import print_badges

#print_badges(__file__)
print_badges("content/manipulation/02b_pandas_TP.qmd")
```
:::

Dans cette s√©rie d'exercices `Pandas`, 
nous allons d√©couvrir comment manipuler plusieurs
jeux de donn√©es avec `Python`.

Si vous √™tes int√©ress√©s par `R`,
une version tr√®s proche de ce TP est
disponible dans [ce cours](https://rgeo.linogaliana.fr/exercises/r-wrangling.html).


Dans ce tutoriel, nous allons utiliser deux sources de donn√©es :

* Les √©missions de gaz √† effet de serre estim√©es au niveau communal par l'`ADEME`. Le jeu de donn√©es est
disponible sur [data.gouv](https://www.data.gouv.fr/fr/datasets/inventaire-de-gaz-a-effet-de-serre-territorialise/#_)
et requ√™table directement dans `Python` avec
[cet url](https://koumoul.com/s/data-fair/api/v1/datasets/igt-pouvoir-de-rechauffement-global/convert) (ce sera l'objet du premier exercice)[^notedownload].
* Id√©alement, on utiliserait directement les donn√©es
[disponibles sur le site de l'Insee](https://www.insee.fr/fr/statistiques/3560121) mais celles-ci n√©cessitent un peu de travail
de nettoyage qui n'entre pas dans le cadre de ce TP. 
Pour faciliter l'import de donn√©es Insee, il est recommand√© d'utiliser les _packages_
[`doremifasol`](https://github.com/InseeFrLab/DoReMIFaSol) et [`insee`](https://github.com/pyr-opendatafr/R-Insee-Data) qui simplifient l'acc√®s aux donn√©es
de l'Insee disponibles sur le site web [insee.fr](https://www.insee.fr/fr/accueil)
ou via des API. 

[^notedownload]: 

  `Pandas` offre la possibilit√© d'importer des donn√©es directement depuis un url. C'est l'option 
  prise dans ce tutoriel. Si vous pr√©f√®rez, pour des 
  raisons d'acc√®s au r√©seau ou de performance, importer depuis un poste local,
  vous pouvez t√©l√©charger les donn√©es et changer
  les commandes d'import avec le chemin ad√©quat plut√¥t que l'url. 

La librairie `pynsee` n'est pas install√©e par d√©faut avec `Python`. Avant de pouvoir l'utiliser,
il est n√©cessaire de l'installer:

```{python}
#| eval: false
#| echo: true
!pip install pynsee
```

Toutes les d√©pendances indispensables √©tant install√©es, il suffit
maintenant d'importer les librairies qui seront utilis√©es
pendant ces exerices:

```{python}
#| echo: true

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import pynsee
import pynsee.download
```

## Importer les donn√©es

### Import d'un csv de l'Ademe


```{python}
#| echo: true
url = "https://koumoul.com/s/data-fair/api/v1/datasets/igt-pouvoir-de-rechauffement-global/convert"
```

::: {.cell .markdown}
```{=html}
<div class="alert alert-success" role="alert">
<h3 class="alert-heading"><i class="fa-solid fa-pencil"></i> Exercice 1: Importer un CSV et explorer la structure de donn√©es</h3>
```

1. Importer les donn√©es de l'Ademe √† l'aide du package `Pandas` et de la commande consacr√©e pour l'import de csv. Nommer le `DataFrame` obtenu `emissions`[^nomdf].
2. Utiliser les fonctions ad√©quates pour les 10 premi√®res valeurs, les 15 derni√®res et un √©chantillon al√©atoire de 10 valeurs gr√¢ce aux m√©thodes ad√©quates du _package_ `Pandas`. 
3. Tirer 5 pourcent de l'√©chantillon sans remise.
4. Ne conserver que les 10 premi√®res lignes et tirer al√©atoirement dans celles-ci pour obtenir un DataFrame de 100 donn√©es.
5. Faire 100 tirages √† partir des 6 premi√®res lignes avec une probabilit√© de 1/2 pour la premi√®re observation et une probabilit√© uniforme pour les autres.


<details>
<summary>
En cas de blocage √† la question 1
</summary>
Lire la documentation de `read_csv` (tr√®s bien faite) ou chercher des exemples
en ligne pour d√©couvrir cette fonction.
</details>


```{=html}
</div>
```
:::

[^nomdf]: Par manque d'imagination, on est souvent tent√© d'appeler notre
_dataframe_ principal `df` ou `data`. C'est souvent une mauvaise id√©e puisque
ce nom n'est pas tr√®s informatif quand on relit le code quelques semaines
plus tard. L'autodocumentation, approche qui consiste √† avoir un code
qui se comprend de lui-m√™me, est une bonne pratique et il est donc recommand√©
de donner un nom simple mais efficace pour conna√Ætre la nature du _dataset_ en question.

```{python}
#| label: exo1-q1
# Question 1
emissions = pd.read_csv(url, sep=",")
```

```{python}
#| label: exo1-q2
# Question 2
emissions.head(2)

emissions.head(10)
emissions.tail(15)
emissions.sample(10)

# Question 3
emissions.sample(frac = 0.05)

# Question 4
emissions.head(10).sample(n = 100, replace = True)

# Question 5
emissions.head(6).sample(n = 100, replace = True, weights = [0.5] + [0.1]*5)
```

## Premi√®res manipulations de donn√©es

Le chapitre pr√©c√©dent √©voquait quelques manipulations traditionnelles
de donn√©es. 

::: {layout-ncol=2}

![S√©lectionner des colonnes](./select_pandas.png)
![Renommer des colonnes](./rename_pandas.png)

![Cr√©er de nouvelles colonnes](./mutate_pandas.png)
![S√©lectionner des lignes](./filter_pandas.png)

![R√©ordonner le _DataFrame_](./arrange_pandas.png)

:::


La _cheatsheet_ suivante est tr√®s pratique puisqu'elle illustre ces diff√©rentes
fonctions. Il est recommand√© de r√©guli√®rement
la consulter (cliquer sur l'image pour zoomer üîé) :

![Cheasheet `Pandas`](https://cdn-images-1.medium.com/max/2000/1*YhTbz8b8Svi22wNVvqzneg.jpeg){width=70%}


::: {.cell .markdown}
```{=html}
<div class="alert alert-success" role="alert">
<h3 class="alert-heading"><i class="fa-solid fa-pencil"></i> Exercice 2: D√©couverte des verbes de `dplyr` pour manipuler des donn√©es</h3>
```

En premier lieu, on propose de se familiariser avec les op√©rations sur
les colonnes.

1. Cr√©er un _dataframe_ `emissions_copy` ne conservant que les colonnes
`INSEE commune`, `Commune`, `Autres transports` et `Autres transports international`

<details>
<summary>
Indice pour cette question
</summary>

![](./select_pandas.png)

</details>

2. Comme les noms de variables sont peu pratiques, les renommer de la
mani√®re suivante:
    + `INSEE commune` $\to$ `code_insee`
    + `Autres transports` $\to$ `transports`
    + `Autres transports international` $\to$ `transports_international`

<details>
<summary>
Indice pour cette question
</summary>

![](./rename_pandas.png)

</details>

3. On propose, pour simplifier, de remplacer les valeurs manquantes (`NA`)
par la valeur 0[^na]. Utiliser la
m√©thode [`fillna`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html)
pour transformer les valeurs manquantes en 0.

4. Cr√©er les variables suivantes:
    - `dep`: le d√©partement. Celui-ci peut √™tre cr√©√© gr√¢ce aux deux premiers caract√®res de `code_insee` en appliquant la m√©thode `str`[^notecorse]
    - `transports_total`: les √©missions du secteur transports (somme des deux variables)

<details>
<summary>
Indice pour cette question
</summary>

![](mutate_pandas.png)

</details>


5. Ordonner les donn√©es du plus gros pollueur au plus petit 
puis ordonner les donn√©es 
du plus gros pollueur au plus petit par d√©partement (du 01 au 95). 

<details>
<summary>
Indice pour cette question
</summary>

![](arrange_pandas.png)

</details>


6. Calculer les √©missions totales par d√©partements

<details>
<summary>
Indice pour cette question
</summary>

* _"Grouper par"_ = `groupby`
* _"√©missions totales"_ = `agg({***: "sum"})`

</details>


```{=html}
</div>
```
:::

```{python}
# Question 1
emissions_copy = emissions.loc[
  :,
  ["INSEE commune", "Commune", "Autres transports", "Autres transports international"]
]

# Question 2
emissions_copy = emissions_copy.rename({
  "INSEE commune": "code_insee",
  "Autres transports": "transports",
  "Autres transports international": "transports_international"
}, axis = 1)

# Question 3
emissions_copy = emissions_copy.fillna(0)

# Question 4
emissions_copy['dep'] = emissions_copy['code_insee'].str[:2]
emissions_copy['transports_total'] = emissions_copy['transports'] + emissions_copy['transports_international']

# Question 5
emissions_copy.sort_values("transports_total", ascending = False)
emissions_copy.sort_values(by = ["dep","transports_total"], ascending = [True, False])
```

```{python}
df = emissions.copy()
```


<!--- old ----->

Pour les donn√©es de cadrage au niveau communal (source Insee), le package `pynsee` facilite grandement la vie. 
La liste des donn√©es disponibles est [ici](https://inseefrlab.github.io/DoReMIFaSol/articles/donnees_dispo.html).
En l'occurrence, on va utiliser les donn√©es Filosofi (donn√©es de revenus) au niveau communal de 2016. 
Le point d'entr√©e principal de la fonction `pynsee` est la fonction `download_file`.
Le code pour t√©l√©charger les donn√©es est le suivant :

```{python}
#| echo: true

df_city = pynsee.download.download_file("FILOSOFI_COM_2016")
```

::: {.cell .markdown}
```{=html}
<div class="alert alert-info" role="alert">
<h3 class="alert-heading"><i class="fa-solid fa-comment"></i> Note</h3>
```

La fonction `download_file` attend un identifiant unique
pour savoir quelle base de donn√©es aller chercher et
restructurer depuis le
site [insee.fr](https://www.insee.fr/fr/accueil). 

Pour conna√Ætre la liste des bases disponibles, vous
pouvez utiliser la fonction `meta = pynsee.get_file_list()`. 
Celle-ci renvoie un `DataFrame` dans lequel on peut
rechercher, par exemple gr√¢ce √† une recherche
de mot cl√©: 

```{python}
#| echo: true

meta = pynsee.get_file_list()
meta.loc[meta['label'].str.contains(r"Filosofi.*2016")]
```

Ici, `meta['label'].str.contains(r"Filosofi.*2016")` signifie:
"_`pandas` trouve moi tous les labels o√π sont contenus les termes Filosofi et 2016._"
 (`.*` signifiant "_peu m'importe le nombre de mots ou caract√®res entre_")


```{=html}
</div>
```
:::


Cette premi√®re approche exploratoire donne une id√©e assez pr√©cise de la mani√®re dont les donn√©es sont organis√©es.
On remarque ainsi une diff√©rence entre `df` et `df_city` quant aux valeurs manquantes :
la premi√®re base est relativement compl√®te, la seconde comporte beaucoup de valeurs manquantes.
Autrement dit, si on d√©sire exploiter `df_city`, il faut faire attention √† la variable choisie.


::: {.cell .markdown}
```{=html}
<div class="alert alert-success" role="alert">
<h3 class="alert-heading"><i class="fa-solid fa-pencil"></i> Exercice 2: structure des donn√©es</h3>
```


La premi√®re chose √† v√©rifier est le format des donn√©es,
afin d'identifier des types de variables qui ne conviennent pas

Ici, comme c'est `pandas` qui a g√©r√© automatiquement les types de variables,
il y a peu de chances que les types ne soient pas ad√©quats mais une v√©rification ne fait pas de mal.

1. V√©rifier les types des variables.
S'assurer que les types des variables communes aux deux bases sont coh√©rents.
Pour les variables qui ne sont pas en type `float` alors qu'elles devraient l'√™tre, modifier leur type.

Ensuite, on v√©rifie les dimensions des `DataFrames` et la structure de certaines variables cl√©s.
En l'occurrence, les variables fondamentales pour lier nos donn√©es sont les variables communales.
Ici, on a deux variables g√©ographiques: un code commune et un nom de commune. 

2. V√©rifier les dimensions des DataFrames

3. V√©rifier le nombre de valeurs uniques des variables g√©ographiques dans chaque base. Les r√©sultats apparaissent-ils coh√©rents ?

4. Identifier dans `df_city` les noms de communes qui correspondent √† plusieurs codes communes et s√©lectionner leurs codes. En d'autres termes, identifier les `CODGEO` tels qu'il existe des doublons de `LIBGEO` et les stocker dans un vecteur `x` (conseil: faire attention √† l'index de `x`)

On se focalise temporairement sur les observations o√π le libell√© comporte plus de deux codes communes diff√©rents

5. Regarder dans `df_city` ces observations

6. Pour mieux y voir, r√©ordonner la base obtenue par order alphab√©tique

7. D√©terminer la taille moyenne (variable nombre de personnes: `NBPERSMENFISC16`) et quelques statistiques descriptives de ces donn√©es.
Comparer aux m√™mes statistiques sur les donn√©es o√π libell√©s et codes communes co√Øncident

8. V√©rifier les grandes villes (plus de 100 000 personnes),
la proportion de villes pour lesquelles un m√™me nom est associ√© √† diff√©rents codes commune.

9. V√©rifier dans `df_city` les villes dont le libell√© est √©gal √† Montreuil.
V√©rifier √©galement celles qui contiennent le terme 'Saint-Denis'

```{=html}
</div>
```
:::

```{python}
#| echo: false

# Question 1
print("base df")
print(df.dtypes)
print("\nbase df_city")
print(df_city.dtypes)

# Il faut changer les types de toutes les variables de df_city √† l'exception des codes et libell√©s de commune.
df_city[df_city.columns[2:len(df_city.columns)]] = df_city[df_city.columns[2:len(df_city.columns)]].apply(pd.to_numeric)
print("\nbase df_city corrig√©e")
print(df_city.dtypes)
```

```{python}
#| echo: false

# Question 2
print(df.shape)
print(df_city.shape)
```

```{python}
#| echo: false

# Question 3
print(df[['INSEE commune', 'Commune']].nunique())
print(df_city[['CODGEO', 'LIBGEO']].nunique())
# R√©sultats dont l'ordre de grandeur est proche. Dans les deux cas, #(libelles) < #(code)
```

```{python}
#| echo: false

# Question 4
x = df_city.groupby('LIBGEO').count()['CODGEO']
x = x[x>1]
x = x.reset_index()
x
```

```{python}
#| echo: false
# Question 5
df_city[df_city['LIBGEO'].isin(x['LIBGEO'])]
```

```{python}
#| echo: false
# Question 6
df_city[df_city['LIBGEO'].isin(x['LIBGEO'])].sort_values('LIBGEO')
```

```{python}
#| echo: false
# Question 7
print(df_city[df_city['LIBGEO'].isin(x['LIBGEO'])]['NBPERSMENFISC16'].describe())
print(df_city[~df_city['LIBGEO'].isin(x['LIBGEO'])]['NBPERSMENFISC16'].describe())
```

```{python}
#| echo: false
# Question 8
df_big_city = df_city[df_city['NBPERSMENFISC16']>100000].copy()
df_big_city['probleme'] = df_big_city['LIBGEO'].isin(x['LIBGEO'])
df_big_city['probleme'].mean()
df_big_city[df_big_city['probleme']]
```

```{python}
#| echo: false
# Question 9
df_city[df_city.LIBGEO == 'Montreuil']
df_city[df_city.LIBGEO.str.contains('Saint-Denis')].head(10)
```

Ce petit exercice permet de se rassurer car les libell√©s dupliqu√©s
sont en fait des noms de commune identiques mais qui ne sont pas dans le m√™me d√©partement.
Il ne s'agit donc pas d'observations dupliqu√©es.
On se fiera ainsi aux codes communes, qui eux sont uniques.

## Les indices

Les indices sont des √©l√©ments sp√©ciaux d'un DataFrame puisqu'ils permettent d'identifier certaines observations.
Il est tout √† fait possible d'utiliser plusieurs indices, par exemple si on a des niveaux imbriqu√©s.


::: {.cell .markdown}
```{=html}
<div class="alert alert-success" role="alert">
<h3 class="alert-heading"><i class="fa-solid fa-pencil"></i> Exercice 3: Les indices</h3>
```


A partir de l'exercice pr√©c√©dent, on peut se fier aux codes communes.

1. Fixer comme indice la variable de code commune dans les deux bases.
Regarder le changement que cela induit sur le *display* du `DataFrame`

2. Les deux premiers chiffres des codes communes sont le num√©ro de d√©partement.
Cr√©er une variable de d√©partement `dep` dans `df` et dans `df_city`

3. Calculer les √©missions totales par secteur pour chaque d√©partement.
Mettre en log ces r√©sultats dans un objet `df_log`.
Garder 5 d√©partements et produire un `barplot`

4. Repartir de `df`.
Calculer les √©missions totales par d√©partement et sortir la liste
des 10 principaux √©metteurs de CO2 et des 5 d√©partements les moins √©metteurs.
Sans faire de *merge*,
regarder les caract√©ristiques de ces d√©partements (population et niveau de vie)

```{=html}
</div>
```
:::

```{python}
#| echo: false
# Question 1
display(df)
df = df.set_index('INSEE commune')
display(df)

display(df_city)
df_city =  df_city.set_index('CODGEO') 
display(df_city)
```

```{python}
#| echo: false
# Question 2
df['dep'] = df.index.str[:2]
df_city['dep'] = df_city.index.str[:2]
```

```{python}
#| echo: false
# Question 3
df_log = df.groupby('dep').sum(numeric_only = True).apply(np.log)
print(df_log.head())
df_log.sample(5).plot(kind = "bar")
```

```{python}
#| echo: false
# Question 4
## Emissions totales par d√©partement (df)
df_emissions = df.reset_index().set_index(['INSEE commune','dep']).sum(axis = 1, numeric_only = True).groupby('dep').sum(numeric_only = True)
#df.reset_index().groupby('dep').sum(numeric_only = True).sum(axis = 1, numeric_only = True).head() #version simplifiee ?
gros_emetteurs = df_emissions.sort_values(ascending = False).head(10)
petits_emetteurs = df_emissions.sort_values().head(5)

## Caract√©ristiques des d√©partements (df_city)
print("gros emetteurs")
print(df_city[df_city['dep'].isin(gros_emetteurs.index)][['NBPERSMENFISC16','MED16']].mean())
print("\npetits emetteurs")
print(df_city[df_city['dep'].isin(petits_emetteurs.index)][['NBPERSMENFISC16','MED16']].mean())
# Les petits emetteurs sont en moyenne plus pauvres et moins peupl√©s que les gros emetteurs
```

::: {.cell .markdown}
```{=html}
<div class="alert alert-success" role="alert">
<h3 class="alert-heading"><i class="fa-solid fa-pencil"></i> Exercice 4: performance des indices</h3>
```

Un des int√©r√™ts des indices est qu'ils permettent des agr√©gations efficaces. 

1. Repartir de `df` et cr√©er une copie `df_copy = df.copy()` et `df_copy2 = df.copy()` afin de ne pas √©craser le DataFrame `df`

2. Utiliser la variable `dep` comme indice pour `df_copy` et retirer tout index pour `df_copy2`

3. Importer le module `timeit` et comparer le temps d'ex√©cution de la somme par secteur, pour chaque d√©partement, des √©missions de CO2

```{=html}
</div>
```
:::

```{python}
#| echo: false
# Question 1
df_copy = df.copy()
df_copy2 = df.copy()
```

```{python}
#| echo: false
# Question 2
df_copy = df_copy.set_index('dep')
df_copy2 = df_copy2.reset_index()
```

```{python}
#| echo: false
#| eval: false
# Question 3
%timeit df_copy.drop('Commune', axis = 1).groupby('dep').sum(numeric_only = True)
%timeit df_copy2.drop('Commune', axis = 1).groupby('dep').sum(numeric_only = True)
# Le temps d'ex√©cution est plus lent sur la base sans index par d√©partement.
```

## Restructurer les donn√©es

On pr√©sente g√©n√©ralement deux types de donn√©es : 
    
* format __wide__ : les donn√©es comportent des observations r√©p√©t√©es, pour un m√™me individu (ou groupe), dans des colonnes diff√©rentes 
* format __long__ : les donn√©es comportent des observations r√©p√©t√©es, pour un m√™me individu, dans des lignes diff√©rentes avec une colonne permettant de distinguer les niveaux d'observations

Un exemple de la distinction entre les deux peut √™tre pris √† l'ouvrage de r√©f√©rence d'Hadley Wickham, *R for Data Science*:

![](https://d33wubrfki0l68.cloudfront.net/3aea19108d39606bbe49981acda07696c0c7fcd8/2de65/images/tidy-9.png)


L'aide m√©moire suivante aidera √† se rappeler les fonctions √† appliquer si besoin:

![](reshape.png)

Le fait de passer d'un format *wide* au format *long* (ou vice-versa)
peut √™tre extr√™mement pratique car certaines fonctions sont plus ad√©quates sur une forme de donn√©es ou sur l'autre.
En r√®gle g√©n√©rale, avec `Python` comme avec `R`, les formats *long* sont souvent pr√©f√©rables.

::: {.cell .markdown}
```{=html}
<div class="alert alert-success" role="alert">
<h3 class="alert-heading"><i class="fa-solid fa-pencil"></i> Exercice 5: Restructurer les donn√©es: wide to long</h3>
```

1. Cr√©er une copie des donn√©es de l'`ADEME` en faisant `df_wide = df.copy()`

2. Restructurer les donn√©es au format *long* pour avoir des donn√©es d'√©missions par secteur en gardant comme niveau d'analyse la commune (attention aux autres variables identifiantes).

3. Faire la somme par secteur et repr√©senter graphiquement

4. Garder, pour chaque d√©partement, le secteur le plus polluant

```{=html}
</div>
```
:::

```{python}
#| echo: false
#| label: question1
# Question 1

df_wide = df.copy()
df_wide[['Commune','dep', "Agriculture", "Tertiaire"]].head() 
```

```{python}
#| echo: false
#| label: question2
# Question 2

df_wide.reset_index().melt(id_vars = ['INSEE commune','Commune','dep'],
                          var_name = "secteur", value_name = "emissions")
```

```{python}
#| echo: false
#| label: question3
# Question 3

(df_wide.reset_index()
 .melt(id_vars = ['INSEE commune','Commune','dep'],
                          var_name = "secteur", value_name = "emissions")
 .groupby('secteur').sum(numeric_only = True).plot(kind = "barh")
)
```

```{python}
#| echo: false
#| label: question4
# Question 4

(df_wide.reset_index().melt(id_vars = ['INSEE commune','Commune','dep'],
                          var_name = "secteur", value_name = "emissions")
 .groupby(['secteur','dep']).sum(numeric_only=True).reset_index().sort_values(['dep','emissions'], ascending = False).groupby('dep').head(1)
)
```

::: {.cell .markdown}
```{=html}
<div class="alert alert-success" role="alert">
<h3 class="alert-heading"><i class="fa-solid fa-pencil"></i> Exercice 6: long to wide</h3>
```

Cette transformation est moins fr√©quente car appliquer des fonctions par groupe, comme nous le verrons par la suite, est tr√®s simple. 

1. Repartir de `df_wide = df.copy()

2. Reconstruire le DataFrame, au format long, des donn√©es d'√©missions par secteur en gardant comme niveau d'analyse la commune puis faire la somme par d√©partement et secteur

3. Passer au format *wide* pour avoir une ligne par secteur et une colonne par d√©partement

4. Calculer, pour chaque secteur, la place du d√©partement dans la hi√©rarchie des √©missions nationales

5. A partir de l√†, en d√©duire le rang m√©dian de chaque d√©partement dans la hi√©rarchie des √©missions et regarder les 10 plus mauvais √©l√®ves, selon ce crit√®re.

```{=html}
</div>
```
:::

```{python}
#| echo: false
# Question 1

df_wide = df.copy()
```

```{python}
#| echo: false
# Question 2

df_long_agg = (df_wide.reset_index()
 .melt(id_vars = ['INSEE commune','Commune','dep'],
                          var_name = "secteur", value_name = "emissions").groupby(["dep", "secteur"]).sum(numeric_only = True)
)

df_long_agg.head()
```

```{python}
#| echo: false
# Question 3

df_wide_agg = df_long_agg.reset_index().pivot_table(values = "emissions", index = "secteur", columns = "dep")

df_wide_agg.head()
```

```{python}
#| echo: false
# Question 4

df_wide_agg.rank(axis = 1)
```

```{python}
#| echo: false
# Question 5

df_wide_agg.rank(axis = 1).median().nlargest(10)
```

## Combiner les donn√©es

Une information que l'on cherche √† obtenir s'obtient de moins en moins √† partir d'une unique base de donn√©es. Il devient commun de devoir combiner des donn√©es issues de sources diff√©rentes. Nous allons ici nous focaliser sur le cas le plus favorable qui est la situation o√π une information permet d'apparier de mani√®re exacte deux bases de donn√©es (autrement nous serions dans une situation, beaucoup plus complexe, d'appariement flou). La situation typique est l'appariement entre deux sources de donn√©es selon un identifiant individuel ou un identifiant de code commune, ce qui est notre cas.

Il est recommand√© de lire [ce guide assez complet sur la question des jointures avec R](https://www.book.utilitr.org/03_fiches_thematiques/fiche_joindre_donnees) qui donne des recommandations √©galement utiles en `python`.

On utilise de mani√®re indiff√©rente les termes *merge* ou *join*. Le deuxi√®me terme provient de la syntaxe SQL. En `pandas`, dans la plupart des cas, on peut utiliser indiff√©remment `df.join` et `df.merge`

![](pandas_join.png)


::: {.cell .markdown}
```{=html}
<div class="alert alert-success" role="alert">
<h3 class="alert-heading"><i class="fa-solid fa-pencil"></i> Exercice 7: Calculer l'empreinte carbone par habitant</h3>
```

1. Cr√©er une variable `emissions` qui correspond aux √©missions totales d'une commune

2. Faire une jointure √† gauche entre les donn√©es d'√©missions et les donn√©es de cadrage. Comparer les √©missions moyennes des villes sans *match* (celles dont des variables bien choisies de la table de droite sont NaN) avec celles o√π on a bien une valeur correspondante dans la base Insee

3. Faire un *inner join* puis calculer l'empreinte carbone (l'√©mission rapport√©e au nombre de m√©nages fiscaux) dans chaque commune. Sortir un histogramme en niveau puis en log et quelques statistiques descriptives sur le sujet. 

4. Regarder la corr√©lation entre les variables de cadrage et l'empreinte carbone. Certaines variables semblent-elles pouvoir potentiellement influer sur l'empreinte carbone ?

```{=html}
</div>
```
:::

```{python}
#| echo: false
# Question 1

df['emissions'] = df.sum(axis = 1, numeric_only = True)
```

```{python}
#| echo: false
# Question 2

df_merged = df.merge(df_city, how = "left", left_index = True, right_index = True)

print(df_merged[df_merged['LIBGEO'].isna()]['emissions'].mean())
print(df_merged[~df_merged['LIBGEO'].isna()]['emissions'].mean())

```

```{python}
#| echo: false
# Question 3

df_merged = df.merge(df_city, left_index = True, right_index = True)
df_merged['empreinte'] = df_merged['emissions']/df_merged['NBPERSMENFISC16']

df_merged['empreinte'].plot(kind ="hist")
np.log(df_merged['empreinte']).plot.hist()
df_merged['empreinte'].describe()
```


```{python}
#| echo: false
# Question 4

df_merged.corr(numeric_only=True)['empreinte'].nlargest(10)
# Les variables en lien avec le transport. 
```

```{python}
#| output: false
#| echo: false
np.log(df_merged['empreinte']).plot.hist()
plt.savefig("featured_tp_pandas.png")
```



## Exercices bonus

Les plus rapides d'entre vous sont invit√©s √† aller un peu plus loin en s'entra√Ænant avec des exercices bonus qui proviennent du  [site de Xavier Dupr√©](http://www.xavierdupre.fr/app/ensae_teaching_cs/helpsphinx3). 3 notebooks en lien avec `numpy` et `pandas` vous y sont propos√©s : 

1. Calcul Matriciel, Optimisation : [√©nonc√©](http://www.xavierdupre.fr/app/ensae_teaching_cs/helpsphinx3/notebooks/td2a_cenonce_session_2A.html) / [corrig√©](http://www.xavierdupre.fr/app/ensae_teaching_cs/helpsphinx3/notebooks/td2a_correction_session_2A.html)
2. DataFrame et Graphes : [√©nonc√©](http://www.xavierdupre.fr/app/ensae_teaching_cs/helpsphinx3/notebooks/td2a_cenonce_session_1.html) / [corrig√©](http://www.xavierdupre.fr/app/ensae_teaching_cs/helpsphinx3/notebooks/td2a_correction_session_1.html)
3. Pandas et it√©rateurs : [√©nonc√©](http://www.xavierdupre.fr/app/ensae_teaching_cs/helpsphinx3/notebooks/pandas_iterator.html) / [corrig√©](http://www.xavierdupre.fr/app/ensae_teaching_cs/helpsphinx3/notebooks/pandas_iterator_correction.html)

