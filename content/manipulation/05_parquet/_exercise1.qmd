::: {.exercise collapse="false"}
# Partie 1 : Du `CSV` au `Parquet`

* Créer un notebook `benchmark_parquet.ipynb` afin de réaliser les différentes comparaisons de performance de l'application
* Créons notre décorateur, en charge de _benchmarker_ le code `Python`:

<details>

<summary>
Dérouler pour retrouver le code du décorateur permettant de mesurer la performance
</summary>

{{< include "content/manipulation/05_parquet/_exercise1_profiler.qmd" >}}

</details>

* Reprendre ce code pour encapsuler un code de construction d'une pyramide des âges dans une fonction `process_csv_appli1`

<details>

<summary>
Dérouler pour récupérer le code pour mesurer les performances de la lecture en CSV
</summary>

{{< include "content/manipulation/05_parquet/_exercise1_measure.qmd" >}}

</details>


* Exécuter `process_csv_appli1()` et `process_csv_appli1(return_output=True)`

* Sur le même modèle, construire une fonction `process_parquet_appli1` basée cette fois sur le fichier `data/RPindividus_24.parquet` chargé avec la fonction [read_parquet](https://pandas.pydata.org/docs/reference/api/pandas.read_parquet.html) de `Pandas`
* Comparer les performances (temps d'exécution et allocation mémoire) de ces deux méthodes grâce à la fonction.

<details>

<summary>
Correction complète
</summary>

{{< include "content/manipulation/05_parquet/_exercise1_correction.qmd" >}}

</details>

:::

_❓️ Quelle semble être la limite de la fonction `read_parquet` ?_

On gagne déjà un temps conséquent en lecture mais on ne bénéficie pas vraiment de l'optimisation permise par `Parquet` car on transforme les données directement après la lecture en `DataFrame` `Pandas`. On n'utilise donc pas l'une des fonctionnalités principales du format `Parquet`, qui explique ses excellentes performances: le _predicate pushdown_ qui consiste à optimiser notre traitement pour faire remonter, le plus tôt possible, les filtres sur les colonnes pour ne garder que celles vraiment utilisées dans le traitement.
