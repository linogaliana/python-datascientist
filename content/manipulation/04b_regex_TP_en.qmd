
# Generalization with `pandas`

`pandas` methods are extensions of those in `re` that avoid looping to check each line with a regex. In practice, when working with `DataFrames`, the `pandas` API is preferred over `re`. Code of the form `df.apply(lambda x: re.<function>(<regex>,x), axis = 1)` should be avoided as it is very inefficient.

The names sometimes change slightly compared to their `re` equivalents.

| Method          | Description |
|-----------------|-------------|
| `str.count()`   | Count the number of occurrences of the pattern in each line |
| `str.replace()` | Replace the pattern with another value. Vectorized version of `re.sub()` |
| `str.contains()`| Test if the pattern appears, line by line. Vectorized version of `re.search()` |
| `str.extract()` | Extract groups that match a pattern and return them in a column |
| `str.findall()` | Find and return all occurrences of a pattern. If a line contains multiple matches, a list is returned. Vectorized version of `re.findall()` |

Additionally, there are `str.split()` and `str.rsplit()` methods which are quite useful.

::: {.cell .markdown}
```{=html}
<details><summary>Example of <code>str.count</code> ðŸ‘‡</summary>
```

You can count the number of times a pattern appears with `str.count`:

```{python}
df = pd.DataFrame({"a": ["toto", "titi"]})
df['a'].str.count("to")
```

```{=html}
</details>
```
:::

::: {.cell .markdown}
```{=html}
<details><summary>Example of <code>str.replace</code> ðŸ‘‡</summary>
```

Replace the pattern _"ti"_ at the end of the string:

```{python}
df = pd.DataFrame({"a": ["toto", "titi"]})
df['a'].str.replace("ti$", " punch")
```

```{=html}
</details>
```
:::


::: {.cell .markdown}
```{=html}
<details><summary>Example of <code>str.contains</code> ðŸ‘‡</summary>
```

Check the cases where our line ends with _"ti"_:

```{python}
df = pd.DataFrame({"a": ["toto", "titi"]})
df['a'].str.contains("ti$")
```

```{=html}
</details>
```
:::

::: {.cell .markdown}
```{=html}
<details><summary>Example of <code>str.findall</code> ðŸ‘‡</summary>
```

```{python}
df = pd.DataFrame({"a": ["toto", "titi"]})
df['a'].str.findall("to")
```

```{=html}
</details>
```
:::

::: {.warning}

Currently, it is not necessary to add the `regex = True` argument, but this should be the case in a future version of `pandas`. It might be worth getting into the habit of adding it.

:::



# For more information

- [Collaborative documentation on `R` named `utilitR`](https://www.book.utilitr.org/03_fiches_thematiques/fiche_donnees_textuelles#regex)
- [_R for Data Science_](https://r4ds.hadley.nz/regexps.html)
- [_Regular Expression HOWTO_ in the official `Python` documentation](https://docs.python.org/3/howto/regex.html)
- The reference tool [https://regex101.com/] for testing regular expressions
- [This site](https://ole.michelsen.dk/tools/regex/) which has a cheat sheet at the bottom of the page.
- The games on [Regex Crossword](https://regexcrossword.com/) allow you to learn regular expressions while having fun

# Additional exercises

## Extracting email addresses

This is a classic use of _regex_

```{python}
text_emails = 'Hello from toto@gmail.com to titi.grominet@yahoo.com about the meeting @2PM'
```

::: {.exercise}
## Exercise: Extracting email addresses

Use the structure of an email address `[XXXX]@[XXXX]` to retrieve this content.

:::


```{python}
#| echo: false

# \S` represents any non-space character 
# `+` denotes the presence of the preceding set of characters between 1 and infinity
list_emails = re.findall('\S+@\S+', text_emails)     
print(list_emails)
```

## Extracting years from a `pandas` `DataFrame`

The general objective of the exercise is to clean columns in a DataFrame using regular expressions.

::: {.exercise}
## Exercise

The dataset in question contains books from the British Library and some related information. The dataset is available here: https://raw.githubusercontent.com/realpython/python-data-cleaning/master/Datasets/BL-Flickr-Images-Book.csv

The "Date of Publication" column is not always a year; sometimes there are other details. The goal of the exercise is to have **a clean book publication date** and to examine the **distribution of publication years**.

To do this, you can:

* Either choose to perform the exercise without help. Your **reading of the instructions ends here**. You should carefully examine the dataset and transform it yourself.

* Or follow the step-by-step instructions below.

```{=html}
<details><summary>Guided version ðŸ‘‡</summary>
```

1. Read the data from the URL `https://raw.githubusercontent.com/realpython/python-data-cleaning/master/Datasets/BL-Flickr-Images-Book.csv`. Be careful with the separator.
2. Keep only the columns `['Identifier', 'Place of Publication', 'Date of Publication', 'Publisher', 'Title', 'Author']`.
3. Observe the _'Date of Publication'_ column and note the issues with some rows (e.g., row 13).
4. Start by looking at the number of missing values. We cannot do better after regex, and normally we should not have fewer...
5. Determine the regex pattern for a publication date. Presumably, there are 4 digits forming a year. Use the `str.extract()` method with the `expand = False` argument (to keep only the first date matching our pattern)?
6. We have 2 `NaN` values that were not present at the start of the exercise. What are they and why?
7. What is the distribution of publication dates in the dataset? You can, for example, display a histogram using the `plot` method with the `kind = "hist"` argument.

```{=html}
</summary>
```

:::


```{python}
#| echo: false

# Question 1
data_books = pd.read_csv('https://raw.githubusercontent.com/realpython/python-data-cleaning/master/Datasets/BL-Flickr-Images-Book.csv', sep=',')
```

```{python}
#| echo: false

# Question 2
data_books = data_books[['Identifier', 'Place of Publication',
       'Date of Publication', 'Publisher', 'Title', 'Author']]
```

Here is an example of the problem to detect in question 3:

```{python}
#| echo: false

# Question 3
data_books[['Date of Publication',"Title"]].iloc[13:20]
```

```{python}
#| echo: false

# Question 4
data_books['Date of Publication'].isna().sum()
```

With our regex (question 5), we obtain a `DataFrame` that is more in line with our expectations:

```{python}
#| echo: false

# Question 5
expression = "([0-2][0-9][0-9][0-9])"
data_books['year'] = data_books['Date of Publication'].str.extract(expression, expand=False)

data_books.loc[~(data_books['Date of Publication'] == data_books['year']), ['Date of Publication', 'year']]
```

As for the new `NaN` values, they are rows that did not contain any strings resembling years:

```{python}
#| echo: false
data_books.loc[~data_books['Date of Publication'].isna() & data_books['year'].isna(), ['Date of Publication', 'year']]
```

Finally, we obtain the following histogram of publication dates:

```{python}
#| echo: false
pd.to_numeric(data_books['year'], downcast='integer').plot(kind ="hist")
```
