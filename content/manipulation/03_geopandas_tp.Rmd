---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.6.0
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
title: "Pratique de geopandas: données vélib"
date: 2020-07-09T13:00:00Z
draft: false
weight: 50
output: 
  html_document:
    keep_md: true
    self_contained: true
slug: geopandasTP
---

```{r setup, include=FALSE}  
library(knitr)  
library(reticulate)  
knitr::knit_engines$set(python = reticulate::eng_python)
knitr::opts_chunk$set(eval = FALSE, include = FALSE, echo = FALSE)
```

```{python, include = FALSE}
import os
os.environ['QT_QPA_PLATFORM_PLUGIN_PATH'] = 'C:/Users/W3CRK9/AppData/Local/r-miniconda/envs/r-reticulate/Library/plugins/platforms'
```



# Lire et enrichir des données spatiales

Dans cette partie, nous utiliserons la fonction suivante, qui facilite 
le téléchargement et le dézippage des données proposées sur `data.gouv`:

```{python, echo = TRUE, include = TRUE}
import requests
import tempfile
import zipfile

temporary_location = tempfile.gettempdir()

def download_unzip(url, dirname = tempfile.gettempdir(), destname = "borders"):
  myfile = requests.get(url)
  open(dirname + '/' + destname + '.zip', 'wb').write(myfile.content)
  with zipfile.ZipFile(dirname + '/' + destname + '.zip', 'r') as zip_ref:
      zip_ref.extractall(dirname + '/' + destname)
```



**Exercice 1: lire et explorer la structure de fichiers géographiques**

1. Utiliser la fonction `download_unzip` avec l'url <https://www.data.gouv.fr/fr/datasets/r/07b7c9a2-d1e2-4da6-9f20-01a7b72d4b12>
pour télécharger les données communales.
2. Importer le fichier avec la package `geopandas`
(si vous avez laissé les paramètres par défaut,
le fichier devrait
être à l'emplacement `temporary_location + "/borders/communes-20190101.json"`).
Vous pouvez le nommer `communes_borders`
3. Regarder les premières lignes des données. Identifier la différence avec
un DataFrame standard. 
4. Afficher l'attribut `crs` de `communes_borders`. Ce dernier contrôle la
transformation de l'espace tridimensionnel terrestre en une surface plane. 
5. Afficher les communes de l'Aveyron (département 12) et utiliser la méthode
`plot`
6. Réprésenter la carte de Paris : quel est le problème ?

```{python}
url = "https://www.data.gouv.fr/fr/datasets/r/07b7c9a2-d1e2-4da6-9f20-01a7b72d4b12"
download_unzip(url)
communes_borders = gpd.read_file(temporary_location + "/borders/communes-20190101.json")
communes_borders.head()
communes_borders.crs
```


```{python}
communes_borders[communes_borders.insee.str.startswith("12")].plot()
```

```{python}
communes_borders[communes_borders.insee.str.startswith("75")].plot()
```

En effet, on ne dispose ainsi pas des limites des arrondissements parisiens, ce
qui appauvrit grandement la carte de Paris. On peut les récupérer directement 
depuis le site d'open data du grand Paris:


**Exercice 2: compléter des données spatiales issues de sources différentes**

1. Importer les données de découpage des arrondissements parisiens à l'adresse
<https://opendata.paris.fr/explore/dataset/arrondissements/download/?format=geojson&timezone=Europe/Berlin&lang=fr>
2. Vérifier sur une carte que les découpages des arrondissements sont bien présents
2. Vérifier l'attribut `crs`. Est-il cohérent avec celui des données communales ?
3. Retirer Paris du jeu de données communales et utiliser les arrondissements
pour enrichir (nommer l'objet obtenu `data_borders`). Ici, on peut ne pas se
soucier de la variable commune de superficie aux niveaux différents car on
va la recréer. En revanche, renommer la variable `c_arinsee` en `insee` avec
la méthode `rename` et faire attention aux types des variables
4. Créer une variable `dep` stockant le département
4. Représenter les communes de la petite couronne parisienne (75, 92, 93, 94)


```{python}
arrondissements = gpd.read_file("https://opendata.paris.fr/explore/dataset/arrondissements/download/?format=geojson&timezone=Europe/Berlin&lang=fr")
arrondissements.plot()
communes_borders.crs == arrondissements.crs
arrondissements = arrondissements.rename(columns = {"c_arinsee": "insee"})
arrondissements['dep'] = "75"
data_paris = communes_borders[~communes_borders.insee.str.startswith("75")].append(arrondissements)
```

```{python}
data_paris['dep'] = data_paris.insee.astype(str).str[:2]
data_paris[data_paris['dep'].isin(['75','92','93','94'])].plot()
```

# Utiliser des données géographiques comme des couches
graphiques

Souvent, le découpage communal ne sert qu'en fond de cartes, pour donner des
repères. En complément de celui-ci, on peut désirer exploiter
un autre jeu de données. On va partir des données de localisation des
stations velib, 
disponibles [sur le site d'open data de la ville de Paris](https://opendata.paris.fr/explore/dataset/velib-emplacement-des-stations/table/) et 
requêtables directement par l'url
<https://opendata.paris.fr/explore/dataset/velib-emplacement-des-stations/download/?format=geojson&timezone=Europe/Berlin&lang=fr>


**Exercice 3: importer et explorer les données velib**

1. Importer les données velib sous le nom station
2. Représenter sur une carte les 100 stations les plus importantes. Vous pouvez également afficher le fonds de carte des arrondissements en ne gardant que les départements de la petite couronne (75, 92, 93, 94).
Cette [page](https://geopandas.org/mapping.html#maps-with-layers) peut vous aider pour afficher plusieurs couches à la fois (nous irons plus loin lors du chapitre XXXX). 
3. (optionnel) Afficher également les réseaux de transport en communs, disponibles [ici](https://data.iledefrance-mobilites.fr/explore/dataset/traces-du-reseau-ferre-idf/map/?location=7,48.69717,2.33167&basemap=jawg.streets). L'url à requêter est
<https://data.iledefrance-mobilites.fr/explore/dataset/traces-du-reseau-ferre-idf/download/?format=geojson&timezone=Europe/Berlin&lang=fr>

```{python}
url = "https://opendata.paris.fr/explore/dataset/velib-emplacement-des-stations/download/?format=geojson&timezone=Europe/Berlin&lang=fr"
stations = gpd.read_file(url)

```

```{python}
base = data_paris[data_paris['dep'] == '75'].plot(alpha = 0.2, edgecolor = 'black')
stations.sort_values('capacity', ascending = False).head(50).plot(ax = base, color = 'red', alpha = 0.6)
```

```{python}
url = "https://data.iledefrance-mobilites.fr/explore/dataset/traces-du-reseau-ferre-idf/download/?format=geojson&timezone=Europe/Berlin&lang=fr"
transports = gpd.read_file(url)


base = data_paris[data_paris['dep'] == '75'].plot(alpha = 0.2, edgecolor = 'black')
stations.sort_values('capacity', ascending = False).head(50).plot(ax = base, color = 'red', alpha = 0.6)
transports[transports['mode'] == "Metro"].plot(ax = base, color = 'black', alpha = 0.3)
```


# Jointures spatiales

Les jointures attributaires fonctionnent comme avec un DataFrame `pandas`. Pour conserver un objet spatial *in fine*, il faut faire attention à utiliser en premier (base de gauche) l'objet `geopandas`. En revanche, l'un des intérêts des objets geopandas est qu'on peut également faire une jointure sur la dimension spatiale.

La documentation à laquelle se référer est [ici](https://geopandas.org/mergingdata.html#spatial-joins). 

**Exercice 4: Associer les stations aux communes et arrondissements auxquels ils appartiennent**

1. Faire une jointure spatiale pour enrichir les données de stations d'informations sur l'environnement.
Appeler cet objet `stations_info`
2. Représenter la carte des stations du 19e arrondissement (s'aider de la variable `c_ar`).
Vous pouvez mettre en fond de carte les arrondissements parisiens. 
3. Compter le nombre de stations velib et le nombre de places velib par arrondissement ou communes (pour vous aider, vous pouvez compléter vos connaissances avec [ce tutoriel](https://pandas.pydata.org/docs/getting_started/intro_tutorials/06_calculate_statistics.html)). Représenter sur une carte chacune des informations
4. Représenter les mêmes informations mais en densité (diviser par la surface de l'arrondissement ou commune en km2)

```{python}
stations_info = gpd.sjoin(stations, data_paris, op = 'within')

base = data_paris[data_paris.dep == "75"].plot(alpha = 0.2, edgecolor = 'k')
stations_info[stations_info['c_ar'] == 19.0].plot(ax = base, color = 'red', alpha = 0.6)
```

```{python}
base = data_paris[data_paris['c_ar'] == 19.0].plot(alpha = 0.2, edgecolor = 'k')
stations_info[stations_info['c_ar'] == 19.0].plot(ax = base, color = 'red', alpha = 0.6)
transports[transports['mode'] == "Metro"].plot(ax = base, color = 'black', alpha = 0.3)

```

```{python}
stations_agg = stations_info.groupby('insee').agg({'stationcode': 'nunique',
                                   'capacity': 'sum'}).reset_index()
data_paris.merge(stations_agg, how = 'inner', suffixes = [None, '_agg']).plot(column = 'capacity')
data_paris.merge(stations_agg, how = 'inner', suffixes = [None, '_agg']).plot(column = 'stationcode')
```

```{python}
df = data_paris.merge(stations_agg, how = 'inner', suffixes = [None, '_agg'])
cols = ['stationcode','capacity']
df = df[[s + '_density' for s in cols]] = df[cols].div(df.to_crs(2158).area*10**(-6), axis = 0)
df.plot(column = 'capacity_density', cmap = 'RdYlBu_r')
df.plot(column = 'capacity_density', cmap = 'plasma_r')
```

**Exercice 5 (optionnel): Relier distance au métro et capacité d'une station**

1. Relier chaque station velib à la station de transport en commun la plus proche
2. Quelle ligne de transport est à proximité du plus de velib ?
3. Calculer la distance de chaque station à la ligne de métro la plus proche. Faire un nuage de points reliant distance au métro et nombre de places en stations

