---
jupyter:
  jupytext:
    formats: ipynb,md
    text_representation:
      extension: .md
      format_name: markdown
      format_version: '1.2'
      jupytext_version: 1.5.2
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
title: "Retour sur numpy"
date: 2020-07-16T13:00:00Z
draft: false
weight: 10
output: 
  html_document:
    keep_md: true
    self_contained: true
slug: "numpy"
---

<!---- reminder_badges("content/manipulation/01_tp_numpy.ipynb") --->
<a href="https://github.com/linogaliana/python-datascientist/blob/master/content/manipulation/01_tp_numpy.ipynb" class="github"><i class="fab fa-github"></i></a>
[![nbviewer](https://img.shields.io/badge/visualize-nbviewer-blue)](https://nbviewer.jupyter.org/github/linogaliana/python-datascientist/blob/master/content/manipulation/01_tp_numpy.ipynb)
[![Onyxia](https://img.shields.io/badge/launch-onyxia-brightgreen)](https://spyrales.sspcloud.fr/my-lab/catalogue/inseefrlab-datascience/jupyter/deploiement)
[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/linogaliana/python-datascientist/master?filepath=content/manipulation/01_tp_numpy.ipynb)
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/github/linogaliana/python-datascientist/blob/master/content/manipulation/01_tp_numpy.ipynb)

```{r setup, include=FALSE}  
library(knitr)  
library(reticulate)  
knitr::knit_engines$set(python = reticulate::eng_python)  
```

```{python, include = FALSE}
import os
os.environ['QT_QPA_PLATFORM_PLUGIN_PATH'] = 'C:/Users/W3CRK9/AppData/Local/r-miniconda/envs/r-reticulate/Library/plugins/platforms'
```


Il est recommandé de régulièrement se référer à
la [cheatsheet numpy](https://www.datacamp.com/community/blog/python-numpy-cheat-sheet) et à la
[doc officielle](https://numpy.org/doc/stable/) en cas de doute
sur une fonction. 

Dans ce chapitre, on ne dérogera pas à la convention qui s'est imposée d'importer `numpy` de la
manière suivante:

```{python import np}
import numpy as np
```

Si les scripts suivants sont exécutés dans un `notebook`, il est recommandé d'utiliser les paramètres suivants
pour contrôler le rendu

~~~python
from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"
~~~


## Le concept d'array

Le concept central de `NumPy` (`Numerical Python`) est
l'**`array`** qui est un tableau de données multidimensionnel.

L'array numpy peut être unidimensionnel et s'apparenter à un vecteur (1d-array),
bidimensionnel et ainsi s'apparenter à une matrice (2d-array) ou, de manière plus générale, 
prendre la forme d'un objet
multidimensionnel (Nd-array). 

Les tableaux simples (uni ou bi-dimensionnels) sont faciles à se représenter seront particulièrement
utilisés dans le paradigme des DataFrames mais 
la possibilité d'avoir des objets multidimensionnel permettra d'exploiter des
structures très complexes.

Un DataFrame sera construit à partir d'une collection
d'array uni-dimensionnels (les variables de la table), ce qui permettra d'effectuer des opérations cohérentes
(et optimisées) avec le type de la variable.


Par rapport à une liste,

* un *array* ne peut contenir qu'un type de données (`integer`, `string`, etc.),
 contrairement à une liste.
* les opérations implémentées par `numpy` seront plus efficaces et demanderont moins
de mémoire



Les données géographiques constitueront une construction un peu plus complexe qu'un DataFrame traditionnel. 
La dimension géographique prend la forme d'un tableau plus profond, au moins bidimensionnel
(coordonnées d'un point). 


## Créer un array

On peut créer un `array` de plusieurs manières. Pour créer un `array` à partir d'une liste,
il suffit d'utiliser la méthode `array`:

```{python}
np.array([1,2,5])
np.array([["a","z","e"],["r","t"],["y"]])
```

Il existe aussi des méthodes pratiques pour créer des array:

* séquences logiques : `np.arange` (suite) ou `np.linspace` (interpolation linéaire entre deux bornes)
* séquences ordonnées: _array_ rempli de zéros, de 1 ou d'un nombre désiré : `np.zeros`, `np.ones` ou `np.full`
* séquences aléatoires: fonctions de génération de nombres aléatoires: `np.rand.uniform`, `np.rand.normal`, etc. 
* tableau sous forme de matrice identité: `np.eye`

Il est possible d'ajouter un argument `dtype` pour contraindre le type du *array*:

```{python}
np.arange(0,10)
np.arange(0,10,3)
np.linspace(0, 1, 5)
np.zeros(10, dtype=int)
np.ones((3, 5), dtype=float)
np.full((3, 5), 3.14)
np.eye(3)
```

**Exercice :**

Générer:

* $X$ une variable aléatoire, 1000 répétitions d'une loi $U(0,1)$
* $Y$ une variable aléatoire, 1000 répétitions d'une loi normale de moyenne nulle et de variance égale à 2
* Vérifier la variance de $Y$ avec `np.var`


```{python, include = FALSE, eval = FALSE}
# Correction
X = np.random.uniform(0,1,1000)
Y = np.random.normal(0,np.sqrt(2),1000)

np.var(Y)
```

## Indexation et slicing

### Logique dans le cas d'un array unidimensionnel

La structure la plus simple imaginable est l'array unidimensionnel:

```{python}
x = np.arange(10)
```

L'indexation est dans ce cas similaire à celle d'une liste: 

* le premier élément est 0
* le énième élément est accessible à la position $n-1$

La logique d'accès aux éléments est ainsi la suivante:

~~~python
x[start:stop:step]
~~~

Avec un *array* unidimensionnel, l'opération de *slicing* (garder une coupe du *array*) est très simple. 
Par exemple, pour garder les *K* premiers éléments d'un *array*, on fera:

~~~python
x[:(K-1)]
~~~

En l'occurrence, on sélectionne le K$^{eme}$ élément en utilisant

~~~python
x[K-1]
~~~

Pour sélectionner uniquement un élément, on fera ainsi:

```{python}
x = np.arange(10)
x[2]
```

Les syntaxes qui permettent de sélectionner des indices particuliers d'une liste fonctionnent également
avec les arrays:

**Exercice**

* Sélectionner les éléments 0,3,5
* Sélectionner les éléments pairs
* Sélectionner tous les éléments sauf le premier
* Sélectionner les 5 premiers éléments


```{python, include = FALSE, eval = FALSE}
# Correction
x[[0,3,5]]
x[::2]
x[-0]
x[:5]
# x2[0,:] # La première ligne
```

### Sur la performance

Un élément déterminant dans la performance de `numpy` par rapport aux listes, lorsqu'il est question de 
*slicing* est qu'un array ne renvoie pas une
copie de l'élément en question (copie qui coûte de la mémoire et du temps) mais simplement une vue de celui-ci
**DETAILS** 

Lorsqu'il est nécessaire d'effectuer une copie, par exemple pour ne pas altérer l'array sous-jacent, on peut 
utiliser la méthode `copy`:

~~~python
x_sub_copy = x[:2, :2].copy()
~~~

-----


### Filtres logiques


Il est également possible, et plus pratique, de sélectionner des données à partir de conditions logiques
(opération qu'on appelle un *boolean mask*)
Cette fonctionalité servira principalement à 
effectuer des opérations de filtre sur les données.

Pour des opérations de comparaison simples, les comparateurs logiques peuvent être suffisants. 
Ces comparaisons fonctionnent aussi sur les tableaux multidimensionnels grâce au
*broadcasting* sur lequel nous reviendront:

```python
x = np.arange(10)
x2 = np.array([[-1,1,-2],[-3,2,0]])
```

```python
x==2
x2<0
```

Pour sélectionner les observations relatives à la condition logique,
il suffit d'utiliser la logique de *slicing* de `numpy` qui fonctionne avec les conditions logiques

**Exercice**

Soit 

```{python}
x = np.random.normal(size=10000)
```

1. Ne conserver que les valeurs dont la valeur absolue est supérieure à 1.96
2. Compter le nombre de valeurs supérieures à 1.96 en valeur absolue et leur proportion dans l'ensemble
3. Sommer les valeurs absolues de toutes les observations supérieures (en valeur absolue) à 1.96
et rapportez les à la somme des valeurs de `x` (en valeur absolue) 



```{python, eval = FALSE, include = FALSE}
# Correction
x = np.random.normal(size=10000)

x2 = x[np.abs(x)>=1.96]

x2.size
x2.size/x.size
np.sum(np.abs(x2))/np.sum(np.abs(x))
```

Lorsque c'est possible, il est recommandé d'utiliser les fonctions logiques de `numpy` (optimisées et 
qui gèrent bien la dimension). Parmi elles, on peut retrouver:

* `count_nonzero`
* `is_nan`
* `any` ; `all` ; notamment avec l'argument `axis`
* `np.array_equal` pour vérifier, élément par élément, l'égalité

**Exercice**

Soit

```{python}
x = np.random.normal(0, size=(3, 4))
```

un *array* multidimensionnel et

```{python}
y = np.array([np.nan, 0, 1])
```

un *array* unidimensionnel présentant une valeur manquante. 

1. Utiliser `count_nonzero` sur `y`
2. Utiliser `is_nan` sur `y` et compter le nombre de valeurs non NaN
2. Vérifier que `x` comporte au moins une valeur positive dans son ensemble, dans chaque array et en

```{python, include = FALSE, eval = FALSE}
# Correction
x = np.random.normal(0, size=(3, 4))
y = np.array([np.nan, 0, 1])

x
y
np.count_nonzero(y)
np.isnan(y)
np.any(x>0)
np.any(x>0, axis = 0)
```

## Manipuler un array

Dans cette section, on utilisera un array multidimensionnel:

```{python}
x = np.random.normal(0, size=(3, 4))
```

### Statistiques sur un array

Pour les statistiques descriptives classiques, `numpy` propose un certain nombre de fonctions déjà implémentées,
qui peuvent être combinées avec l'argument `axis`

**Exercice**

1. Faire la somme de tous les éléments d'un `array`, des éléments en ligne et des éléments en colonne. Vérifier
la cohérence
2. Ecrire une fonction `statdesc` pour renvoyer les valeurs suivantes : moyenne, médiane, écart-type, minimum et maximum.
L'appliquer sur `x` en jouant avec l'argument axis

```{python, include = FALSE, eval = FALSE}
x.sum()
x.sum(axis = 0)
x.sum(axis = 1)
# check coherence
x.sum(axis = 0).sum()
x.sum(axis = 1).sum()
```

```{python, include = FALSE, eval = FALSE}
def statdesc(x, axis = None):
    """
    Statistiques agrégées sur un array numpy

    :param x: Numpy array
    :param axis: Numpy dimension that should be used
    :return: A numpy array with mean, median, sd, min and max
    """

    return np.array([
        np.mean(x, axis = axis),
        np.median(x, axis = axis),
        np.std(x, axis = axis),
        np.min(x, axis = axis),
        np.max(x, axis = axis)
        ])

statdesc(x)
statdesc(x, axis = 0)
statdesc(x, axis = 1)
```


### Fonctions de manipulation

Voici quelques fonctions pour modifier un array, 

| Opération | Implémentation |
|-----------|----------------|
| Applatir un array | `x.flatten()` (méthode) |
| Transposer un array | `x.T` (méthode) ou `np.transpose(x)` (fonction) |
| Ajouter des éléments à la fin | `np.append(x, [1,2])` |
| Ajouter des éléments à un endroit donné (aux positions 1 et 2) | `np.insert(x, [1,2], 3)` |
| Supprimer des éléments (aux positions 0 et 3) | `np.delete(x, [0,3])` |

Pour combiner des array, on peut utiliser, selon les cas, 
les fonctions `np.concatenate`, `np.vstack` ou la méthode `.r_` (concaténation *rowwise*). 
`np.hstack` ou la méthode `.column_stack` ou `.c_` (concaténation *column-wise*)

```{python}
x = np.random.normal(size = 10)
```

A l'inverse, 

Pour ordonner un array, on utilise `np.sort`

```{python}
x = np.array([7, 2, 3, 1, 6, 5, 4])

np.sort(x)
```

Si on désire faire un ré-ordonnement partiel pour trouver les _k_ valeurs les plus petites d'un `array` sans les ordonner, on utilise `partition`:

```{python}
np.partition(x, 3)
```



## Broadcasting

Le broadcasting désigne un ensemble de règles pour appliquer une opération qui normalement
ne s'applique que sur une seule valeur à l'ensemble des membres d'un tableau Numpy. 

Le broadcasting nous permet d'appliquer ces opérations sur des tableaux de dimensions différentes.

```{python}
a = np.array([0, 1, 2])

b = np.array([5, 5, 5])

a + b
a + 5
```

Le *broadcasting* peut être très pratique pour effectuer de manière efficace des opérations sur des données à
la structure complexe. Pour plus de détails, se rendre
[ici](https://jakevdp.github.io/PythonDataScienceHandbook/02.05-computation-on-arrays-broadcasting.html).

## Application: k-nearest neighbor fait-main

<!----
L'idée de cet exercice vient de
[là](https://jakevdp.github.io/PythonDataScienceHandbook/02.08-sorting.html#Example:-k-Nearest-Neighbors). 
------>

1. Créer `X` un tableau à deux dimensions (i.e. une matrice) comportant 10 lignes
et 2 colonnes. Les nombres dans le tableau sont aléatoires.
2. Importer le module `matplotlib.pyplot` sous le nom `plt`. Utiliser
`plt.scatter` pour représenter les données sous forme de nuage de points. 
3. Constuire une matrice 10x10 stockant, à l'élément $(i,j)$, la distance euclidienne entre les points $X[i,]$ et $X[j,]$. Pour cela, il va falloir jouer avec les dimensions en créant des tableaux emboîtés à partir par des appels à `np.newaxis` :
  + En premier lieu, utiliser `X1 = X[:, np.newaxis, :]` pour transformer la matrice en tableau emboîté. Vérifier les dimensions
  + Créer `X2` de dimension `(1, 10, 2)` à partir de la même logique
  + En déduire, pour chaque point, la distance avec les autres points pour chaque coordonnées. Elever celle-ci au carré
  + A ce stade, vous devriez avoir un tableau de dimension `(10, 10, 2)`. La réduction à une matrice s'obtient en sommant sur le dernier axe. Regarder dans l'aide de `np.sum` comme effectuer une somme sur le dernier axe. 
  + Enfin, appliquer la racine carrée pour obtenir une distance euclidienne en bonne et due forme. 
4. Vérifier que les termes diagonaux sont bien nuls (distance d'un point à lui-même...)
5. Il s'agit maintenant de classer, pour chaque point, les points dont les valeurs sont les plus similaires. Utiliser `np.argsort` pour obtenir, pour chaque ligne, le classement des points les plus proches
6. On va s'intéresser aux k-plus proches voisins. Pour le moment, fixons k=2. Utiliser `argpartition` pour réordonner chaque ligne de manière à avoir les 2 plus proches voisins de chaque point d'abord et le reste de la ligne ensuite
7. Utiliser le morceau de code ci-dessous

~~~python
plt.scatter(X[:, 0], X[:, 1], s=100)

# draw lines from each point to its two nearest neighbors
K = 2

for i in range(X.shape[0]):
    for j in nearest_partition[i, :K+1]:
        # plot a line from X[i] to X[j]
        # use some zip magic to make it happen:
        plt.plot(*zip(X[j], X[i]), color='black')
~~~

pour représenter graphiquement le réseau de plus proches voisins

```{python, include = FALSE}
X = np.random.random((10, 2))
X
```

Pour la question 2, Vous devriez obtenir un graphique ayant cet aspect :

```{python, echo = FALSE}
import matplotlib.pyplot as plt
plt.scatter(X[:, 0], X[:, 1], s=100)
```

```{python, include = FALSE}
dist = np.sqrt(
np.sum((X[:, np.newaxis, :] - X[np.newaxis, :, :]) ** 2, axis=-1))
dist
```


```{python, include = FALSE}
dist.diagonal()
```

```{python, include = FALSE}
np.argsort(dist)
```

```{python, include = FALSE}
K = 2
# Ne pas oublier que le plus proche voisin d'un point est lui-même !
nearest_partition = np.argpartition(dist, K + 1, axis=1)
nearest_partition
```

Finalement, vous devriez obtenir un graphique ayant cet aspect :

```{python, echo = FALSE}
plt.scatter(X[:, 0], X[:, 1], s=100)

# draw lines from each point to its two nearest neighbors
K = 2

for i in range(X.shape[0]):
    for j in nearest_partition[i, :K+1]:
        # plot a line from X[i] to X[j]
        # use some zip magic to make it happen:
        plt.plot(*zip(X[j], X[i]), color='black')
```

Ai-je inventé cet exercice corsé ? Pas du toût, il [vient de là](https://jakevdp.github.io/PythonDataScienceHandbook/02.08-sorting.html#Example:-k-Nearest-Neighbors). Mais, si je vous l'avez indiqué immédiatement, auriez-vous cherché à répondre aux questions

Par ailleurs, il ne serait pas une bonne idée de généraliser cet algorithme à de grosses données. La complexité de notre approche est $O(N^2)$. L'algorithme implémenté par Scikit-learn est
en $O[NlogN]$

<!-----
## Restructuration, concaténation et division

* Pour restructurer un `array`, c'est-à-dire changer ses dimensions, le plus simple est d'utiliser la méthode `reshape`. Par exemple, pour 

np.reshape
np.concatenate
np.split, np.hsplit, and np.vsplit
----->
