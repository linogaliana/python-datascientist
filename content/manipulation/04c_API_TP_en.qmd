
```{python}
#| echo: true
import requests
import pandas as pd

req = requests.get(url_api)
wb = req.json()
```

Let's take, for example, the first 1000 characters of the result to get an idea of the output and confirm that our filter at the communal level has been correctly applied:

```{python}
#| echo: true
#| output: asis
print(req.content[:1000])
```

Here, it is not even necessary at first to use the `json` package since the information is already tabulated in the echoed output (we have the same information for all countries):
So we can simply use `Pandas` to transform our data into a `DataFrame` and `Geopandas` to convert it into geographical data:

{{< include "04_api/_example_dpe.qmd" >}}


## An incomplete catalog of existing APIs

More and more websites are providing APIs for developers and curious individuals alike.

To name a few well-known ones:

- `Twitter` <i class="fab fa-twitter"></i>: <https://dev.twitter.com/rest/public>
- `Facebook` <i class="fab fa-facebook"></i>: <https://developers.facebook.com/>
- `Instagram` <i class="fab fa-instagram"></i>: <https://www.instagram.com/developer/>
- `Spotify` <i class="fab fa-spotify"></i>: <https://developer.spotify.com/web-api/>

However, it is worth not limiting ourselves to these, whose data is not always the most interesting. Many data producers, both private and public, make their data available through APIs.

- [API gouv](https://api.gouv.fr/): many official APIs from the French government and access to documentation
- Insee: https://api.insee.fr/catalogue/ and [`pynsee`](https://github.com/InseeFrLab/Py-Insee-Data/tree/main/pynsee)
- Pôle Emploi: https://www.emploi-store-dev.fr/portail-developpeur-cms/home.html
- SNCF: https://data.sncf.com/api
- World Bank: https://datahelpdesk.worldbank.org/knowledgebase/topics/125589

# The DVF API: accessing real estate transaction data easily

:::: {.important}
This section needs updating to prioritize the Cerema DVF API
::::


The `DVF` (demand for property values) website allows users to view all data related to transactions (sales of houses, apartments, garages, etc.) conducted over the past five years.

A visualization site is available at <https://app.dvf.etalab.gouv.fr/>.

This site is very comprehensive when it comes to knowing the average price per square meter of a neighborhood or comparing regions. The DVF API allows you to go further by retrieving results in a data processing software. It was created by [Christian Quest](https://github.com/cquest) and the source code is available on Github <a href="https://github.com/cquest/dvf_as_api" class="github"><i class="fab fa-github"></i></a>.

The search criteria are as follows:

- `code_commune` = INSEE code of the municipality (e.g., 94068)
- `section` = cadastral section (e.g., 94068000CQ)
- `numero_plan` = plot identifier (e.g., 94068000CQ0110)
- `lat` + `lon` + `dist` (optional): for a geographical search, `dist` is by default a 500m radius
- `code_postal`

Additional selection filters:
- `nature_mutation` (Sale, etc.)
- `type_local` (House, Apartment, Local, Dependency)

Requests are of the form: `http://api.cquest.org/dvf?code_commune=29168`.

{{< include "04_api/_exo1_en.qmd" >}}
{{< include "04_api/_exo1_solution.qmd" >}}


Let's create a map of the sales, displaying the purchase price.
The interactive map will be presented in the chapters on data visualization.

Assuming the sales DataFrame is called `ventes`, we first need to convert it into a `geopandas` object.

```{python}
#| eval: false

ventes = ventes.dropna(subset = ['lat','lon'])
ventes = gpd.GeoDataFrame(ventes, geometry=gpd.points_from_xy(ventes.lon, ventes.lat))
ventes
```

Before making a map, we will convert the boundaries of the Plogoff municipality to GeoJSON for easier representation with `folium` ([see the `geopandas` documentation](https://geopandas.readthedocs.io/en/latest/gallery/polygon_plotting_with_folium.html#Add-polygons-to-map)):

```{python}
#| eval: false
geo_j = plgf.to_json()
```

To graphically represent this, you can use the following code (try to understand it, not just execute it).

```{python}
#| output: hide
#| eval: false
import folium
import numpy as np

ventes['map_color'] = pd.qcut(ventes['valeur_fonciere'], [0,0.8,1], labels = ['lightblue','red'])
ventes['icon'] = np.where(ventes['type_local']== 'Maison', "home", "")
ventes['num_voie_clean'] = np.where(ventes['numero_voie'].isnull(), "", ventes['numero_voie'])
ventes['text'] = ventes.apply(lambda s: "Adresse: {num} {voie} <br>Vente en {annee} <br>Prix {prix:.0f} €".format(
                        num = s['num_voie_clean'],
                        voie = s["voie"],
                        annee = s['date_mutation'].split("-")[0],
                        prix = s["valeur_fonciere"]),
             axis=1)
             
center = ventes[['lat', 'lon']].mean().values.tolist()
sw = ventes[['lat', 'lon']].min().values.tolist()
ne = ventes[['lat', 'lon']].max().values.tolist()

m = folium.Map(location = center, tiles='OpenStreetMap')

# I can add marker one by one on the map
for i in range(0,len(ventes)):
    folium.Marker([ventes.iloc[i]['lat'], ventes.iloc[i]['lon']],
                  popup=ventes.iloc[i]['text'],
                  icon=folium.Icon(color=ventes.iloc[i]['map_color'], icon=ventes.iloc[i]['icon'])).add_to(m)

m.fit_bounds([sw, ne])
```


```{python}
#| echo : true
#| eval: false
# Afficher la carte
m
```


# Geocode data using official APIs

To be able to do this exercise

```{python}
#| output: false
#| echo: true
!pip install xlrd
```

Up until now, we have worked on data where the geographical dimension was already present or relatively easy to integrate.

This ideal case is not necessarily encountered in practice. Sometimes we have more or less precise and more or less well-formatted locations to determine the location of certain places.

For a few years now, an official geocoding service has been set up. This service is free and allows us to efficiently code addresses using an API. This API, known as the __Base d'Adresses Nationale (BAN)__, has benefited from the pooling of data from several actors (local authorities, Post Office) and the skills of actors such as Etalab. The documentation for this API is available at the address <https://api.gouv.fr/les-api/base-adresse-nationale>.

To illustrate how to geocode data with `Python`, we will start with the database of [driving school results for the driving test in 2018](https://www.data.gouv.fr/fr/datasets/taux-de-reussite-auto-ecole-par-auto-ecole-en-2018/).

This data requires a bit of work to be suitable for statistical analysis. After renaming the columns, we will only keep the information related to the B license (standard car license) and driving schools that have presented at least 20 people to the exam.


{{< include "04_api/_exo2_preliminary1.qmd" >}}


Our geographical information takes the following form:

```{python}
#| echo: true
df.loc[:,['Adresse','CP','Ville']].head(5)
```

In other words, we have an address, a zip code, and a city name. This information can be used to search for the location of a driving school and possibly restrict it to a subsample.

## Using the BAN API

The [official API documentation](https://adresse.data.gouv.fr/api-doc/adresse) provides several examples of how to geolocate data. In our situation, two entry points seem interesting:

* __The `/search/` API__ which represents an entry point with URLs of the form `https://api-adresse.data.gouv.fr/search/?q=\<address\>&postcode=\<zipcode\>&limit=1`
* __The `/search/csv` API__ which takes a CSV as input and returns the same CSV with the geocoded observations. The request takes the following form, which seems less simple to implement: `curl -X POST -F data=@search.csv -F columns=address -F columns=zipcode https://api-adresse.data.gouv.fr/search/csv/`

The temptation would be strong to use the first method with a loop over the rows of our `DataFrame` to geocode our entire dataset. However, this would be a bad idea because the communications between our `Python` session and the API servers would be too numerous to offer satisfactory performance.

To convince yourself, you can run the following code on a small sample of data (for example, 100 as here) and notice that the execution time is quite significant.

{{< include "04_api/_exo2_preliminary2.qmd" >}}


As indicated in the documentation, if we want to industrialize our geocoding process, we will prefer the CSV API.

To obtain a `CURL` request consistent with the format desired by the API, we will again use `Requests` but this time with additional parameters:

* `data` will allow us to pass parameters to `CURL` (equivalent to the `-F` of the `CURL` request):
    + `columns`: The columns used to locate data. In this case, we use the address and the city (since zip codes are not unique, the same street name can be found in several cities sharing the same zip code);
    + `postcode`: The zip code of the city. Ideally, we would have used the INSEE code, but we do not have it in our data;
    + `result_columns`: we restrict the data exchanged with the API to the columns that interest us. This allows us to speed up the processes (we exchange less data) and reduce the carbon footprint of our activity (less data transfer = less energy spent). In this case, we only return the geolocated data and a confidence score for the geolocation;
* `files`: allows sending a file via `CURL`.

The data is retrieved with `request.post`. Since it is a string, we can directly read it with `Pandas` using `io.StringIO` to avoid writing intermediate data.

The number of echoes seeming to be limited, it is proposed to proceed in chunks (here, the dataset is divided into 5 chunks).

{{< include "04_api/_exo2_preliminary3.qmd" >}}



You can go further with the following exercise.

{{< include "04_api/_exo2_en.qmd" >}}
{{< include "04_api/_exo2_solution.qmd" >}}



# Additional exercises

## Discover the `OpenFoodFacts` API

To help you, you can look at an example of the JSON structure here: <https://world.openfoodfacts.org/api/v0/product/3274080005003.json>, particularly the `nutriments` category.

{{< include "04_api/_exo3_en.qmd" >}}
{{< include "04_api/_exo3_solution.qmd" >}}

