---
title: "Approfondissement ElasticSearch pour des recherches de proximité géographique"
date: 2020-09-03T13:00:00Z
draft: false
weight: 20
tags:
  - elastic
  - levenshtein
  - sirene
categories:
  - Tutoriel
slug: elastic-geo
type: book
summary: |
  TO BE COMPLETED 
---


Pour essayer les exemples présents dans ce tutoriel : 

```{python}
#| echo: false
#| output: 'asis'
#| include: true
#| eval: true

import sys
sys.path.insert(1, '../../../../') #insert the utils module
from utils import print_badges

#print_badges(__file__)
print_badges("content/course/modern-ds/elastic_approfondissement.qmd")
```

Ce chapitre est issu du travail produit
dans le cadre d'un hackathon de l'Insee avec
[Raphaële Adjerad](https://github.com/raphaeleadjerad) 
et présente quelques éléments qui peuvent être utiles
pour l'enrichissement de données d'entreprises
à partir d'un répertoire officiel. 

:warning: Il nécessite une version particulière du package `elasticsearch` pour tenir compte de l'héritage de la version 7 du moteur Elastic. Pour cela, faire

~~~python
pip install elasticsearch==8.2.0
~~~

# Introduction

## Objectif

Ce chapitre vise à approfondir les éléments présentés sur Elastic précédemment. L'idée
est de se placer dans un contexte opérationnel où on reçoit des informations
sur des entreprises telles que l'adresse et la localisation et qu'on 
désire associer à des données administratives considérées plus fliables. 


## Réplication de ce chapitre

Comme le précédent, ce chapitre est plus exigeant en termes d'infrastructures que les précédents.
Il nécessite un serveur Elastic. Les utilisateurs du
[SSP Cloud](datalab.sspcloud.fr/) pourront répliquer les exemples de ce cours
car cette technologie est disponible (que ce soit pour indexer une base ou
pour requêter une base existante).

La première partie de ce tutoriel, qui consiste à créer une base Sirene géolocalisée
à partir des données _open-data_ ne nécessite pas d'architecture particulière et
peut ainsi être exécutée en utilisant les packages suivants: 

```{python}
import time
import numpy as np
import pandas as pd
```


## Sources

Ce chapitre va utiliser plusieurs sources de diffusion de
l'Insee:

- Le stock des établissements présents dans les [données de diffusion Sirene](https://www.insee.fr/fr/information/3591226) ;
- Les [données Sirene géolocalisées](https://www.data.gouv.fr/fr/datasets/geolocalisation-des-etablissements-du-repertoire-sirene-pour-les-etudes-statistiques/)


# Constitution du référentiel administratif géolocalisé

Dans un premier temps, on va combiner ensemble les différentes sources
_open-data_ pour créer un référentiel fiable d'entreprises
géolocalisées.

La base d'entrée à utiliser est disponible sur
[data.gouv](https://www.data.gouv.fr/fr/datasets/base-sirene-des-entreprises-et-de-leurs-etablissements-siren-siret/)

```{python}
import requests
import zipfile

url_download = "https://www.data.gouv.fr/fr/datasets/r/0651fb76-bcf3-4f6a-a38d-bc04fa708576"
req = requests.get(url_download)

with open("sirene.zip",'wb') as f:
  f.write(req.content)

with zipfile.ZipFile("sirene.zip", 'r') as zip_ref:
  zip_ref.extractall("sirene")
```

On va importer seulement les colonnes utiles et simplifier la structure
pour être en mesure de ne garder que les informations qui nous
intéressent (nom de l'entreprise, adresse, commune, code postal...)

```{python}
import pandas as pd
import numpy as np

list_cols = [
  'siren', 'siret',
  'activitePrincipaleRegistreMetiersEtablissement',
  'complementAdresseEtablissement',
  'numeroVoieEtablissement',
  'typeVoieEtablissement',
  'libelleVoieEtablissement',
  'codePostalEtablissement',
  'libelleCommuneEtablissement',
  'codeCommuneEtablissement',
  'etatAdministratifEtablissement',
  'denominationUsuelleEtablissement',
  'activitePrincipaleEtablissement'
]

df = pd.read_csv(
  "sirene/StockEtablissement_utf8.csv",
  usecols = list_cols)

df['numero'] = df['numeroVoieEtablissement']\
  .replace('-', np.NaN).str.split().str[0]\
  .str.extract('(\d+)', expand=False)\
  .fillna("0").astype(int)

df['numero'] = df['numero'].astype(str).replace("0","")

df['adresse'] = df['numero'] + " " + \
  df['typeVoieEtablissement'] + " " + \
  df['libelleVoieEtablissement']

df['adresse'] = df['adresse'].replace(np.nan, "")

df = df.loc[df['etatAdministratifEtablissement'] == "A"]

df.rename(
  {"denominationUsuelleEtablissement": "denom",
  "libelleCommuneEtablissement": "commune",
  "codeCommuneEtablissement" : "code_commune",
  "codePostalEtablissement": "code_postal"},
  axis = "columns", inplace = True)

df['ape'] = df['activitePrincipaleEtablissement'].str.replace("\.", "", regex = True)
df['denom'] = df["denom"].replace(np.nan, "")

df_siret = df.loc[:, ['siren', 'siret','adresse', 'ape', 'denom', 'commune', 'code_commune','code_postal']]
df_siret['code_postal'] = df_siret['code_postal'].replace(np.nan, "0").astype(int).astype(str).replace("0","")
```

On importe ensuite les données géolocalisées

```{python}
import zipfile
import shutil
import os

os.remove("siret.zip")
shutil.rmtree('siret/')

url_geoloc = "https://files.data.gouv.fr/insee-sirene-geo/GeolocalisationEtablissement_Sirene_pour_etudes_statistiques_utf8.zip"
r = requests.get(url_geoloc)  

with open('geoloc.zip', 'wb') as f:
    f.write(r.content)

df_geoloc = pd.read_csv(
  "geoloc/GeolocalisationEtablissement_Sirene_pour_etudes_statistiques_utf8.csv",
  usecols = ["siret", "epsg", "x_longitude", "y_latitude"] , sep = ";")

df_geolocalized = df_siret.merge(df_geoloc, on = "siret") 
```