---
title: "Webscraping avec python"
date: 2020-09-08T13:00:00Z
draft: false
weight: 60
slug: webscraping
tags:
  - Deep Learning
  - DallE
  - Tutoriel
  - Image
  - Thèmes avancés
categories:
  - Tutoriel
  - Avancé
type: book
summary: |
  La _hype_ autour du
  modèle de génération d'image `Dall-E` a amené 
  une grande attention sur les modèles
  autogénératifs de contenu. `Dall-E` est, à l'heure
  actuelle, le modèle le plus célèbre de génération
  d'image à partir de texte. Il est maintenant
  possible de créer, depuis `Python` grâce à 
  l'implémentation de [`StableDiffusion`](https://huggingface.co/CompVis/stable-diffusion-v1-4),
  soit-même
  ses propres images rigolotes.
---

Pour tester les exemples présentés dans ce chapitre:

::: {.cell .markdown}
```{python}
#| echo: false
#| output: 'asis'
#| include: true
#| eval: true

import sys
sys.path.insert(1, '../../../../') #insert the utils module
from utils import print_badges

#print_badges(__file__)
print_badges("content/course/modern-ds/dallE.qmd")
```
:::

{{% box status="note" title="Remarque" icon="fa fa-lightbulb" %}}
L'utilisation de ce tutoriel est assez exigeante en termes d'infrastructure
car il est nécessaire de disposer de GPU.

Bien qu'il en existe sur
le _cloud_ du SSPCloud, je n'ai pas encore eu le temps de creuser la configuration
à mettre en oeuvre pour répliquer ce chapitre.

Pour le moment, il faudra
se contenter de `Google Colab` pour tester ces exemples. La configuration
à mettre en oeuvre pour tester ces exemples est présentée dans une autre
boîte. 
{{% /box %}}

{{% box status="note" title="Utiliser des GPU sur `Colab`" icon="fa fa-lightbulb" %}}
Par défaut, Colab n'utilise pas de GPU mais de la CPU. Il est donc nécessaire
d'éditer les paramètres d'exécution du Notebook
- Dans le menu `Exécution`, cliquer sur `Modifier le type d'exécution`
- Sélectionner `GPU` sous `Accélérateur matériel`
{{% /box %}}

# Contexte

La publication par l'organisation [Open AI](https://openai.com/) de
son modèle de génération de contenu créatif [Dall-E-2](https://openai.com/dall-e-2/)
(un jeu de mot mélangeant Dali et Wall-E) a créé un bruit inédit dans
le monde de la _data-science_.
Un compte twitter ([@Weird Dall-E Mini Generations](https://twitter.com/weirddalle))
propose de nombreuses générations de contenu drôles ou incongrues. 
Le bloggeur tech Casey Newton a pu parler d'une 
[révolution créative dans le monde de l'IA](https://www.platformer.news/p/how-dall-e-could-power-a-creative).

![](https://upload.wikimedia.org/wikipedia/commons/2/2b/A_Shiba_Inu_dog_wearing_a_beret_and_black_turtleneck_DALLE2.jpg)

Dall-E-2 s'appuie sur des réseaux de neurone à différents niveaux :

- le contenu de la phrase est analysé par un réseau de neurone similaire (mais bien sûr plus évolué) que 
ceux que nous avons présenté dans la partie [NLP](#nlp)
- les éléments importants de la phrase (recontextualisés) sont ensuite transformés en image à partir de
modèles entraînés à reconnaître des images

Jusqu'à présent, l'inconvénient principal de `Dall-E`
pour générer facilement du contenu
était que le nombre de contenu pouvant être payé
avec un accès gratuit était limité (50 crédits gratuits par mois).
Depuis le 22 août 2022, un générateur similaire est disponible gratuitement,
avec une licence permissive[^1]. Celui-ci, développé
par une équipe de chercheurs [@Rombach_2022_CVPR], 
s'appelle `Stable Diffusion` ([dépôt `Github` pour le code source](https://github.com/CompVis/stable-diffusion) et
[dépôt `HuggingFace` pour le modèle mis à disposition](https://huggingface.co/CompVis/stable-diffusion-v1-4)).
Un [excellent article de blog](https://huggingface.co/blog/stable_diffusion) décrit la démarche de `Stable Diffusion`

[^1]: Il est notamment possible de réutiliser l'image générée à des fins commerciales. En revanche, il est interdit de chercher à nuire à une personne. Pour cette raison, il est fréquent que les visages de personnes célèbres soient floutés pour éviter la création de contenu nuisant à leur réputation.

