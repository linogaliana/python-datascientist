---
title: "Comment aborder un jeu de données"
date: 2020-07-22T12:00:00Z
draft: false
weight: 35
slug: datanalysis
type: book
summary: |
  La démarche à adopter face à un jeu de données
---

# Démarche à adopter face à un jeu de données

Pour bien débuter des travaux sur une base de données,
il est nécessaire de se poser quelques questions de bon sens
et de suivre une démarche assez simple.

## Une démarche scientifique

Dans un projet sur des jeux de données, on peut schématiquement
séparer les étapes en quatre grandes parties :

* la récupération et structuration des données;
* leur analyse (notamment descriptive);
* la modélisation ;
* la valorisation finale des étapes précédentes.


## Lors de la récupération des données

### Réflexions à mener en amont

La phase de constitution de son jeu de données sous-tend tout le projet qui suit.

La première question à se poser est
_"de quelles données ai-je besoin pour répondre à ma problématique ?"_.
Cette problématique pourra éventuellement 
être affinée en fonction des besoins mais les travaux sont généralement
de meilleure qualité lorsque la problématique amène à la réflexion sur les données
disponibles plutôt que l'inverse. 

Ensuite, _"qui produit et met à disposition ces données" ?_
_Les sources disponibles sur internet sont-elles fiables ?_
Par exemple, les sites d'_open data_ gouvernementaux sont par exemple assez fiables mais autorisent parfois l'archivage de données restructurées par des tiers et non des producteurs officiels. A l'inverse, sur `Kaggle` ou sur `Github` la source de certains jeux de données n'est pas tracée ce qui rend compliquée la confiance sur la qualité de la donnée

Une fois identifié une ou plusieurs sources de données,
_est-ce que je peux les compléter avec d'autres données ?_
(dans ce cas, faire attention à avoir des niveaux de granularité adéquats)

### Structuration des données

Vient ensuite la phase de mise en forme et nettoyage des jeux de données récupérés.
Cette étape est primordiale et est généralement celle qui mobilise le plus
de temps. Pendant quelques années, on parlait de _data-cleaning_. Cependant,
cela a pu, implicitement, laisser penser qu'il s'agissait d'une tâche 
subalterne. On commence à lui préférer le concept de _feature engineering_ 
qui souligne bien qu'il s'agit d'une compétence qui nécessite beaucoup 
de compétences.

Un jeu de données propre est un jeu de données dont la structure est 
adéquate et n'entraînera pas d'erreur, visible ou non,
lors de la phase d'analyse. Voici quelques éléments structurants
d'un jeu de données propre: 

- les __informations manquantes__ sont bien comprises et traitées. `numpy` et
`pandas` proposent un certain formalisme sur le sujet qu'il est utile 
d'adopter en remplaçant par `NaN` les observations manquantes[^3]. Cela
implique de faire attention à la manière dont certains producteurs
codent les valeurs manquantes: certains ont la facheuse tendance à 
être imaginatifs sur les codes pour valeurs manquantes: _"-999"_, _"XXX"_, _"NA"_ 
- les __variables servant d'identifiants__ sont bien les mêmes d'une table à l'autre (notamment dans le cas de jointure) : même format, même modalités
- pour des __variables textuelles__, qui peuvent etre mal saisies, avoir corrigé les éventuelles fautes (ex "Rolland Garros" > "Roland Garros")
- créer des variables qui synthétisent l'information dont vous avez besoin
- supprimer les éléments inutiles (colonne ou ligne vide)
- renommer les colonnes avec des noms compréhensibles

[^3]: TO DO Une note sur `Stata` et le problème des valeurs manquantes recodées en 0

## Lors de l'analyse descriptive

Une fois les jeux de données nettoyés, vous pouvez plus sereinement
étudier l'information présente dans les données.
Cette phase et celle du nettoyage ne sont pas séquentielles,
en réalité vous devrez régulièrement passer de votre nettoyage à quelques statistiques descriptives qui vous montreront un problème, retourner au nettoyage etc.

Les questions à se poser pour _"challenger"_ le jeu de données :

- est-ce que mon échantillon est bien __représentatif__ de ce qui m'intéresse ? N'avoir que 2000 communes sur les 35000 n'est pas nécessairement un problème mais il est bon de s'être posé la question.
- est-ce que les __ordres de grandeur__ sont bons ? pour cela, confronter vos premieres stats desc à vos recherches internet. Par exemple trouver que les maisons vendues en France en 2020 font en moyenne 400 m² n'est pas un ordre de grandeur réaliste.
- est-ce que je __comprends toutes les variables__ de mon jeu de données ? est-ce qu'elles se "comportent" de la bonne façon ? à ce stade, il est parfois utile de se faire un dictionnaire de variable (qui explique comment elles sont construites ou calculées). On peut également mener des études de __corrélation__ entre nos variables.
- est-ce que j'ai des __outliers__, i.e. des valeurs aberrantes pour certains individus ? Dans ce cas, il faut décider quel traitement on leur apporte (les supprimer, appliquer une transformation logarithmique, les laisser tel quel) et surtout bien le justifier.
- est-ce que j'ai des __premiers grands messages__ sortis de mon jeu de données ? est-ce que j'ai des résultats surprenants ? Si oui, les ai-je creusé suffisamment pour voir si les résultats tiennent toujours ou si c'est à cause d'un souci dans la construction du jeu de données (mal nettoyées, mauvaise variable...)

## Lors de la modélisation

A cette étape, l'analyse descriptive doit voir avoir donné quelques premières pistes pour savoir dans quelle direction vous voulez mener votre modèle.
Une erreur de débutant est de se lancer directement dans la modélisation parce
qu'il s'agirait d'une compétence plus poussée. Cela amène généralement 
à des analyses de pauvre qualité: la modélisation tend généralement à confirmer
les intuitions issues de l'analyse descriptive. Sans cette dernière,
l'interprétation des résultats d'un modèle peu s'avérer inutilement complexe. 

Vous devrez plonger dans vos autres cours (Econométrie 1, Series Temporelles, Sondages, Analyse des données etc.) pour trouver le modèle le plus adapté à votre question.

La méthode sera guidée par l'objectif. 

- Est-ce que vous voulez expliquer ou prédire ? https://hal-cnam.archives-ouvertes.fr/hal-02507348/document
- Est-ce que vous voulez classer un élément dans une catégorie (classification ou clustering) ou prédire une valeur numérique (régression) ?

En fonction des modèles que vous aurez déjà vu en cours et des questions que vous souhaiterez résoudre sur votre jeu de données, le choix du modèle sera souvent assez direct.


Vous pouvez également vous référez à la démarche proposée par Xavier Dupré
http://www.xavierdupre.fr/app/ensae_teaching_cs/helpsphinx3/debutermlprojet.html#l-debutermlprojet

Pour aller plus loin (mais de manière simplifiée) sur les algorithmes de Machine Learning :  
https://datakeen.co/8-machine-learning-algorithms-explained-in-human-language/


### Valorisation des travaux

La mise à disposition de code sur `Github` ou `Gitlab` est une incitation
très forte pour produire du code de qualité. Il est ainsi recommandé de
systématiquement utiliser ces plateformes pour la mise à disposition de
code. Cependant, il ne s'agit que d'une petite partie des gains à
l'utiliser.
Le cours que je donne avec Romain Avouac en troisième année d'ENSAE
(ensae-reproductibilite.netlify.app/) évoque
l'un des principaux gains à utiliser ces plateformes, à savoir
la possibilité de mettre à disposition automatiquement différents livrables
pour valoriser son travail auprès de différents publics.

Selon le public visé, la communication ne sera pas identique. Le code peut
intéresser les personnes désirant avoir des détails sur la méthodologie mise
en oeuvre en pratique mais il peut s'agir d'un format rebutant pour d'autres
publics. Une visualisation de données dynamiques parlera à des publics
moins experts de la donnée mais est plus dure à mettre en oeuvre
qu'un graphique standard. 

{{% box status="hint" title="Conseil" icon="fa fa-lightbulb" %}}

Les Notebooks `Jupyter` ont eu beaucoup de succès dans le monde de 
la _data-science_ pour valoriser des travaux. Pourtant il ne s'agit
pas forcément toujours du meilleur format. En effet, beaucoup
de _notebooks_ tentent à empiler des pavés de code et du texte, ce
qui les rend difficilement lisibles. 

Sur un projet conséquent, il vaut mieux reporter le plus de code 
possible dans des scripts bien structurés et avoir un notebook
qui appelle ces scripts pour produire des outputs. Ou alors ne
pas utiliser un notebook et privilégier un autre format (un 
tableau de bord, un site web, une appli réactive...)
{{% /box %}}



# Ethique et responsabilité du data-scientist

Les données sont une représentation synthétique de la vie des gens et les
conclusions de certaines analyses peuvent avoir un vrai impact sur 
leur vie. Les chiffres erronés de 
Reinhart et Rogoff ont ainsi pu servir de justification théorique à des
politiques d'austérité qui ont pu avoir des conséquences violentes
pour certains citoyens de
pays en crise[^4]. En Grande-Bretagne [cas excel covid]
Un exemple sur le credit scoring ? 

[^4]: Krugman a parlé à propos de ce scandale scientifique
de _"reproducibility crisis"_. 

La transparence sur les intérêts et limites d'une méthode mise en oeuvre
est importante. Cette exigence de la recherche mérite également d'être appliquée
en entreprise ou administration. 
Même sans intention manifeste de la part de la personne qui analyse des données,
une mauvaise interprétation est toujours possible. Tout en valorisant un
résultat, il est possible d'alerter sur certaines limites. 

Parler biais cognitifs  (comme biais confirmation)

Certaines représentations de données sont à exclure car des biais cognitifs
peuvent amener à des interprétations erronées[^5]. Dans le domaine de la 
visualisation de données, les camemberts (_pie chart_) ou les diagrammes
araignées (vrai nom ?) sont par exemple 
à exclure car l'oeil humain perçoit mal ces formes circulaires. Pour une raison
similaire, les cartes avec aplat de couleur (cartes
chrolophetes) sont trompeuses. 

[Remettre carte land does not vote ?]

[^5]: On suppose ici que le message erroné est transmis sans volonté de 
manipulation. La manipulation manifeste est un problème encore plus grave. 

