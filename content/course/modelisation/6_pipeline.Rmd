---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.6.0
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
title: "Premier pas vers l'industrialisation avec les pipelines scikit"
date: 2020-10-20T13:00:00Z
draft: false
weight: 60
slug: pipeline-scikit
type: book
tags:
  - scikit
  - machine learning
  - pipeline
categories:
  - Tutorial
summary: |
  Les pipelines scikit permettent d'intégrer de manière très flexible
  un ensemble d'opérations de pre-processing et d'entraînement de modèles
  dans une chaîne d'opérations. Il s'agit d'une approche particulièrement
  appropriée pour réduire la difficulté à changer d'algorithme ou pour
  faciliter la ré-application d'un code à de nouvelles données
---


```{r setup, include=FALSE}
dir_path <- gsub(here::here(), "..", here::here("course","modelisation"))
knitr::knit_hooks$set(
  plot = function(x, options) modif_plot(x, options, dir_path = dir_path)
)
```

```{r, echo = FALSE, results = 'asis', include = TRUE, eval = TRUE}
print_badges()
```

# Pourquoi les pipelines ?

Les chapitres précédents ont permis de montrer des bouts de code 
épars pour entraîner des modèles ou faire du _preprocessing_.
Cette démarche est intéressante pour tâtonner mais risque d'être coûteuse
ultérieurement s'il est nécessaire d'ajouter une étape de preprocessing 
ou de changer d'algorithme.

Heureusement, `scikit` propose un excellent outil pour proposer un cadre
général pour créer une chaîne de production *machine learning*. Il
s'agit des
[_pipelines_](https://scikit-learn.org/stable/modules/compose.html). 
Ils présentent de nombreux intérêts, parmi lesquels:

* Ils sont très __pratiques__ et __lisibles__. On rentre des données en entrée, on n'appelle qu'une seule fois les méthodes `fit` et `predict` ce qui permet de s'assurer une gestion cohérente des transformations de variables, par exemple après l'appel d'un `StandardScaler`
* La __modularité__ rend aisée la mise à jour d'un pipeline et renforce la capacité à le réutiliser
* Ils permettent de facilement chercher les hyperparamètres d'un modèle. Sans *pipeline*, écrire un code qui fait du *tuning* d'hyperparamètres peut être pénible. Avec les *pipelines*, c'est une ligne de code. 
* La __sécurité__ d'être certain que les étapes de preprocessing sont bien appliquées aux jeux de données désirés avant l'estimation. 


{{% panel status="hint" title="Hint" icon="fa fa-lightbulb" %}}
Un des intérêts des *pipelines* scikit est qu'ils fonctionnent aussi avec
des méthodes qui ne sont pas issues de `scikit`. Il est très 
facile d'introduire un modèle de réseau de neurone `Keras` dans
un pipeline `scikit`. Pour introduire un modèle économétrique `statsmodels`
c'est un peu plus coûteux mais nous allons proposer des exemples
qui peuvent servir de modèle et qui montrent que c'est faisable 
sans trop de difficulté.
{{% /panel %}}

