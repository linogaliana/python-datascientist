---
title: "Partie 1: manipuler des données"
date: 2020-07-16
draft: false
weight: 20
#linktitle: manipulation
type: book
summary: |
  Python s'est imposé comme une alternative très crédible à R dans
  la manipulation de données. L'écosystème pandas a permis de démocratiser
  l'utilisation des DataFrames dans Python et faciliter la manipulation
  de données structurées grâce à la philosophie SQL. Python reste également
  le langage le plus pratique pour récupérer et manipuler
  des données moins structurées (webscraping, API). Python tend à devenir,
  grâce au développement d'API vers d'autres langages (C, Spark, Postgres,
  ElasticSearch...),
  le langage *"one to rule them all"*
slug: manipulation
icon: database
icon_pack: fas
---

Le *dataframe* est l'outil central du logiciel `R` mais il s'agit d'un objet qui, en `Python`, ne s'est
imposé que récemment, notamment grâce au package `pandas`. Le concept de *dataframe* est relativement 
intuitif et il existe un grand socle d'approches, héritières notamment de la logique SQL, 
facilitant le maniement de ces données.

`pandas` est devenu incontournable dans l'écosystème `Python` pour la *data science*. 
`pandas` est lui-même construit à partir du package `numpy`, qu'il est utile de comprendre
pour être à l'aise avec `pandas`. `numpy` est une librairie bas-niveau 
pour stocker et manipuler des données. 
`numpy` est au coeur de l'écosystème de la *data science* car la plupart des librairies, même celles
qui manient des objets destructurés,
utilisent des objets construits à partir de `numpy`. 

L'approche `pandas` a été étendue aux objets géographiques avec `geopandas`.
Il est ainsi possible de manipuler des données géographiques comme s'il
s'agissait de données structurées classiques. Les données géographiques et
la représentation cartographique deviennent de plus en plus commun avec
la multiplication de données ouvertes localisées et de *big-data* géolocalisées.

Cependant, les données structurées, importées depuis des fichiers plats
ne représentent pas l'unique source de données. Les API et le *webscraping*
permettent de requêter ou d'extraire 
des données de manière très flexible. Ces données, notamment
celles obtenues par *webscraping* nécessitent souvent un peu plus de travail
de nettoyage de données, notamment des chaînes de caractère. 

## Structure de la partie


{{< list_children >}}

## Exercices

Les notebooks d'exercices sont listés [ici](listetp). Il est
possible de les consulter sur ce site ou d'utiliser l'un des
badges présents en début de chapitre, par exemple
ceux-ci pour ouvrir le TP `pandas`:

```{python}
#| echo: false
#| output: 'asis'
#| include: true
#| eval: true

import sys
sys.path.insert(1, '../../../') #insert the utils module
from utils import print_badges

#print_badges(__file__)
print_badges("content/course/manipulation/02b_pandas_TP.qmd")
```



## Pour aller plus loin

Ce cours n'aborde pas encore les questions de volumétrie ou de vitesse de 
calcul. `pandas` peut montrer ses limites dans ce domaine. 

Il est ainsi intéressant de porter attention à:

* Le livre [Modern Pandas](https://tomaugspurger.github.io/modern-1-intro.html)
pour obtenir des éléments supplémentaires sur la question de la performance
avec `pandas`
* La question des
[objets sparse](https://chrisalbon.com/machine_learning/vectors_matrices_and_arrays/create_a_sparse_matrix/)
* Le package [`dask`](https://dask.org/) pour accélérer les calculs
* [`pySpark`](https://spark.apache.org/docs/latest/api/python/index.html) pour des données très volumineuses



