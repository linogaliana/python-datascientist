---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.6.0
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
title: "Natural Language Processing (NLP): quelques éléments"
date: 2020-10-15T13:00:00Z
draft: false
weight: 70
output: 
  html_document:
    keep_md: true
    self_contained: true
slug: nlp
---


{{% panel status="warning" title="Warning" icon="fa fa-exclamation-triangle" %}}
Le NLP est un domaine immense de recherche. Cette page est une introduction
fort incomplète à la question. Il s'agit de montrer la logique, quelques exemples
avec `Python` <i class="fab fa-python"></i>
et s'amuser avec comme base d'exemple un livre formidable :books: :
*Le Comte de Monte Cristo*
{{% /panel %}}

## Base d'exemple

La base d'exemple est le *Comte de Monte Cristo* d'Alexandre Dumas.
Il est disponible
gratuitement sur le site
[Project Gutemberg](http://www.gutenberg.org/ebooks/author/492) comme des milliers
d'autres livres dans le domaine public. La manière la plus simple de le récupérer
est de télécharger avec le module `urllib` le fichier texte et le retravailler
légèrement pour ne conserver que le corpus du livre. 

```{python}
from urllib import request

url = "https://www.gutenberg.org/ebooks/17989.txt.utf-8"
response = request.urlopen(url)
raw = response.read().decode('utf8')
dumas = raw.split("Produced by Chuck Greif and www.ebooksgratuits.com")[1].split("End of the Project Gutenberg EBook")[0]

import re

def clean_text(text):
    text = text.lower() # mettre les mots en minuscule
    text = " ".join(text.split())
    return text

dumas = clean_text(dumas)

dumas[10000:10500]
```


## La particularité des données textuelles

### Objectif

Le *natural language processing* (NLP) ou
*traitement automatisé de la langue* (TAL) en Français, vise à extraire de l'information de textes à partir d'une analyse statistique du contenu. 
Cette définition permet d'inclure de nombreux champs d'applications au sein
du NLP (traduction, analyse de sentiment, recommandation, surveillance, etc. ) ainsi que de méthodes. 

Cette approche implique de transformer un texte, qui est une information compréhensible par un humain, en un nombre, information appropriée pour un ordinateur et une approche statistique ou algorithmique. 

Transformer une information textuelle en valeurs numériques propres à une analyse statistique n'est pas une tâche évidente. Les données textuelles sont **non structurées** puisque l'information cherchée, qui est propre à chaque analyse, est perdue au milieu d'une grande masse d'information qui doit, de plus, être interprétée dans un certain contexte (un même mot ou une phrase n'ayant pas la même signification selon le contexte). 

Si cette tâche n'était pas assez difficile comme ça, on peut ajouter d'autres difficultés propres à l'analyse textuelle car ces données sont:

* bruitées: ortographe, fautes de frappe...
* changeantes: la langue évolue avec de nouveaux mots, sens...
* complexes: structures variables, accords...
* ambigues: synonymie, polysémie, sens caché...
* propres à chaque langue: il n'existe pas de règle de passage unique entre deux langues
* grande dimension: des combinaisons infinies de séquences de mots

### Méthode

L’unité textuelle peut être le mot ou encore une séquence de *n*
mots (un *n-gramme*) ou encore une chaîne de caractères (e.g. la
ponctuation peut être signifiante). On parle de **token**. L’analyse textuelle vise à transformer le texte en données
numériques manipulables. 

On peut ensuite utiliser diverses techniques (clustering,
classification supervisée) suivant l’objectif poursuivi pour exploiter
l’information transformée. Mais les étapes de nettoyage de texte sont indispensables car sinon un algorithme sera incapable de détecter une information pertinente dans l'infini des possibles. 




## Nettoyer un texte

```{python}
import wordcloud

mycloud = wordcloud.WordCloud().generate(dumas)
import matplotlib.pyplot as plt
plt.imshow(mycloud, interpolation='bilinear')
plt.axis("off")


import numpy as np
import io
import requests

img = "https://upload.wikimedia.org/wikipedia/commons/thumb/9/92/Open_book_nae_02.svg/1000px-Open_book_nae_02.svg.png"
book_mask = np.array(PIL.Image.open(io.BytesIO(requests.get(img).content)))
```
