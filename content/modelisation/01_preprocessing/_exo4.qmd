:::: {.content-visible when-profile="fr"}

::: {.exercise}
## Exercice 4 : Normalisation

1. A l'aide de la documentation de la fonction [`train_test_split`](https://scikit-learn.org/dev/modules/generated/sklearn.model_selection.train_test_split.html) de `Scikit`, créer deux échantillons (respectivement 70% et 30% des données).
2. Normaliser la variable `Median_Household_Income_2019` (ne pas écraser les valeurs !) et regarder l'histogramme avant/après normalisation.
3. Vérifier que la norme $\mathcal{l}_2$ est bien égale à 1 (grâce à la fonction `np.linalg.norm` et l'argument `axis=1` pour les 10 premières observations, sur l'ensemble d'entraînement puis sur les autres observations.

:::
::::

:::: {.content-visible when-profile="en"}

::: {.exercise}
## Exercise 4: Normalization

1. Using the documentation for the [`train_test_split`](https://scikit-learn.org/dev/modules/generated/sklearn.model_selection.train_test_split.html) function in `Scikit`, create two samples (70% and 30% of the data, respectively).
2. Normalize the `Median_Household_Income_2019` variable (do not overwrite the values!) and examine the histogram before and after normalization.
3. Verify that the $\mathcal{l}_2$ norm is indeed equal to 1 (using the `np.linalg.norm` function with the `axis=1` argument) for the first 10 observations in the training set and then for the other observations.
:::

::::



```{python}
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    df2.drop(columns = "winner"),
    df2['winner'], test_size=0.3
)
```

```{python}
# 1. Normalisation des variables et vérification sur Median_Household_Income_2019
scaler = preprocessing.Normalizer().fit(X_train)
X1 = pd.DataFrame(
  scaler.transform(X_train),
  columns = X_train.columns
)
X2 = pd.DataFrame(
  scaler.transform(X_test),
  columns = X_test.columns
)
```

```{python}
p1 = (
  ggplot(X_train, aes(x = "Median_Household_Income_2019")) +
  geom_histogram() +
  labs(x = "2019 Median household income ($)")
)
p2 = (
  ggplot(X1, aes(x = "Median_Household_Income_2019")) +
  geom_histogram() +
  labs(x = "2019 Median household income (normalized, training sample)")
)
p3 = (
  ggplot(X2, aes(x = "Median_Household_Income_2019")) +
  geom_histogram() +
  labs(x = "2019 Median household income (normalized, extrapolated sample)")
)
```


```{python}
#| fig-cap: "Question 2, avant normalisation"
p1
```

```{python}
#| fig-cap: "Question 2, variable transformée, sur l'échantillon de normalisation"
p2
```

```{python}
#| fig-cap: "Question 2, variable transformée, à partir des paramètres entraînés"
p3
```



::: {.content-visible when-profile="fr"}
Enfin, si on calcule la norme, on obtient bien le résultat attendu à la fois sur l'échantillon _train_ et sur l'échantillon extrapolé.
:::

::: {.content-visible when-profile="en"}
Finally, if we compute the norm, we obtain the expected result on both the train sample and the extrapolated sample.
:::


```{python}
# 3. Vérification de la norme L2
pd.DataFrame(
  {
    "X_train_norm2": np.linalg.norm(X1.head(10), axis=1),
    "X_test_norm2": np.linalg.norm(X2.head(10), axis=1)
  }
).head(5)
```