---
title: "Pr√©paration des donn√©es pour construire un mod√®le"
title-en: "Preprocessing before building machine learning models"
author: Lino Galiana
tags:
  - scikit
  - machine learning
  - US election
  - preprocessing
  - Modelisation
  - Exercice
categories:
  - Mod√©lisation
  - Exercice
description: |
  Afin d'avoir des donn√©es coh√©rentes avec les hypoth√®ses de mod√©lisation, il est fondamental de prendre le temps de pr√©parer les donn√©es √† fournir √† un mod√®le. La qualit√© de la pr√©diction d√©pend fortement de ce travail pr√©alable qu'on appelle _preprocessing_. Ce chapitre pr√©sente les enjeux et les illustre par le biais de la librairie `Scikit Learn`, qui rend ce travail moins fastidieux et plus fiable. 
description-en: |
  In order to obtain data that is consistent with modeling assumptions, it is essential to take the time to prepare the data to be supplied to a model. The quality of the prediction depends heavily on this preliminary work, known as _preprocessing_. This chapter presents the issues involved and illustrates them using the `Scikit Learn` library, which makes this work less tedious and more reliable.
bibliography: ../../reference.bib
image: https://minio.lab.sspcloud.fr/lgaliana/generative-art/pythonds/artisan.jfif
echo: false
---

{{< badges
    printMessage="true"
>}}

:::: {.content-visible when-profile="fr"}

::: {.callout-tip collapse="true"}

## Comp√©tences √† l'issue de ce chapitre

- Comprendre l‚Äôimportance cruciale du preprocessing pour garantir la coh√©rence entre les donn√©es et les hypoth√®ses de mod√©lisation, en s‚Äôappuyant sur l‚Äô√©cosyst√®me robuste de Scikit-Learn ;
- Explorer la structure des donn√©es √† l‚Äôaide de Pandas pour s√©lectionner les variables pertinentes avant mod√©lisation ;
- Transformer les donn√©es continues selon les besoins du mod√®le : standardisation (distribution centr√©e-r√©duite) ou normalisation (norme unit√©), selon le contexte de l‚Äôalgorithme ;
- Encoder les variables cat√©gorielles via LabelEncoder, OrdinalEncoder ou OneHotEncoder pour les rendre utilisables en mod√©lisation ;
- G√©rer les valeurs manquantes gr√¢ce √† l‚Äôimputation (moyenne, m√©diane, mode ou m√©thodes plus sophistiqu√©es), au lieu de supprimer syst√©matiquement les observations ;
- D√©tecter et traiter les valeurs aberrantes (outliers), en les identifiant via leur distribution, puis en les retirant si elles nuisent √† la qualit√© du mod√®le ;
- Comprendre que, du point de vue de l'impl√©mentation en Scikit, le preprocessing constitue un apprentissage : les param√®tres estim√©s (moyenne, variance) sur l‚Äôensemble d‚Äôentra√Ænement peuvent √™tre r√©-appliqu√©s √† tout nouveau jeu de donn√©es, assurant que la distribution des donn√©es post-processing co√Øncide avec celle des donn√©es d'apprentissage.

:::

::::

  
::::: {.content-visible when-profile="en"}

::: {.callout-tip collapse="true"}

## Skills you will acquire in this chapter

- Understand the critical role of preprocessing in aligning data with modeling assumptions, using the robust Scikit-Learn ecosystem  
- Use Pandas to explore data structure and select relevant features before modeling  
- Transform continuous variables to fit model requirements: standardization (zero mean, unit variance) or normalization (unit norm), depending on the algorithm  
- Encode categorical variables using `LabelEncoder`, `OrdinalEncoder`, or `OneHotEncoder` to make them usable in machine learning models  
- Handle missing data through imputation (mean, median, mode, or more advanced techniques) rather than simply dropping observations  
- Detect and manage outliers by analyzing their distribution and removing them when they negatively impact model performance  
- Understand that in Scikit-Learn, preprocessing is part of the learning process: parameters like mean or variance are estimated from the training set and reapplied to new data, ensuring consistency in distribution between training and prediction phases  



:::

::::

::: {.content-visible when-profile="fr"}
# Introduction

L'[introduction de cette partie](/content/modelisation/index.qmd) pr√©sentait les enjeux de l'adoption d'une approche algorithmique plut√¥t que statistique pour mod√©liser des processus empiriques. L'objectif de ce chapitre est d'introduire √† la m√©thodologie du _machine learning_, aux choix qu'impliquent une approche algorithmique sur la structuration du travail sur les donn√©es. Ce sera √©galement l'occasion de pr√©senter l'√©cosyst√®me du _machine learning_ en `Python` et notamment la librairie centrale dans celui-ci: [`Scikit Learn`](https://scikit-learn.org/stable/).

L'objectif de ce chapitre est de pr√©senter quelques √©l√©ments de 
pr√©paration des donn√©es. Il s'agit d'une √©tape fondamentale, √† ne
pas n√©gliger. Les mod√®les reposent sur certaines hypoth√®ses, g√©n√©ralement
relatives √† la distribution th√©orique des variables, qui y sont int√©gr√©es.

Il est n√©cessaire de faire correspondre la distribution empirique
√† ces hypoth√®ses, ce qui implique un travail de restructuration des donn√©es.
Celui-ci permettra d'avoir des r√©sultats de mod√©lisation plus pertinents. 
Nous verrons dans le chapitre sur les *pipelines* comment industrialiser
ces √©tapes de _preprocessing_ afin de se simplifier la vie pour appliquer
un mod√®le sur un jeu de donn√©es diff√©rent de celui sur lequel il a √©t√© estim√©. 

Ce chapitre, comme l'ensemble de la partie _machine learning_, est une introduction pratique illustr√©e dans une perspective de pr√©diction √©lectorale. En l'occurrence, il s'agit de pr√©dire les r√©sultats des √©lections am√©ricaines de 2020 au niveau comt√© √† partir de variables socio-d√©mographiques. L'id√©e sous-jacente est qu'il existe des facteurs sociologiques, √©conomiques ou d√©mographiques influen√ßant le vote mais dont on ne conna√Æt pas bien les motifs ou les interactions complexes entre plusieurs facteurs.
:::

::: {.content-visible when-profile="en"}

# Introduction

The [introduction to this section](/content/modelisation/index.qmd) discussed the importance of adopting an algorithmic rather than a statistical approach for modeling empirical processes. The goal of this chapter is to introduce machine learning methodology and the choices that an algorithmic approach entails for structuring data work. This will also be an opportunity to introduce the Python machine learning ecosystem, particularly its core library: [`Scikit-Learn`](https://scikit-learn.org/stable/).

The aim of this chapter is to present some data preparation elements. This is a fundamental step that should not be overlooked. Models are based on certain assumptions, usually related to the theoretical distribution of variables, which are integrated into them.

It is necessary to align the empirical distribution with these assumptions, which requires a restructuring of the data. This will lead to more relevant modeling results. In the chapter on *pipelines*, we will see how to industrialize these preprocessing steps to simplify applying a model to a dataset different from the one on which it was estimated.

This chapter, like the entire machine learning section, is a practical introduction illustrated from an electoral prediction perspective. Specifically, it involves predicting the results of the 2020 U.S. elections at the county level based on socio-demographic variables. The underlying idea is that there are sociological, economic, or demographic factors influencing voting behavior, but the motivations or complex interactions between these factors are not well understood.

:::



::: {.content-visible when-profile="fr"}
## Pr√©sentation de l'√©cosyst√®me `Scikit`

`Scikit Learn` est aujourd'hui la librairie de r√©f√©rence dans l'√©cosyst√®me du
_Machine Learning_. Il s'agit d'une librairie qui, malgr√© les tr√®s nombreuses
m√©thodes impl√©ment√©es, pr√©sente l'avantage d'√™tre un point d'entr√©e unifi√©.
Cet aspect unifi√© est l'une des raisons du succ√®s pr√©coce de celle-ci. `R` n'a 
b√©n√©fici√© que plus r√©cemment d'une librairie unifi√©e,
√† savoir [`tidymodels`](https://www.tidymodels.org/).

Une autre raison du succ√®s de `Scikit` est son approche op√©rationnelle : la mise
en production de mod√®les d√©velopp√©s via les _pipelines_ `Scikit` est peu co√ªteuse.
Un [chapitre sp√©cial de ce cours](/pipeline-scikit) est d√©di√© aux _pipelines_.
Avec Romain Avouac, nous proposons un [cours plus avanc√©](https://ensae-reproductibilite.github.io/website/) 
en derni√®re ann√©e d'ENSAE o√π nous pr√©sentons certains enjeux relatifs
√† la mise en production de mod√®les d√©velopp√©s avec `Scikit`. 

Le guide utilisateur de `Scikit` est une r√©f√©rence pr√©cieuse,
√† consulter r√©guli√®rement. La partie sur le *preprocessing*, objet de ce chapitre, est
disponible [ici](https://scikit-learn.org/stable/modules/preprocessing.html).

:::

::: {.content-visible when-profile="en"}

## Introduction to the `Scikit` ecosystem

`Scikit Learn` is currently the go-to library in the machine learning ecosystem. It is a library that, despite its many implemented methods, offers the advantage of a unified entry point. This unified approach is one of the reasons for its early success. `R` only recently gained a unified library, namely [`tidymodels`](https://www.tidymodels.org/).

Another reason for `Scikit`'s success is its operational focus: deploying models developed through `Scikit` pipelines is cost-effective. A [dedicated chapter of this course](/pipeline-scikit) covers pipelines.
Together with Romain Avouac, we offer a [more advanced course](https://ensae-reproductibilite.github.io/website/) in the final year at ENSAE, where we present some challenges related to deploying models developed with `Scikit`.

The `Scikit` user guide is a valuable reference to consult regularly. The section on *preprocessing*, the focus of this chapter, is available [here](https://scikit-learn.org/stable/modules/preprocessing.html).

:::




:::: {.content-visible when-profile="fr"}

::: {.callout-note}
## `Scikit Learn`, un succ√®s fran√ßais ! üêìü•ñü•ê

`Scikit Learn` est une librairie _open source_ issue des travaux de l'[Inria](https://www.inria.fr/fr) üá´üá∑. Depuis plus de 10 ans, cette institution publique fran√ßaise d√©veloppe et maintient ce _package_ t√©l√©charg√© 2 millions de fois par jour. En 2023, pour s√©curiser la maintenance de ce _package_, une  _start up_ nomm√©e [`Probabl.ai`](https://probabl.ai/) a √©t√© cr√©√©e autour de l'√©quipe des d√©veloppeurs.euses de `Scikit`.

Pour d√©couvrir la richesse de l'√©cosyst√®me `Scikit`, il 
est recommand√© de suivre le
[`MOOC scikit`](https://www.fun-mooc.fr/fr/cours/machine-learning-python-scikit-learn/),
d√©velopp√© dans le cadre de l'initiative [`Inria Academy`](https://www.inria.fr/fr/mooc-scikit-learn).

:::

::::

:::: {.content-visible when-profile="en"}

::: {.callout-note}
## `Scikit Learn`, a French Success! üêìü•ñü•ê

`Scikit Learn` is an open-source library originating from the work of [Inria](https://www.inria.fr/fr) üá´üá∑. For over 10 years, this French public institution has developed and maintained this package, which is downloaded 2 million times a day. In 2023, to secure the maintenance of this package, a startup named [`Probabl.ai`](https://probabl.ai/) was created around the team of `Scikit` developers.

To explore the depth of the `Scikit` ecosystem, it is recommended to follow the
[`Scikit MOOC`](https://www.fun-mooc.fr/fr/cours/machine-learning-python-scikit-learn/),
developed as part of the [`Inria Academy`](https://www.inria.fr/fr/mooc-scikit-learn) initiative.
:::

::::


::: {.content-visible when-profile="fr"}

## Pr√©paration des donn√©es

L'exercice 1 permet, √† ceux qui le d√©sirent, d'essayer de le reconstituer pas √† pas. 

Les _packages_ suivants sont n√©cessaires pour importer et visualiser
les donn√©es d'√©lection :

:::

::: {.content-visible when-profile="en"}

## Data preparation

Exercise 1 allows those interested to try to recreate it step by step.

The following packages are needed to import and visualize the election data:

:::


```{python}
#| eval: false
#| echo: true
!pip install --upgrade xlrd
!pip install geopandas
```


::: {.content-visible when-profile="fr"}

Les sources de donn√©es √©tant diverses, le code qui construit la base finale est directement fourni. 
Le travail de construction d'une base unique
est un peu fastidieux mais il s'agit d'un bon exercice, que vous pouvez tenter,
pour [r√©viser `Pandas`](/content/manipulation/02a_pandas_tutorial.qmd):

:::

::: {.content-visible when-profile="en"}

The data sources are varied, so the code that builds the final dataset is provided directly.
Building a single dataset can be somewhat tedious, but it‚Äôs a good exercise, which you can try,
to [review `Pandas`](/content/manipulation/02a_pandas_tutorial.qmd):

:::

{{< include "01_preprocessing/_exo1.qmd" >}}

::: {.content-visible when-profile="fr"}
N√©anmoins, avant de se concentrer sur la pr√©paration des donn√©es, nous
allons passer un peu de temps √† explorer la structure des donn√©es 
√† partir de laquelle nous d√©sirons construire une mod√©lisation. Ceci 
est indispensable afin de comprendre la nature de celles-ci et choisir
une mod√©lisation ad√©quate. 

Ce code introduit une base nomm√©e `votes` dans l'environnement. Il s'agit d'une base rassemblant les diff√©rentes sources. Elle a l'aspect
suivant :
:::

::: {.content-visible when-profile="en"}

However, before focusing on data preparation, we will spend some time exploring the structure of the data from which we want to build a model. This is essential to understand its nature and choose an appropriate model.

This code introduces a dataset named `votes` into the environment. It is a combined dataset from different sources and appears as follows:
:::


```{python}
#| echo: true
votes.loc[:, votes.columns != "geometry"].head(3)
```

::: {.content-visible when-profile="fr"}
La carte choropl√®the suivante permet de visualiser rapidement les r√©sultats
(l'Alaska et Hawa√Ø ont √©t√© exclus).
:::

::: {.content-visible when-profile="en"}

The following choropleth map provides a quick visualization of the results (Alaska and Hawaii are excluded).
:::


```{python}
#| warning: false
#| echo: true
#| message: false
#| code-fold: true
#| code-summary: "Code pour reproduire cette carte"
from plotnine import *

# republican : red, democrat : blue
color_dict = {'republican': '#FF0000', 'democrats': '#0000FF'}

(
  ggplot(votes) +
  geom_map(aes(fill = "winner")) +
  scale_fill_manual(color_dict) +
  labs(fill = "Winner") +
  theme_void() +
  theme(legend_position = "bottom")
)
```


:::: {.content-visible when-profile="fr"}

::: {.callout-important}
## Le pi√®ge territorial

Comme cela a √©t√© √©voqu√© dans le [chapitre consacr√© √† la cartographie](/content/visualisation/matplotlib.qmd), les cartes choropl√®thes peuvent donner une impression fallacieuse
que le parti R√©publicain a gagn√© largement en 2020 car ce type de repr√©sentation graphique donne plus d'importance aux grands espaces plut√¥t qu'aux espaces denses. Ceci explique que ce type de carte ait pu servir 
de justification pour contester les r√©sultats du vote.

Il existe des repr√©sentations √† 
privil√©gier pour ce type de ph√©nom√®nes o√π la densit√© est importante. L'une des repr√©sentations √† privil√©gier est les
ronds proportionnels (voir @inseeSemiologie, _"Le pi√®ge territorial en cartographie"_). Les cercles proportionnels permettent ainsi √† l'oeil de se concentrer sur les 
zones les plus denses et non sur les grands espaces. Cette fois, on voit bien
que le vote d√©mocrate est majoritaire, ce que cachait l'aplat de couleur. 

Le [GIF "Land does not vote, people do"](https://www.core77.com/posts/90771/A-Great-Example-of-Better-Data-Visualization-This-Voting-Map-GIF), qui avait eu un certain succ√®s en 2020, propose un autre mode de visualisation.
La carte originale a √©t√© construite avec `JavaScript`. Cependant,
on dispose avec `Python` de plusieurs outils
pour r√©pliquer, √† faible co√ªt, cette carte 
gr√¢ce √†
l'une des surcouches √† `JavaScript` vues dans la partie [visualisation](/content/visualisation/index.qmd). 

:::

::::

::: {.content-visible when-profile="en"}

:::: {.callout-important}
## The Territorial Trap

As mentioned in the [chapter on mapping](/content/visualisation/matplotlib.qmd), choropleth maps can give a misleading impression that the Republican Party won by a large margin in 2020 because this type of graphic representation gives more importance to large areas rather than dense areas. This explains why this type of map has been used as justification for contesting the election results.

There are alternative representations better suited to such phenomena where density is significant. One such representation is proportional circles (see @inseeSemiologie, _"The Territorial Trap in Cartography"_). Proportional circles allow the eye to focus on denser areas rather than large open spaces. With this representation, it becomes clear that the Democratic vote is in the majority, which was obscured by the flat color fill.

The [GIF "Land does not vote, people do"](https://www.core77.com/posts/90771/A-Great-Example-of-Better-Data-Visualization-This-Voting-Map-GIF), which gained popularity in 2020, offers another visualization approach. The original map was created with `JavaScript`. However, with `Python`, we have several tools to replicate this map at a low cost using one of the `JavaScript` overlays discussed in the [visualization section](/content/visualisation/index.qmd).

::::
:::



```{python}
#| echo: true
#| code-fold: true
#| code-summary: "Code pour reproduire cette carte interactive"
import numpy as np
import pandas as pd
import geopandas as gpd
import plotly
import plotly.graph_objects as go


centroids = votes.copy()
centroids.geometry = centroids.centroid
centroids['size'] = centroids['CENSUS_2020_POP'] / 10000  # to get reasonable plotable number

color_dict = {"republican": '#FF0000', 'democrats': '#0000FF'}
centroids["winner"] =  np.where(centroids['votes_gop'] > centroids['votes_dem'], 'republican', 'democrats') 


centroids['lon'] = centroids['geometry'].x
centroids['lat'] = centroids['geometry'].y
centroids = pd.DataFrame(centroids[["county_name",'lon','lat','winner', 'CENSUS_2020_POP',"state_name"]])
groups = centroids.groupby('winner')

df = centroids.copy()

df['color'] = df['winner'].replace(color_dict)
df['size'] = df['CENSUS_2020_POP']/6000
df['text'] = df['CENSUS_2020_POP'].astype(int).apply(lambda x: '<br>Population: {:,} people'.format(x))
df['hover'] = df['county_name'].astype(str) +  df['state_name'].apply(lambda x: ' ({}) '.format(x)) + df['text']

fig_plotly = go.Figure(
  data=go.Scattergeo(
  locationmode = 'USA-states',
  lon=df["lon"], lat=df["lat"],
  text = df["hover"],
  mode = 'markers',
  marker_color = df["color"],
  marker_size = df['size'],
  hoverinfo="text"
  )
)

fig_plotly.update_traces(
  marker = {'opacity': 0.5, 'line_color': 'rgb(40,40,40)', 'line_width': 0.5, 'sizemode': 'area'}
)

fig_plotly.update_layout(
  title_text = "Reproduction of the \"Acres don't vote, people do\" map <br>(Click legend to toggle traces)",
  showlegend = True,
  geo = {"scope": 'usa', "landcolor": 'rgb(217, 217, 217)'}
)

fig_plotly.show()
```


::: {.content-visible when-profile="fr"}
# La d√©marche g√©n√©rale

Dans ce chapitre, nous allons nous focaliser sur la pr√©paration
des donn√©es √† faire en amont du travail de mod√©lisation.
Cette √©tape est indispensable pour s'assurer de la coh√©rence
entre les donn√©es et les hypoth√®ses de mod√©lisation mais aussi
pour produire des analyses valides scientifiquement. 

La d√©marche g√©n√©rale que nous adopterons dans ce chapitre, et qui sera ensuite raffin√©e dans les prochains chapitres, est la suivante : 

![Illustraton de la m√©thodologie du _machine learning_](/content/modelisation/img/pipeline1.png){#fig-ml-pipeline}

La @fig-ml-pipeline illustre la structuration d'un probl√®me de _machine learning_. 

Tout d'abord, on d√©coupe l'ensemble des donn√©es disponibles en deux parties, __√©chantillons d'apprentissage__ et de __validation__. Le premier sert √† entra√Æner un mod√®le et la qualit√© des pr√©dictions de celui-ci est
√©valu√©e sur le deuxi√®me pour limiter
le biais de surapprentissage. Le chapitre suivant approfondira
cette question de l'√©valuation des mod√®les. A ce stade de notre
progression, on se concentrera dans ce chapitre
sur la question des donn√©es. 

La librairie `Scikit` est particuli√®rement pratique parce qu'elle propose √©norm√©ment d'algorithmes de _machine learning_ avec quelques points d'entr√©e unifi√©e, notamment les m√©thodes `fit` et `predict`. N√©anmoins, l'unification va au-del√† de l'entra√Ænement d'algorithmes. Toutes les √©tapes de pr√©paration de donn√©es qui sont int√©gr√©es dans `Scikit` proposent ces deux m√™mes points d'entr√©e. Autrement dit, les pr√©parations de donn√©es sont construites comme une estimation de param√®tres qui peut √™tre r√©appliqu√©e sur un autre jeu de donn√©es. Par exemple, cette pr√©paration de donn√©es peut √™tre une estimation de moyenne et variance pour normaliser des variables. La moyenne et la variance seront √©valu√©es sur l'√©chantillon d'apprentissage et les m√™mes moyennes et variances pourront √™tre r√©appliqu√©es sur un autre jeu de donn√©es pour le normaliser de la m√™me fa√ßon. 
:::

::: {.content-visible when-profile="en"}

# General Approach

In this chapter, we will focus on data preparation to be done before modeling work. This step is essential to ensure consistency between the data and modeling assumptions and to produce scientifically valid analyses.

The general approach we will adopt in this chapter, which will be refined in subsequent chapters, is as follows:

![Illustration of machine learning methodology](/content/modelisation/img/pipeline1.png){#fig-ml-pipeline}

@fig-ml-pipeline illustrates the structure of a machine learning problem.

First, the available dataset is split into two parts: __training sample__ and __validation sample__. The former is used to train a model, and its prediction quality is evaluated on the latter to limit overfitting bias. The next chapter will delve deeper into model evaluation. At this stage of our progress, we will focus in this chapter on data issues.

The `Scikit` library is particularly convenient because it offers many machine learning algorithms with a few unified entry points, especially the `fit` and `predict` methods. However, the unification extends beyond algorithm training. All data preparation steps integrated into `Scikit` offer these same entry points. In other words, data preparations are built like parameter estimations that can be reapplied to another dataset. For example, this data preparation might be a mean and variance estimation for normalizing variables. The mean and variance are calculated on the training sample, and the same values can be reapplied to another dataset to normalize it in the same way.
:::


::: {.content-visible when-profile="fr"}
# Explorer la structure des donn√©es

La premi√®re √©tape n√©cessaire √† suivre avant de se lancer dans la mod√©lisation
est de d√©terminer les variables √† inclure dans le mod√®le.

Les fonctionnalit√©s de `Pandas` sont, √† ce niveau, suffisantes pour explorer des structures simples.
N√©anmoins, lorsqu'on est face √† un jeu de donn√©es pr√©sentant de
nombreuses variables explicatives (*features* en machine learning, *covariates* en √©conom√©trie),
il est souvent judicieux d'avoir une premi√®re √©tape de s√©lection de variables,
ce que nous verrons par la suite dans la [partie d√©di√©e](/content/modelisation/4_featureselection.qmd).  

Avant d'√™tre en mesure de s√©lectionner le meilleur ensemble de variables explicatives,
nous allons en prendre un nombre restreint et arbitraire.
La premi√®re t√¢che est de repr√©senter les relations entre les donn√©es,
notamment la relation des variables explicatives
√† la variable d√©pendante (le score du parti r√©publicain)
ainsi que les relations entre les variables explicatives. 
:::

::: {.content-visible when-profile="en"}

# Exploring data structure

The first necessary step before diving into modeling is to determine which variables to include in the model.

`Pandas` functionalities are sufficient at this stage for exploring simple structures.
However, when dealing with a dataset with numerous explanatory variables (*features* in machine learning, *covariates* in econometrics), it is often wise to start with a variable selection step, which we will cover later in the [dedicated section](/content/modelisation/4_featureselection.qmd).

Before selecting the best set of explanatory variables, we will start with a small and arbitrary selection.
The first task is to represent the relationships within the data, particularly the relationship between explanatory variables and the dependent variable (the Republican Party‚Äôs score), as well as relationships among explanatory variables.
:::


{{< include "01_preprocessing/_exo2.qmd" >}}


::: {.content-visible when-profile="fr"}
# Transformer les donn√©es

Les diff√©rences d'√©chelle ou de distribution entre les variables peuvent 
diverger des hypoth√®ses sous-jacentes dans les mod√®les.

Par exemple, dans le cadre
de la r√©gression lin√©aire, les variables cat√©gorielles ne sont pas trait√©es √† la m√™me
enseigne que les variables ayant valeur dans $\mathbb{R}$. Une variable
discr√®te (prenant un nombre fini de valeurs) devra √™tre transform√©e en suite de
variables 0/1 (des _dummies_) par rapport √† une modalit√© de r√©f√©rence pour √™tre en ad√©quation
avec les hypoth√®ses de la r√©gression lin√©aire.
On appelle ce type de transformation
*one-hot encoding*, sur laquelle nous reviendrons. Il s'agit d'une transformation,
parmi d'autres, disponibles dans `Scikit` pour mettre en ad√©quation un jeu de
donn√©es et des hypoth√®ses math√©matiques. 

L'ensemble de ces t√¢ches de pr√©paration de donn√©es s'appelle le *preprocessing* ou le _feature engineering_. L'un des int√©r√™ts
d'utiliser `Scikit` est qu'on peut consid√©rer qu'une t√¢che de _preprocessing_
est, en fait, une t√¢che d'apprentissage. En effet, le _preprocessing_ 
consiste √† apprendre des param√®tres d'une structure 
de donn√©es (par exemple estimer moyennes et variances pour les retrancher √† chaque
observation) et on peut tr√®s bien appliquer ces param√®tres
√† des observations qui n'ont pas servi √† construire
ceux-ci. Autrement dit, cette pr√©paration de donn√©es s'int√®gre tr√®s bien dans le _pipeline_ @fig-ml-pipeline. 
:::

::: {.content-visible when-profile="en"}

# Transforming data

Differences in scale or distribution between variables can diverge from the underlying assumptions in models.

For example, in linear regression, categorical variables are not treated the same way as variables with values in $\mathbb{R}$. A discrete variable (taking a finite number of values) must be transformed into a sequence of 0/1 variables (dummies) relative to a reference category to meet the assumptions of linear regression. This type of transformation is known as *one-hot encoding*, which we will revisit. It is one of many transformations available in `Scikit` to align a dataset with mathematical assumptions.

All these data preparation tasks fall under preprocessing or feature engineering. One advantage of using `Scikit` is that preprocessing tasks can be considered learning tasks. Preprocessing involves learning parameters from a data structure (e.g., estimating means and variances to subtract from each observation), and these parameters can then be applied to observations not used to calculate them. In other words, this data preparation fits seamlessly into the pipeline shown in @fig-ml-pipeline.
:::


:::: {.content-visible when-profile="fr"}
## _Preprocessing_ de variables continues

Nous allons voir deux processus tr√®s classiques de *preprocessing* pour des variables continues : 

1. La **standardisation** transforme des donn√©es pour que la distribution empirique suive une loi $\mathcal{N}(0,1)$.

2. La **normalisation**  transforme les donn√©es de mani√®re √† obtenir une norme ($\mathcal{l}_1$ ou $\mathcal{l}_2$) unitaire. Autrement dit, avec la norme ad√©quate, la somme des √©l√©ments est √©gale √† 1.

Il en existe d'autres, par exemple le `MinMaxScaler` pour renormaliser les variables en fonction des bornes minimales et maximales des valeurs observ√©es. Le choix de la m√©thode √† mettre en oeuvre d√©pend du type d'algorithmes choisis par la suite: les hypoth√®ses des k plus proches voisins (knn) seront diff√©rentes de celles d'une _random forest_. C'est pour cette raison que, normalement, on d√©finit des _pipelines_ complets, int√©grant √† la fois _preprocessing_ et apprentissage. Ce sera l'objet des prochains chapitres.

::: {.callout-caution}
Pour les statisticiens.ennes,
le terme _normalization_ dans le vocable `Scikit` peut avoir un sens contre-intuitif.
On s'attendrait √† ce que la normalisation consiste √† transformer une variable de mani√®re √† ce que $X \sim \mathcal{N}(0,1)$.
C'est, en fait, la **standardisation** en `Scikit` qui fait cela.

:::
::::

:::: {.content-visible when-profile="en"}

## Continuous Variable Preprocessing

We will cover two very common preprocessing steps for continuous variables:

1. **Standardization** transforms data so that the empirical distribution follows a $\mathcal{N}(0,1)$ distribution.

2. **Normalization** transforms data to achieve a unit norm ($\mathcal{l}_1$ or $\mathcal{l}_2$). In other words, with the appropriate norm, the sum of elements equals 1.

There are other options, such as `MinMaxScaler` to rescale variables according to observed minimum and maximum bounds. The choice of method depends on the algorithms chosen later: the assumptions of k-nearest neighbors (knn) differ from those of a random forest. For this reason, complete pipelines are usually defined, integrating both preprocessing and learning, which will be discussed in upcoming chapters.

:::: {.callout-caution}
For statisticians,
the term _normalization_ in `Scikit` terminology can have a counterintuitive meaning.
One might expect normalization to transform a variable so that $X \sim \mathcal{N}(0,1)$.
In `Scikit`, this is actually **standardization**.

::::

:::


::: {.content-visible when-profile="fr"}
### Standardisation

La standardisation consiste √† transformer des donn√©es pour que la distribution empirique suive une loi $\mathcal{N}(0,1)$. Pour √™tre performants, la plupart des mod√®les de _machine learning_ n√©cessitent souvent d'avoir des donn√©es dans cette distribution. M√™me lorsque ce n'est pas indispensable, par exemple avec des r√©gressions logistiques, cela peut acc√©l√©rer la vitesse de convergence des algorithmes.
:::

::: {.content-visible when-profile="en"}

### Standardization

Standardization involves transforming data so that the empirical distribution follows a $\mathcal{N}(0,1)$ distribution. For optimal performance, most machine learning models often require data to follow this distribution. Even when it‚Äôs not essential, as with logistic regressions, it can speed up the convergence rate of algorithms.
:::


{{< include "01_preprocessing/_exo3.qmd" >}}


:::: {.content-visible when-profile="fr"}

C'est une illustration d'un probl√®me classique en _machine learning_, le _data drift_, qui arrive lorsqu'on essaie d'extrapoler √† des donn√©es dont la distribution ne correspond plus √† celle des donn√©es d'apprentissage. Ce type de situation arrive typiquement lorsqu'on a entra√Æn√© un algorithme sur un √©chantillon biais√© de la population ou lorsqu'on a des s√©ries temporelles non stationnaires. Il est donc important de bien r√©fl√©chir √† la constitution de l'√©chantillon d'apprentissage et aux possibilit√©s d'extrapolation sur une population plus large : la validit√© externe du mod√®le - pr√©paration des donn√©es ou algorithme d'apprentissage - peut √™tre nulle si cette √©tape a √©t√© r√©alis√©e de mani√®re h√¢tive.

::: {.callout-important}
## Le _data drift_

Le _data drift_ d√©signe un changement dans la distribution des donn√©es au fil du temps, entra√Ænant une d√©gradation des performances d‚Äôun mod√®le de _machine learning_ qui, par construction, a √©t√© entra√Æn√© sur des donn√©es pass√©es. 

Ce ph√©nom√®ne peut survenir √† cause de variations dans la population cible, de changements dans les caract√©ristiques des donn√©es ou de facteurs externes. 

Il est crucial de d√©tecter le _data drift_ pour ajuster ou r√©entra√Æner le mod√®le, afin de maintenir sa pertinence et sa pr√©cision. Les techniques de d√©tection incluent des tests statistiques et le suivi de m√©triques sp√©cifiques.

:::
::::

:::: {.content-visible when-profile="en"}

This is an illustration of a classic problem in machine learning, called _data drift_, which occurs when we attempt to extrapolate to data whose distribution no longer corresponds to that of the training data. This situation typically arises when an algorithm has been trained on a biased sample of the population or when we have non-stationary time series data. It is, therefore, essential to carefully consider the construction of the training sample and the potential for extrapolation to a broader population: the external validity of the model‚Äîwhether data preparation or learning algorithm‚Äîcan be null if this step was rushed.

::: {.callout-important}
## Data Drift

Data drift refers to a shift in data distribution over time, leading to a degradation in the performance of a machine learning model that, by design, was trained on past data.

This phenomenon can occur due to changes in the target population, shifts in data characteristics, or external factors.

Detecting data drift is crucial to adjust or retrain the model, ensuring its relevance and accuracy. Detection techniques include statistical tests and monitoring specific metrics.
:::
::::


::: {.content-visible when-profile="fr"}
### Normalisation

La **normalisation** est l'action de transformer les donn√©es de mani√®re
√† obtenir une norme ($\mathcal{l}_1$ ou $\mathcal{l}_2$) unitaire.
Autrement dit, avec la norme ad√©quate, la somme des √©l√©ments est √©gale √† 1.
Par d√©faut, la norme utilis√©e par `Scikit` est une norme  $\mathcal{l}_2$.
Cette transformation est particuli√®rement utilis√©e en classification de texte ou pour effectuer du *clustering*.

Au passage, ceci est l'occasion de d√©couvrir comment d√©couper ses donn√©es en plusieurs √©chantillons gr√¢ce √† la fonction [`train_test_split`](https://scikit-learn.org/dev/modules/generated/sklearn.model_selection.train_test_split.html) de `Scikit`. Nous allons faire un √©chantillon de 70% des donn√©es pour estimer les param√®tres de normalisation (phase d'apprentissage) et extrapoler aux 30% de donn√©es restantes. Cette r√©partition est assez classique mais est bien-s√ªr adaptable selon les projets. L'avantage d'utiliser [`train_test_split`](https://scikit-learn.org/dev/modules/generated/sklearn.model_selection.train_test_split.html) plut√¥t que de faire soi-m√™me les √©chantillonnages avec la m√©thode `sample` de `Pandas` est que la fonction de `Scikit` permettra d'aller beaucoup plus loin dans le param√©trage de l'√©chantillonnage, notamment si on d√©sire de la stratification, tout en √©tant fiable. Faire ceci de mani√®re manuelle est fastidieux et risqu√© car potentiellement complexe √† mettre en oeuvre sans erreur. 
:::

::: {.content-visible when-profile="en"}

### Normalization

**Normalization** is the process of transforming data to achieve a unit norm ($\mathcal{l}_1$ or $\mathcal{l}_2$).
In other words, with the appropriate norm, the sum of elements equals 1.
By default, `Scikit` uses an $\mathcal{l}_2$ norm.
This transformation is especially useful in text classification or clustering.

This is also an opportunity to explore how to split data into multiple samples using the [`train_test_split`](https://scikit-learn.org/dev/modules/generated/sklearn.model_selection.train_test_split.html) function in `Scikit`. We will create a 70% sample of the data to estimate normalization parameters (training phase) and extrapolate to the remaining 30%. This split is fairly standard but, of course, adaptable depending on the project. The advantage of using [`train_test_split`](https://scikit-learn.org/dev/modules/generated/sklearn.model_selection.train_test_split.html) instead of manually sampling with `Pandas`‚Äô `sample` method is that `Scikit`‚Äôs function allows for much more control over sampling, particularly if stratification is desired, while being reliable. Doing this manually can be tedious and risky, as it is potentially complex to implement without errors.
:::


{{< include "01_preprocessing/_exo4.qmd" >}}



::: {.content-visible when-profile="fr"}
## Encodage des valeurs cat√©gorielles

Les donn√©es cat√©gorielles doivent √™tre recod√©es sous forme de valeurs num√©riques pour √™tre int√©gr√©s aux mod√®les de *machine learning*.

Cela peut √™tre fait de plusieurs mani√®res avec `Scikit` :

* `LabelEncoder`: transforme un vecteur `["a","b","c"]` en vecteur num√©rique `[0,1,2]`. Cette approche a l'inconv√©nient d'introduire un ordre dans les modalit√©s, ce qui n'est pas toujours souhaitable.
* `OrdinalEncoder`: une version g√©n√©ralis√©e du `LabelEncoder` qui a vocation √† s'appliquer sur des matrices ($X$),
alors que `LabelEncoder` s'applique plut√¥t √† un vecteur ($y$).

En ce qui concerne le _one hot encoding_, il est possible d'utiliser plusieurs m√©thodes :

* `pandas.get_dummies` effectue une op√©ration de *dummy expansion*.
Un vecteur de taille *n* avec *K* cat√©gories sera transform√© en matrice de taille $n \times K$
pour lequel chaque colonne sera une variable *dummy* pour la modalit√© *k*.
Il y a ici $K$ modalit√©s et il y a donc multicolin√©arit√©.
Avec une r√©gression lin√©aire avec constante,
il convient de retirer une modalit√© avant l'estimation.

* `OneHotEncoder` est une version g√©n√©ralis√©e (et optimis√©e) de la *dummy expansion*. C'est la m√©thode recommand√©e.


## Imputation

Les donn√©es peuvent souvent contenir des valeurs manquantes, autrement dit des observations de notre _DataFrame_ contenant un `NaN`. Ces trous dans les donn√©es peuvent √™tre √† l'origine de _bugs_ ou de mauvaises interpr√©tations lorsque l'on passe √† la mod√©lisation.
Pour y rem√©dier, une premi√®re approche peut √™tre de retirer toutes les observations pr√©sentant un `NaN` dans au moins une des ses colonnes.
Cependant, si notre table contient beaucoup de `NaN`, ou bien que ces derniers sont r√©partis sur de nombreuses colonnes,
c'est aussi prendre le risque de retirer un nombre important de lignes, et avec cela de l'information importante pour un mod√®le car les valeurs manquantes sont rarement [r√©parties de mani√®re al√©atoire](https://stefvanbuuren.name/fimd/sec-MCAR.html).

M√™me si dans plusieurs situations, cette solution reste tout √† fait viable, il existe une autre approche plus robuste appel√©e *imputation*. Cette m√©thode consiste √† remplacer les valeurs manquantes par une valeur donn√©e. Par exemple :

- Imputation par la moyenne : remplacer tous les `NaN` dans une colonne par la valeur moyenne de la colonne ;
- Imputation par la m√©diane sur le m√™me principe, ou par la valeur de la colonne la plus fr√©quente pour les variables cat√©gorielles ;
- Imputation par r√©gression : se servir d'autres variables pour essayer d'interpoler une valeur de remplacement adapt√©e.

Des m√©thodes plus complexes existent mais dans de nombreux cas, les approches ci-dessus peuvent suffire pour donner des r√©sultats beaucoup plus satisfaisants.
Le package `Scikit` permet de faire de l'imputation de mani√®re tr√®s simple ([documentation ici](https://scikit-learn.org/stable/modules/impute.html)).


## Gestion des valeurs aberrantes (_outliers_)

Les valeurs aberrantes (_outliers_ en anglais) sont des observations qui se situent significativement √† l'ext√©rieur de la tendance g√©n√©rale des autres observations dans un ensemble de donn√©es. En d'autres termes, ce sont des points de donn√©es qui se d√©marquent de mani√®re inhabituelle par rapport √† la distribution globale des donn√©es.
Cela peut √™tre d√ª √† des erreurs de remplissage, des personnes ayant mal r√©pondu √† un questionnaire, ou
parfois simplement des valeurs extr√™mes qui peuvent biaiser un mod√®le de fa√ßon trop importante.

A titre d'exemple, cela va √™tre 3 individus mesurant plus de 4 m√®tres dans une population,
ou bien des revenus de m√©nage d√©passant les 10M d'euros par mois sur l'√©chelle d'un pays, etc.

Une bonne pratique peut donc √™tre de syst√©matiquement regarder la distribution des variables √† disposition,
pour se rendre compte si certaines valeurs s'√©loignent de fa√ßon trop importante des autres.
Ces valeurs vont parfois nous int√©resser, si, par exemple, on se concentre uniquement sur les tr√®s hauts revenus (top 0.1%)
en France. Cependant, ces donn√©es vont souvent nous g√™ner plus qu'autre chose, surtout si elles n'ont pas de sens dans le monde r√©el.

Si l'on estime que la pr√©sence de ces donn√©es extr√™mes, ou *outliers*, dans notre base de donn√©es vont √™tre probl√©matiques plus qu'autre chose,
alors il est tout √† fait entendable et possible de simplement les retirer.
La plupart du temps, on va se donner une proportion des donn√©es √† retirer, par exemple 0.1%, 1% ou 5%,
puis retirer dans les deux queues de la distribution les valeurs extr√™mes correspondantes.

Plusieurs packages permettent de faire ce type d'op√©rations, qui sont parfois plus complexes si on s'int√©resse aux outlier sur plusieurs variables.
On pourra notamment citer la fonction `IsolationForest()` du package `sklearn.ensemble`.
:::
::: {.content-visible when-profile="en"}

## Encoding Categorical Values

Categorical data must be recoded into numeric values to be integrated into machine learning models.

This can be done in several ways with `Scikit`:

* `LabelEncoder`: transforms a vector `["a","b","c"]` into a numeric vector `[0,1,2]`. This approach has the drawback of introducing an order to the categories, which is not always desirable.
* `OrdinalEncoder`: a generalized version of `LabelEncoder` designed to apply to matrices ($X$), while `LabelEncoder` applies mainly to a vector ($y$).

For one-hot encoding, several methods are available:

* `pandas.get_dummies` performs a dummy expansion.
A vector of size *n* with *K* categories will be transformed into a matrix of size $n \times K$, where each column represents a dummy variable for category *k*.
There are $K$ categories, resulting in multicollinearity.
In linear regression with a constant,
one category should be removed before estimation.

* `OneHotEncoder` is a generalized (and optimized) version of dummy expansion. This is the recommended method.


## Imputation

Data often contains missing values, that is, observations in our _DataFrame_ containing a `NaN`. These gaps can cause bugs or misinterpretations when moving to modeling.
One initial approach could be to remove all observations with a `NaN` in at least one column.
However, if our table contains many `NaN`s, or if these are spread across numerous columns,
we risk removing a significant number of rows, and, with that, losing important information, as missing values are rarely [randomly distributed](https://stefvanbuuren.name/fimd/sec-MCAR.html).

While this solution remains viable in many cases, a more robust approach called *imputation* exists. This method involves replacing missing values with a specified value. For example:

- Mean imputation: replacing all `NaN`s in a column with the column's average;
- Median imputation on the same principle, or using the most frequent column value for categorical variables;
- Regression imputation: using other variables to interpolate an appropriate replacement value.

More complex methods are available, but in many cases, the above approaches can provide much more satisfactory results.
The `Scikit` package makes imputation very straightforward ([documentation here](https://scikit-learn.org/stable/modules/impute.html)).


## Handling Outliers

Outliers are observations that significantly deviate from the general trend of other observations in a dataset. In other words, they are data points that stand out unusually from the overall data distribution.
This may be due to data entry errors, respondents who incorrectly answered a survey, or simply extreme values that may bias a model too much.

For example, these could be 3 individuals measuring over 4 meters in height within a population or household incomes exceeding 10 million euros per month at a national level.

It is good practice to routinely examine the distribution of available variables
to check if some values deviate too significantly from others.
Sometimes these values will interest us, for instance, if we are focusing solely on very high incomes (top 0.1%) in France. However, often these values will be more of a hindrance, especially if they don‚Äôt make sense in the real world.

If we find that the presence of these extreme values or *outliers* in our dataset is more problematic than helpful,
it is reasonable to simply remove them.
Most of the time, we set a percentage of data to remove, such as 0.1%, 1%, or 5%,
then remove the corresponding extreme values in both tails of the distribution.

Several packages can perform these operations, which can become complex if we examine outliers across multiple variables.
The `IsolationForest()` function in the `sklearn.ensemble` package is particularly noteworthy.
:::



::: {.content-visible when-profile="fr"}
## Exercice d'application

::: {.callout-caution}
## Attention aux nouvelles modalit√©s !

Les _transformers_ cr√©ent un _mapping_ entre des modalit√©s textuelles et des valeurs num√©riques. Cela pr√©suppose que les donn√©es sur lesquelles a √©t√© construit ce _mapping_ int√®grent l'ensemble des valeurs possibles pour les modalit√©s textuelles. 

N√©anmoins, si de nouvelles modalit√©s apparaissent, le classifieur ne saura pas comment celles-ci doivent √™tre transform√©es en valeurs num√©riques. Cela provoquera une erreur pour `Scikit`. Cette erreur technique est logique puisqu'il faudrait mettre √† jour non seulement le _mapping_ mais aussi l'estimation des param√®tres sous-jacents. 

:::

::::

:::: {.content-visible when-profile="en"}

## Application exercise

::: {.callout-caution}
## Be careful with new categories!

Transformers create a mapping between text categories and numeric values. This assumes that the data used to build this mapping includes all possible values for the text categories.

However, if new categories appear, the classifier will not know how to transform these into numeric values, which will cause an error in `Scikit`. This technical error makes sense, as it would require updating not only the mapping but also the estimation of underlying parameters.

:::
::::

{{< include "01_preprocessing/_exo5.qmd" >}}



::: {.content-visible when-profile="fr"}
# R√©f√©rences {.unnumbered}
:::

::: {.content-visible when-profile="en"}
# Reference {.unnumbered}
:::

::: {#refs}
:::
