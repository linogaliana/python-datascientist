---
title: "Découverte de la classification avec la technique des SVM"
title-en: "Discovering classification with the SVM technique"
author: Lino Galiana
categories:
  - Modélisation
description: |
  La classification permet d'attribuer une classe d'appartenance (_label_ dans la terminologie du _machine learning_) discrète à des données à partir de certaines variables explicatives (_features_ dans la même terminologie). Les algorithmes de classification sont nombreux. Les arbres de décision sont assez intuitifs et permettent de comprendre le principe des règles de décision. Ce chapitre illustre les enjeux de la classification à partir de ce modèle sur les données de vote aux élections présidentielles US de 2020.
description-en: |
  Classification enables us to assign a discrete membership class (_label_ in machine learning terminology) to data, based on certain explanatory variables (_features_ in the same terminology). Classification algorithms are numerous. Decision trees are among the most intuitive approach. This chapter illustrates the challenges of using this model to classify model on voting data for the 2020 US presidential elections.
echo: false
image: https://minio.lab.sspcloud.fr/lgaliana/generative-art/pythonds/kid-classification.webp
---


{{< badges
    printMessage="true"
>}}

::: {.content-visible when-profile="fr"}
# Introduction

Ce chapitre vise à présenter de manière très succincte le principe de l'entraînement de modèles dans un cadre de classification. L'objectif est d'illustrer la démarche à partir d'un algorithme dont le principe est assez intuitif. Il s'agit d'illustrer quelques uns des concepts évoqués dans les chapitres précédents, notamment ceux relatifs à l'entraînement d'un modèle. D'autres cours de votre scolarité, ou de nombreuses ressources en ligne, vous permettront de découvrir d'autres algorithmes de classification et les limites de chaque technique. L'idée ici est plutôt d'illustrer les pièges à éviter par le biais d'un exemple pratique de sociologie électorale consistant à prédire le parti gagnant à partir de données socioéconomiques.

## Données
:::

::: {.content-visible when-profile="en"}
# Introduction

This chapter aims to very briefly introduce the principle of training models in a classification context. The goal is to illustrate the process using an algorithm with an intuitive principle. It seeks to demonstrate some of the concepts discussed in previous chapters, particularly those related to model training. Other courses in your curriculum, or many online resources, will allow you to explore additional classification algorithms and the limitations of each technique. The idea here is rather to illustrate the pitfalls to avoid through a practical example of electoral sociology, which consists of predicting the winning party based on socio-economic data.

## Data
:::


{{< include _import_data_ml.qmd >}}

:::: {.content-visible when-profile="fr"}
## Approche méthodologique

### Principe des arbres de décision

Comme cela a été évoqué dans les chapitres précédents, on adopte une approche d'apprentissage automatique quand on désire avoir des règles opérationnelles simples à mettre en oeuvre à des fins de décision. Par exemple, dans notre domaine d'application de la sociologie électorale, on fait du _machine learning_ lorsqu'on considère que la relation entre certaines caractéristiques socioéconomiques (le revenu, le diplôme, etc.) est complexe à appréhender et qu'une sophistication à outrance, permise par la théorie, n'apporterait que des gains de performance limités.

Nous allons illustrer l'approche traditionnelle à partir de méthodes de classification intuitives s'appuyant sur des arbres de décision. Cette approche est assez intuitive. Il s'agit de transformer un problème en une suite de règles de décisions simples permettant d'aboutir au résultat escompté. Par exemple, 

* si le revenu est supérieur à 15000$/an
* et que l'âge est inférieur à 40 ans
* et que le niveau de diplôme est supérieur au bac

alors statistiquement on aura plutôt un vote démocrate. 

La @fig-iris-classification-fr illustre, de manière graphique, la manière dont un arbre de décision est construit comme une suite de choix binaires. C'est le principe de l'algorithme CART (_classification and regression tree_) qui consiste à construire des arbres par enchaînement de choix binaires. 

![Exemple d'arbre de décision sur le jeu de données classique iris. Source: [Documentation de scikit-learn](https://scikit-learn.org/stable/modules/tree.html)](https://scikit-learn.org/stable/_images/iris.svg){#fig-iris-classification-fr}

Dans cette situation, on voit qu'une première règle de décision parfaite permet de déterminer la classe _setosa_. Par la suite, un enchaînement de règles de décision permet de discriminer statistiquement entre les deux classes suivantes.
::::

:::: {.content-visible when-profile="en"}
## Methodological approach

### Principle of decision trees

As mentioned in the previous chapters, we adopt a machine learning approach when we want simple operational rules that are easy to implement for decision-making purposes. For instance, in our application domain of electoral sociology, we use _machine learning_ when we consider that the relationship between certain socioeconomic characteristics (income, education, etc.) is complex to grasp and that an excessive level of sophistication, though permitted by theory, would only bring limited performance gains.

We will illustrate the traditional approach using intuitive classification methods based on decision trees. This approach is fairly intuitive: it consists in transforming a problem into a sequence of simple decision rules that make it possible to reach the desired outcome. For example,

* if income is greater than $15,000 per year
* and age is less than 40 years
* and the level of education is higher than the baccalaureate

then, statistically, we are more likely to observe a Democratic vote.

Figure @fig-iris-classification-en illustrates, graphically, how a decision tree is built as a sequence of binary choices. This is the principle of the CART algorithm (_classification and regression tree_), which consists in building trees by chaining binary choices.

![Example of a decision tree on the classic iris dataset. Source: [scikit-learn documentation](https://scikit-learn.org/stable/modules/tree.html)](https://scikit-learn.org/stable/_images/iris.svg){#fig-iris-classification-en}

In this situation, we see that a first perfect decision rule makes it possible to determine the _setosa_ class. Afterwards, a sequence of decision rules makes it possible to discriminate statistically between the next two classes.
::::

:::: {.content-visible when-profile="fr"}
### Le fonctionnement itératif

Cette structure finale est le résultat d'un algorithme itératif. Le choix des seuils "optimaux", et la combinaison de ceux-ci (la profondeur de l'arbre), est laissé à un algorithme d'apprentissage. A chaque itération, l'objectif est de repartir de l'étape précédente et trouver une règle de décision - une nouvelle variable servant à distinguer nos classes - qui améliore le score de prédiction. 

Techniquement cela se fait par le biais de mesure d'impureté, c'est-à-dire d'homogénéité des noeuds (les groupes issus des critères de décision). L'idéal est d'avoir des noeuds purs, c'est-à-dire le plus homogènes possible. Les plus utilisées sont l'indice de Gini ou l'entropie de Shannon.
::::

:::: {.content-visible when-profile="en"}
### Iterative procedure

This final structure is the result of an iterative algorithm. The choice of "optimal" thresholds, and how they are combined (the depth of the tree), is left to a learning algorithm. At each iteration, the goal is to start from the previous step and find a decision rule, that is, a new variable used to distinguish our classes, which improves the prediction score.

Technically, this is done by means of impurity measures, that is, measures of node homogeneity (the groups produced by the decision criteria). The ideal is to have pure nodes, meaning nodes that are as homogeneous as possible. The most commonly used measures are the Gini index and Shannon entropy.
::::

:::: {.content-visible when-profile="fr"}
::: {.callout-note collapse="false"}
Il serait bien sûr possible de présenter ces intuitions par la formalisation mathématique. Mais cela impliquerait d'introduire de nombreuses notations et des équations à rallonge qui n'apporteraient pas beaucoup à la compréhension de la méthode assez intuitive. 

Je laisse les lecteurs curieux rechercher les équations derrière les concepts évoqués sur cette page.
:::
::::

:::: {.content-visible when-profile="en"}
::: {.callout-note collapse="false"}
It would of course be possible to present these intuitions through mathematical formalization. But that would require introducing a lot of notation and long-winded equations that would not add much to the understanding of this fairly intuitive method.

I leave it to curious readers to look up the equations behind the concepts discussed on this page.
:::
::::

:::: {.content-visible when-profile="fr"}
Ces mesures d'impureté servent à guider le choix de la structure de l'arbre, notamment de sa racine (le point de départ) à sa feuille (le noeud auquel on aboutit après avoir enchaîné le chemin de combinaison d'arbre). 

Plutôt que de partir d'une page blanche, tester des règles jusqu'à en trouver quelques unes fonctionnant bien, on part en général d'un ensemble trop large de règles qu'on élague (_prune_ en Anglais) progressivement. Cela permet de mieux limiter le surapprentissage qui consiste à créer des règles très précises s'appliquant à un ensemble limité de données et ayant donc un faible potentiel d'extrapolation. 

Par exemple, si on reprend la @fig-iris-classification-fr, on voit que certains noeuds s'appliquent à un ensemble très limité de données (des échantillons de trois ou quatre observations): le pouvoir statistique de ces règles est sans doute limité. 
::::

:::: {.content-visible when-profile="fr"}
These impurity measures are used to guide the choice of the tree’s structure, in particular from its root (the starting point) to its leaf (the node reached after following a path through the tree’s sequence of splits).

Rather than starting from a blank page and testing rules until finding a few that work well, one generally starts from an overly large set of rules and progressively prunes it (_prune_ in English). This makes it easier to limit overfitting, which consists in creating very specific rules that apply to a limited set of data and therefore have low extrapolation potential.

For example, if we return to Figure @fig-iris-classification-fr, we can see that some nodes apply to a very small subset of the data (samples of three or four observations): the statistical power of these rules is probably limited.
::::


::: {.content-visible when-profile="fr"}
# Application

Pour appliquer un modèle de classification, il nous faut
trouver une variable dichotomique. Le choix naturel est
de prendre la variable dichotomique qu'est la victoire ou 
défaite d'un des partis. 

Même si les Républicains ont perdu en 2020, ils l'ont emporté
dans plus de comtés (moins peuplés). Nous allons considérer
que la victoire des Républicains est notre _label_ 1 et la défaite _0_.

Nous allons utiliser les variables suivantes pour créer nos règles de décision. 
:::

::: {.content-visible when-profile="en"}
# Application

To apply a classification model, we need to find a dichotomous variable. The natural choice is to use the dichotomous variable of a party's victory or defeat.

Even though the Republicans lost in 2020, they won in more counties (less populated ones). We will consider a Republican victory as our _label_ 1 and a defeat as _0_.

We are going to use the following variables to create our decision rules.
:::


```{python}
#| echo: true
xvars = [
  'Unemployment_rate_2019', 'Median_Household_Income_2021',
  'Percent of adults with less than a high school diploma, 2018-22',
  "Percent of adults with a bachelor's degree or higher, 2018-22"
]
```

::: {.content-visible when-profile="fr"}
Nous allons également utiliser ces packages
:::

::: {.content-visible when-profile="en"}
We are going to use these packages
:::

```{python}
#| echo: true
import sklearn.metrics
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
import matplotlib.pyplot as plt
```


::: {.content-visible when-profile="fr"}

:::: {.callout-tip}
## Exercice 1 : Premier algorithme de classification

1. Créer une variable *dummy* appelée `y` dont la valeur vaut 1 quand les républicains l'emportent. 
2. En utilisant la fonction prête à l'emploi nommée `train_test_split` de la librairie `sklearn.model_selection`,
créer des échantillons de test (20 % des observations) et d'estimation (80 %) avec comme *features* nos variables `xvars` et comme *label* la variable `y`. 

3. Entraîner un classifieur SVM avec comme paramètre de régularisation `C = 1`. Regarder les mesures de performance suivante : `accuracy`, `f1`, `recall` et `precision`.

2. Vérifier la matrice de confusion : vous devriez voir que malgré des scores en apparence pas si mauvais, il y a un problème notable. 

3. Refaire les questions précédentes avec des variables normalisées. Le résultat est-il différent ?

4. Changer de variables *x*. Utiliser uniquement le résultat passé du vote démocrate (année 2016) et le revenu. Les variables en question sont `share_2016_republican` et `Median_Household_Income_2021`. Regarder les résultats, notamment la matrice de confusion. 

5. [OPTIONNEL] Faire une 5-fold validation croisée pour déterminer le paramètre *C* idéal. 
::::

:::


:::: {.content-visible when-profile="en"}
::: {.callout-tip}

## Exercise 1: First classification algorithm

1. Create a *dummy* variable called `y` with a value of 1 when the Republicans win. 
2. Using the ready-to-use function `train_test_split` from the `sklearn.model_selection` library, 
create test samples (20% of the observations) and training samples (80%) with the following *features*: 

```{.python}
xvars = [
  "Unemployment_rate_2019", "Median_Household_Income_2021",
  "Percent of adults with less than a high school diploma, 2018-22",
  "Percent of adults with a bachelor's degree or higher, 2018-22"
]
```


and use the variable `y` as the *label*. 

3. Train an SVM classifier with a regularization parameter `C = 1`. Examine the following performance metrics: `accuracy`, `f1`, `recall`, and `precision`.

4. Check the confusion matrix: despite seemingly reasonable scores, you should notice a significant issue.

5. Repeat the previous steps using normalized variables. Are the results different?


6. Change the *x* variables. Use only the previous Democratic vote result (2016) and income. Variables in question are `share_2016_republican` and `Median_Household_Income_2021`. Examine results, in particular the confusion matrix.

7. [OPTIONAL] Perform 5-fold cross-validation to determine the ideal *C* parameter. 

:::
::::


```{python}
# 1. Création de la dummy y de victoire des républicains
votes['y'] = (votes['votes_gop'] > votes['votes_dem']).astype(int)
```


```{python}
#2. Création des échantillons d'entraînement et de validation

df = votes.loc[:, ["y"] + xvars]
df = df.dropna()

X_train, X_test, y_train, y_test = train_test_split(
    df.loc[: , xvars],
    df['y'], test_size=0.2, random_state=123
)
```

::: {.content-visible when-profile="fr"}
On obtient donc un ensemble de _features_ d'entraînement ayant cette forme:
:::

::: {.content-visible when-profile="en"}
We thus obtain a set of training _features_ with the following structure:
:::

```{python}
X_train.head()
```

::: {.content-visible when-profile="fr"}
Et les _labels_ associés sont les suivants:
:::

::: {.content-visible when-profile="en"}
And the associated _labels_ are as follows:
:::

```{python}
y_test
```


```{python}
# 3. Entraînement du modèle et performances
clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)
y_pred = clf.predict(X_test)

sc_accuracy = sklearn.metrics.accuracy_score(y_pred, y_test)
sc_f1 = sklearn.metrics.f1_score(y_pred, y_test)
sc_recall = sklearn.metrics.recall_score(y_pred, y_test)
sc_precision = sklearn.metrics.precision_score(y_pred, y_test)
```

```{python}
stats_perf = pd.DataFrame.from_dict(
  {
    "Accuracy": [sc_accuracy], "Recall": [sc_recall],
    "Precision": [sc_precision], "F1": [sc_f1]
  }, orient = "index", columns = ["Score"]
)
```


::: {.content-visible when-profile="fr"}
A l'issue de la question 3, notre classifieur manque totalement les labels 0, qui sont minoritaires. Parmi les raisons possibles : l'échelle des variables. Le revenu, notamment, a une distribution qui peut écraser celle des autres variables, dans un modèle linéaire. Il faut donc, a minima, standardiser les variables, ce qui est l'objet de la question 4.
:::

::: {.content-visible when-profile="en"}
At the end of question 3, our classifier completely misses the 0 labels, which are in the minority. One possible reason is the scale of the variables. Income, in particular, has a distribution that can dominate the others in a linear model. Therefore, at a minimum, it is necessary to standardize the variables, which is the focus of question 4.
:::



```{python}
import matplotlib.pyplot as plt

# 4. Matrice de confusion
predictions = clf.predict(X_test)
cm = sklearn.metrics.confusion_matrix(y_test, predictions, labels=clf.classes_)
disp = sklearn.metrics.ConfusionMatrixDisplay(
            confusion_matrix=cm,
            display_labels=clf.classes_
       )
disp.plot()
plt.show()
```

::: {.content-visible when-profile="fr"}
Standardiser les variables n'apporte finalement pas de gain :
:::

::: {.content-visible when-profile="en"}
Standardizing the variables ultimately does not bring any improvement:
:::

```{python}
import sklearn.preprocessing as preprocessing

X = df.loc[:, xvars]
y = df['y']
scaler = preprocessing.StandardScaler().fit(X)
X = scaler.transform(X)

X_train, X_test, y_train, y_test = train_test_split(
    X,
    y, test_size=0.2, random_state=0
)

clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)
predictions = clf.predict(X_test)
cm = sklearn.metrics.confusion_matrix(y_test, predictions, labels=clf.classes_)
disp = sklearn.metrics.ConfusionMatrixDisplay(
  confusion_matrix=cm,
  display_labels=clf.classes_
)
disp.plot()
plt.show()
```

::: {.content-visible when-profile="fr"}
Il faut donc aller plus loin : le problème ne vient pas de l'échelle mais du choix des variables. C'est pour cette raison que l'étape de sélection de variables est cruciale et qu'un chapitre y est consacré.

À l'issue de la question 6, le nouveau classifieur devrait avoir les performances suivantes :
:::

::: {.content-visible when-profile="en"}
It is therefore necessary to go further: the problem does not lie in the scale but in the choice of variables. This is why the step of variable selection is crucial and why a chapter is dedicated to it.

At the end of question 6, the new classifier should have the following performance:
:::


```{python}
#| output: asis

out = pd.DataFrame.from_dict(
  {
    "Accuracy": [sc_accuracy], "Recall": [sc_recall],
    "Precision": [sc_precision], "F1": [sc_f1]
  }, orient = "index", columns = ["Score"]
)
```

```{python}
# Question 6
votes['y'] = (votes['votes_gop'] > votes['votes_dem']).astype(int)
df = votes.loc[: , ["y", "share_2016_republican", 'Median_Household_Income_2021']]
tempdf = df.dropna(how = "any")

X = tempdf.loc[:, ['share_2016_republican', 'Median_Household_Income_2021']]
y = tempdf['y']
scaler = preprocessing.StandardScaler().fit(X)
X = scaler.transform(X)

X_train, X_test, y_train, y_test = train_test_split(
    X,
    y, test_size=0.2, random_state=0
)

clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)
y_pred = clf.predict(X_test)

sc_accuracy = sklearn.metrics.accuracy_score(y_pred, y_test)
sc_f1 = sklearn.metrics.f1_score(y_pred, y_test)
sc_recall = sklearn.metrics.recall_score(y_pred, y_test)
sc_precision = sklearn.metrics.precision_score(y_pred, y_test)

predictions = clf.predict(X_test)
cm = sklearn.metrics.confusion_matrix(y_test, predictions, labels=clf.classes_)
disp = sklearn.metrics.ConfusionMatrixDisplay(
            confusion_matrix=cm,
            display_labels=clf.classes_
       )
disp.plot()

plt.savefig("confusion_matrix3.png")
```














