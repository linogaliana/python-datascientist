:::: {.content-visible when-profile="fr"}

::: {.exercise}
## Exercice 1 : TF-IDF : calcul de fréquence

1. Utiliser le vectoriseur TF-IdF de `scikit-learn` pour transformer notre corpus en une matrice `document x terms`. Au passage, utiliser l'option `stop_words` pour ne pas provoquer une inflation de la taille de la matrice. Nommer le modèle `tfidf` et le jeu entraîné `tfs`.
2. Après avoir construit la matrice de documents x terms avec le code suivant, rechercher les lignes où les termes ayant la structure `abandon` sont non-nuls.
3. Trouver les 50 extraits où le score TF-IDF du mot _"fear"_ est le plus élevé et l'auteur associé. Déterminer la répartition des auteurs dans ces 50 documents.
4. Observer les 10 scores où TF-IDF de _"fear"_ sont les plus élevés

<details>
<summary>
Aide pour la question 2
</summary>

```python
feature_names = tfidf.get_feature_names_out()
corpus_index = [n for n in list(tfidf.vocabulary_.keys())]
horror_dense = pd.DataFrame(tfs.todense(), columns=feature_names)
```
</details>

:::

::::

:::: {.content-visible when-profile="en"}

::: {.exercise}
## Exercise 1: TF-IDF Frequency Calculation

1. Use the TF-IDF vectorizer from `scikit-learn` to transform your corpus into a `document x terms` matrix. Use the `stop_words` option to avoid inflating the matrix size. Name the model `tfidf` and the resulting dataset `tfs`.
2. After constructing the document x terms matrix with the code below, find the rows where terms matching `abandon` are non-zero.
3. Identify the 50 excerpts where the TF-IDF score for the word _"fear"_ is highest and their associated authors. Determine the distribution of authors among these 50 documents.
4. Inspect the top 10 scores where TF-IDF for _"fear"_ is highest.

<details>
<summary>
Hint for question 2
</summary>

```python
feature_names = tfidf.get_feature_names_out()
corpus_index = [n for n in list(tfidf.vocabulary_.keys())]
horror_dense = pd.DataFrame(tfs.todense(), columns=feature_names)
```
</details>

:::

::::




::: {.content-visible when-profile="fr"}

Le vectoriseur obtenu à l'issue de la question 1 est
le suivant :

:::

::: {.content-visible when-profile="en"}

The vectorizer obtained at the end of question 1 is
as follows:

:::


```{python}
#1. TfIdf de scikit
from sklearn.feature_extraction.text import TfidfVectorizer
tfidf = TfidfVectorizer(stop_words=list(stopwords))
tfidf
```

```{python}
tfs = tfidf.fit_transform(horror['Text'])
```

```{python}
import pandas as pd

feature_names = tfidf.get_feature_names_out()
corpus_index = [n for n in list(tfidf.vocabulary_.keys())]
horror_dense = pd.DataFrame(tfs.todense(), columns=feature_names)

horror_dense.head()
```

::: {.content-visible when-profile="fr"}

Les lignes où le terme _"abandon"_ apparait
sont les suivantes (question 2) :

:::

::: {.content-visible when-profile="en"}

The lines where the term _"abandon"_ appears
are as follows (question 2):

:::

```{python}
#2. Lignes où les termes de abandon sont non nuls.
tempdf = horror_dense.loc[(horror_dense.filter(regex = "abandon")!=0).any(axis=1)]
print(tempdf.index)
```

::: {.content-visible when-profile="fr"}

La matrice document-terme associée à celles-ci est la suivante :

:::

::: {.content-visible when-profile="en"}

The document-term matrix associated with these is as follows:

:::

```{python}
tempdf.head(5)
```

::: {.content-visible when-profile="fr"}

On remarque ici l'inconvénient de ne pas avoir fait de racinisation. Les variations
de _"abandon"_ sont éclatées sur de nombreuses colonnes. _"abandoned"_ est aussi différent d'_"abandon"_ que de _"fear"_. C'est l'un des problèmes de l'approche _bag of words_.

:::

::: {.content-visible when-profile="en"}

Here we notice the drawback of not applying stemming. Variations of _"abandon"_ are spread across many columns. _"abandoned"_ is treated as different from _"abandon"_ just as it is from _"fear"_. This is one of the limitations of the _bag of words_ approach.

:::


```{python}
#| include: true

# 3. 50 extraits avec le TF-IDF le plus élevé.
list_fear = (
  horror_dense["fear"]
  .sort_values(ascending =False)
  .head(n=50)
  .index.tolist()
)
(
  horror.iloc[list_fear]
  .agg({"Text": "count"})
  .sort_values(ascending = False)
)
```

::: {.content-visible when-profile="fr"}

Les 10 scores les plus élevés sont les suivants :

:::

::: {.content-visible when-profile="en"}

The 10 highest scores are as follows:

:::

```{python}
# 4. Les 10 scores les plus élevés
horror.iloc[list_fear[:9]]['Text'].tolist()
```
