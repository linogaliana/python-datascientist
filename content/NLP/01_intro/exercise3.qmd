:::: {.content-visible when-profile="fr"}

::: {.exercise}
## Exercice 3 : Nettoyage du texte

1. Reprendre l'ouvrage de Dumas et nettoyer celui-ci avec `Spacy`. Refaire le nuage de mots et conclure.
2. Faire ce même exercice sur le jeu de données anglo-saxon. Idéalement, vous devriez être en mesure d'utiliser la fonctionnalité de _pipeline_ de `SpaCy`.

:::

::::

:::: {.content-visible when-profile="en"}

::: {.exercise}
## Exercise 3: Text Cleaning

1. Take Dumas' work and clean it using `Spacy`. Generate the word cloud again and draw your conclusions.
2. Perform the same task on the Anglo-Saxon dataset. Ideally, you should be able to use the `SpaCy` _pipeline_ functionality.

:::

::::

```{.python include="cleantext.py"}
```

```{python}
del clean_text
def clean_text(doc):
    # Tokenize, remove stop words and punctuation, and lemmatize
    cleaned_tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]
    # Join tokens back into a single string
    cleaned_text = ' '.join(cleaned_tokens)
    return cleaned_text
```


```{python}
#| label: clean-stopwords-dumas
# Process the text with spaCy
doc = nlp(
  dumas[:30000],
  disable=['ner', 'textcat']
)

# Clean the text
cleaned_dumas = clean_text(doc)
```

```{python}
wordcloud_dumas_nostop = make_wordcloud(cleaned_dumas)
```

Ces retraitements commencent à porter leurs fruits puisque des mots ayant plus
de sens commencent à se dégager, notamment les noms des personnages
(Dantès, Danglart, etc.):


```{python}
#| fig-cap: Nuage de mot produit à partir du Comte de Monte Cristo après nettoyage
#| label: fig-wordcloud-dumas-nostop
plt.imshow(wordcloud_dumas_nostop, interpolation='bilinear')
plt.axis("off")
```




```{python}
#| label: clean-stopwords-horror
# Question 2
docs = nlp_english.pipe(horror["Text"])
cleaned_texts = [clean_text(doc) for doc in docs]
horror['preprocessed_text'] = cleaned_texts
```

```{python}
#| fig-cap:
#|   - "Lovercraft"
#|   - "Poe"
#|   - "Shelley"
#| label: fig-wordcloud-spooky-nostop
fig = plt.figure(figsize=(15, 12))
for i in range(len(n_topics)):
    wordcloud = graph_wordcloud(n_topics[i], horror, "preprocessed_text")
    plt.imshow(wordcloud)
    plt.axis('off')
    plt.show()
```


