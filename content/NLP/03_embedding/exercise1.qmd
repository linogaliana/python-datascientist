:::: {.content-visible when-profile="fr"}

::: {.exercise}
## Exercice 1: recherche de similarité avec TF-IDF

1. Utiliser la méthode `transform` pour vectoriser tout notre corpus d'entraînement.

2. En supposant que votre jeu d'entraînement vectorisé s'appelle `X_train_tfidf`, vous pouvez le transformer en _DataFrame_ avec la commande suivante:

````python
X_train_tfidf = pd.DataFrame(
    X_train_tfidf.todense(), columns=pipeline_tfidf.get_feature_names_out()
)
````

3. Utiliser la méthode `cosine_similarity` de `Scikit` pour calculer la similarité cosinus entre notre texte vectorisé et l'ensemble du corpus d'entraînement grâce au code suivant:

````python
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

cosine_similarities = cosine_similarity(
    X_train_tfidf,
    pipeline_tfidf.transform([text])
).flatten()

top_4_indices = np.argsort(cosine_similarities)[-4:][::-1]  # Tri décroissant
top_4_similarities = cosine_similarities[top_4_indices]
````

4. Retrouver les documents concernés. Êtes-vous satisfait du résultat ? Comprenez-vous ce qu'il s'est passé ?

:::

::::

:::: {.content-visible when-profile="en"}

::: {.exercise}
## Exercise 1: Similarity Search with TF-IDF

1. Use the `transform` method to vectorize the entire training corpus.

2. Assuming your vectorized training set is named `X_train_tfidf`, you can convert it to a _DataFrame_ with the following command:

````python
X_train_tfidf = pd.DataFrame(
    X_train_tfidf.todense(), columns=pipeline_tfidf.get_feature_names_out()
)
````

3. Use `Scikit`'s `cosine_similarity` method to compute cosine similarity between your vectorized text and the training corpus using this code:

````python
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

cosine_similarities = cosine_similarity(
    X_train_tfidf,
    pipeline_tfidf.transform([text])
).flatten()

top_4_indices = np.argsort(cosine_similarities)[-4:][::-1]  # Descending sort
top_4_similarities = cosine_similarities[top_4_indices]
````

4. Retrieve the corresponding documents. Are you satisfied with the result? Do you understand what happened?

:::

::::


```{python}
#| label: exo1-q1-q2
X_train_tfidf = (
    pipeline_tfidf.transform(spooky_df['text_clean'])
)
X_train_tfidf=pd.DataFrame(
    X_train_tfidf.todense(),columns=pipeline_tfidf.get_feature_names_out()
)
```

```{python}
#| label: exo1-q3
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

cosine_similarities = cosine_similarity(
    X_train_tfidf,
    pipeline_tfidf.transform([text])
).flatten()

top_4_indices = np.argsort(cosine_similarities)[-4:][::-1]  # Sort and reverse for descending order
top_4_similarities = cosine_similarities[top_4_indices]
```

A l'issue de l'exercice, les 4 textes les plus similaires sont:

```{python}
documents_plus_proches = spooky_df.iloc[top_4_indices].loc[:, ["text", "author"]]
documents_plus_proches['score'] = top_4_similarities

documents_plus_proches
```
